[{"content":"原文链接how-quic-is-displacing-tcp-for-speed\n引言 在过去的三十年中，HTTP（超文本传输协议）一直是互联网的支柱。我们能够浏览网页、下载文件、流式传输电影等，都是因为HTTP。这个协议多年来不断发展，见证了重大的改进。\nHTTP协议是一个应用层协议，工作在TCP（传输控制协议）之上。TCP协议有一些限制，导致网络应用程序响应性较差。\n谷歌开发了一种改变游戏规则的传输协议QUIC，以克服TCP的缺点。QUIC几年前被标准化并加入到IETF（互联网工程任务组）。\n在过去几年中，QUIC的采用呈指数级增长。大多数科技公司，如谷歌、Facebook、Pinterest等，已经开始采用使用QUIC作为传输层的HTTP/3.0。这些公司在使用HTTP/3.0和QUIC后，其网站性能有了显著提升。\n让我们开始我们的旅程，了解QUIC如何取代TCP。我们首先将了解一些基本的TCP和UDP网络概念。之后，我们将看看HTTP的演变，以及每个版本是如何克服前一个版本的限制的。然后，我们将了解QUIC是什么以及它的工作原理。我们将探讨为什么QUIC的性能比TCP高。\nTCP和UDP是如何工作的？ TCP（传输控制协议）和UDP（用户数据报协议）是传输层协议。这些协议管理互联网数据包流向和来自任何电子设备的过程。让我们详细了解这两个协议是如何工作的。\nTCP TCP是一种基于连接的协议。客户端与服务器建立连接，然后发送数据。TCP连接是通过一种称为三次握手的机制建立的。下图展示了三次握手过程：\n这个过程包括三个步骤：\nSYN - 客户端向服务器发送一个SYN数据包。\nACK - 服务器接收到SYN后，通过ACK数据包向客户端发送确认。\nSYN-ACK - 客户端收到服务器的ACK数据包后，最终通过SYN-ACK向服务器发送确认。\nTCP是一个有状态和可靠的协议。它保证从一台设备到另一台设备的所有数据包的传输。此外，它允许客户端和服务器使用相同的连接进行通信。\nUDP UDP是一种无连接协议。与TCP不同，客户端和服务器之间没有三次握手。客户端向服务器发送数据包，不等待服务器的确认。\nUDP不能保证100%的数据包传输。数据包可能会丢失，可能无法到达另一台设备。UDP不像TCP那样可靠。\n由于没有初始握手，UDP比TCP快得多。出于性能原因，UDP主要用于流式数据应用程序，如音乐/视频。\n这是一个流行的互联网梗，对TCP/UDP进行了调侃：\n到目前为止，我们已经了解了TCP和UDP协议是如何工作的。现在让我们探索HTTP协议，这是一个应用层协议。\nHTTP的演变 由Tim Berners-Lee在CERN开发的HTTP的第一个版本是在1989年。从那时起，该协议经历了多次优化和性能改进。大多数现代设备使用HTTP 1.1/ HTTP 2.0和HTTP 3.0。让我们回顾一下HTTP的历史，了解协议经历的重大变化。\nHTTP/1.0 在最初的HTTP/0.9版本之后，HTTP/1.0开始支持头、请求体、文本文件等。客户端每次使用HTTP从服务器获取数据时，都必须创建一个TCP连接。这导致在建立连接时显著浪费资源。\nHTTP/1.1 这个协议增加了对重用客户端和服务器之间现有TCP连接以获取新数据的支持。这是通过HTTP头keep-alive实现的。\n如果客户端想要获取10个JavaScript文件，那么它将与服务器建立一个连接。然后，它将重用相同的连接来获取这10个文件，而不是为每个文件创建一个新连接。\n这导致资源浪费减少和性能提升，因为它避免了创建多余的连接。然而，一个主要的缺点是众所周知的_队头阻塞_问题。\n下图展示了_队头阻塞_问题。\n让我们通过一个例子来理解这个概念。如上图所示，你有3个文件 - 图像、文本和视频。视频文件体积较大，传输时间会更长。由于视频文件传输时间较长，它会阻塞图像和文本文件的发送。\nHTTP/2.0 HTTP 2.0通过多路复用解决了_队头阻塞_问题。通过多路复用，多个文件可以通过同一个TCP连接发送。\n这导致了性能提升，并解决了应用层面的队头阻塞问题。然而，在TCP层面，如果发生数据包丢失，它必须等待数据包重传。\n多路复用解决方案在数据包丢失的情况下并不像预期的那样有效。实际上，如果数据包丢失超过5%，HTTP 1.1的性能比HTTP 2.0更好。_队头阻塞_问题从应用层转移到了传输层。\n下图展示了单个数据包丢失如何导致多个流延迟：\n当一个数据包丢失时，TCP将其后续数据包存储在其缓冲区中，直到收到丢失的数据包。然后TCP使用重传来获取丢失的数据包。HTTP无法看到TCP重传。因此，在这种情况下，不同的流会看到传输延迟。\n什么是QUIC？ 在过去的几个部分中，我们看到了TCP有一些固有的限制，如三次握手和队头阻塞。这些限制可以通过增强TCP或用新协议替换TCP来解决。\n尽管增强TCP很简单，但TCP存在于最低层，与操作系统紧密耦合。简单来说，TCP的代码存在于内核层而不是用户空间。考虑到大量的设备，实施内核空间的更改将需要大量的时间才能到达所有用户。\n因此，谷歌提出了一种新的协议QUIC，作为TCP的替代品。像TCP一样，QUIC也是一个传输层协议。然而，它位于用户空间而不是内核空间。这使得它容易更改和增强，与TCP不同。\nQUIC在UDP之上工作。它通过使用UDP克服了TCP的限制。它只是一个在UDP之上的层或包装器。该包装器添加了TCP的功能，如拥塞控制、数据包重传、多路复用等。它内部使用UDP，并在其上添加了TCP的最佳功能。\n下图显示了QUIC如何适应网络栈：\n现在我们已经了解了QUIC的基础知识，让我们深入了解这个协议的工作原理。\nQUIC是如何工作的？ QUIC握手 QUIC在UDP上工作，它不需要经过三次握手过程。三次握手过程增加了额外的开销，增加了延迟。因此，QUIC通过减少连接延迟来提高性能。\n在TCP的情况下，还有一个额外的用于TLS的握手，这也增加了延迟。QUIC将TLS握手和QUIC握手合并为一个调用。它优化了握手过程并提高了性能。\n可靠性 您可能会想“既然QUIC在UDP上工作，数据包会丢失吗？”。答案是不。QUIC在UDP堆栈上添加了可靠性。它实现了数据包重传，以防它没有收到必要的数据包。例如：如果服务器没有收到来自客户端的第5个数据包，协议将检测到它并要求客户端重新发送相同的数据包。\n多路复用 与TCP类似，QUIC也实现了多路复用。客户端可以使用单个通道同时传输多个文件。QUIC为每个流（传输的文件）创建一个UUID。它使用UUID来识别流。然后，多个流通过单个通道发送。\n下图展示了QUIC中多路复用是如何工作的：\nQUIC还通过其多路复用解决了TCP面临的队头阻塞问题。如果一个流遭受数据包丢失，只有该流会受到影响。QUIC中的流是独立的，不会影响彼此的工作。\n安全性 此外，QUIC 还支持 TLS 1.3（传输层安全性）。这保证了数据的安全性和保密性。TLS 加密了 QUIC 协议的大部分内容，例如数据包编号和连接关闭信号。\n为什么选择QUIC？ 降低延迟 - QUIC通过将TLS握手与连接建立结合起来，最小化了延迟。这也被称为0-RTT（零往返时间）。它实现了更快的连接建立，并提高了网络应用程序的性能。 多路复用 - 通过多路复用，QUIC可以在单个通道上发送多个数据流。这对于下载多个文件（如图像、JavaScript、CSS等）的客户端应用程序非常有用。 连接迁移 - 使用QUIC，您可以在不出现任何问题的情况下从一种网络接口切换到另一种（例如从Wi-Fi切换到移动数据）。这对于移动设备很重要，并提高了用户体验。 提高安全性 - QUIC使用TLS 1.3，提供更好的安全性。此外，它还加密了协议的大部分，与只加密HTTP有效载荷的TCP和TLS不同。与TCP相比，它更能抵御安全攻击。 广泛支持 - 自其诞生以来，它的采用率一直在上升。这进一步加强了它的有效性。 HTTP/3和QUIC HTTP/3是超文本传输协议（HTTP）的最新版本。它内部使用QUIC而不是TCP。它旨在为现代网络提供更有效和安全的基础。它拥有QUIC提供的所有优势。\nHTTP/3由IETF标准化。今天，很大一部分互联网流量依赖于HTTP/3。以下是显示HTTP/3采用率的图表：\n从上述图表中可以看出，采用率已经飙升至30%，并逐渐超越了HTTP/1.1。按照目前的发展速度，HTTP/3.0将在未来几年逐渐超越HTTP/2.0。\n结论 自三十年前HTTP诞生以来，互联网已经走过了漫长的道路。HTTP的演变使在线体验更加高效和响应迅速。随着现代应用程序需求的增长，我们意识到了底层协议如TCP的固有限制。\n谷歌开发了改变游戏规则的协议QUIC。它利用UDP并解决了TCP的所有不足。降低延迟、多路复用、增强安全性和连接迁移是QUIC的一些显著特点。QUIC带来的创新解决了队头阻塞等问题。\n像谷歌和Facebook这样的大型科技公司通过在HTTP/3中采用QUIC，在性能上取得了显著提升。随着采用率的上升和日益增长的支持，HTTP/3将成为互联网通信的标准。在未来几年，互联网将发展并过渡到HTTP/3，以实现效率、可靠性和性能。\n参考文献 TCP VS UDP 梗 为什么HTTP/3.0正在吞噬世界？ Pinterest现在使用HTTP/3.0 与谷歌对等 - QUIC ","date":"2024-06-14T09:38:42+08:00","image":"https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd0e30c17-275b-4a94-8883-74c546ead5e5_5955x3350.jpeg","permalink":"https://huizhou92.com/zh-cn/p/quic-%E5%A6%82%E4%BD%95%E5%9C%A8%E9%80%9F%E5%BA%A6%E5%92%8C%E5%AE%89%E5%85%A8%E6%80%A7%E6%96%B9%E9%9D%A2%E5%8F%96%E4%BB%A3-tcp/","title":"QUIC 如何在速度和安全性方面取代 TCP？"},{"content":"上周，Go 1.23 进入冻结期，这意味着不会添加任何新功能，并且任何已添加的功能不太可能被删除。这是一个预览即将发生的变化的好机会。\n这篇文章，来了解一下 1.23 转正的 iter 包。\nThis article is first published in the medium MPP plan. If you are a medium user, please follow me in medium. Thank you very much.\n在Go 1.22中，引入了range over func实验性功能，但需要通过参数GOEXPERIMENT=rangefunc启用。在Go 1.23中，可以直接使用代码实现这种迭代方式。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 func Backward(s []string) func(yield func(string) bool) { return func(yield func(string) bool) { for i := len(s) - 1; i \u0026gt;= 0; i-- { yield(strings.ToUpper(s[i])) } } } ​ func ToUpperByIter() { sl := []string{\u0026#34;hello\u0026#34;, \u0026#34;world\u0026#34;, \u0026#34;golang\u0026#34;} for v := range Backward(sl) { // do business } } yield是传递给迭代器的可调用函数的常规名称。\n我们考虑一下如何在不使用“iter”包的情况下编写代码来实现相同的功能：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 func Convert[S any, D any](src []S, mapFn func(s S) D) []D { r := make([]D, 0, len(src)) for _, i := range src { r = append(r, mapFn(i)) } return r } func ToUpByString() { sl := []string{\u0026#34;hello\u0026#34;, \u0026#34;world\u0026#34;, \u0026#34;golang\u0026#34;} s0 := Convert(sl, func(v string) string { return strings.ToUpper(v) }) for _, v := range s0 { // do business } } 性能对比 1 2 3 4 5 6 7 8 9 10 11 12 13 ➜ huizhou92 git:(master) ✗ go test -bench . -count=3 goos: darwin goarch: arm64 pkg: huizhou92 cpu: Apple M1 Pro BenchmarkToUpByString-10 8568332 128.7 ns/op BenchmarkToUpByString-10 9310351 128.6 ns/op BenchmarkToUpByString-10 9344986 128.5 ns/op BenchmarkToUpByIter-10 12440120 96.22 ns/op BenchmarkToUpByIter-10 12436645 96.25 ns/op BenchmarkToUpByIter-10 12371175 96.64 ns/op PASS ok huizhou92 8.162s 结果很明显：ToUpperByIter 性能更好，因为它不会重新分配新的slice，使得它比以前的方法更高效。\niter 的目标 iter 包旨在提供统一且高效的迭代方法。它为自定义容器类（尤其是在引入泛型之后）提供了标准的迭代接口，并可以替换一些返回切片的现有 API。通过使用迭代器并利用编译器优化，可以提高性能。此外，它还提供了适合函数式编程风格的标准迭代机制。\n如何使用 iter iter支持两种类型的迭代器：\n1 2 3 4 5 6 7 8 9 // Seq is an iterator over sequences of individual values. // When called as seq(yield), seq calls yield(v) for each value v in the sequence, // stopping early if yield returns false. type Seq[V any] func(yield func(V) bool) // Seq2 is an iterator over sequences of pairs of values, most commonly key-value pairs. // When called as seq(yield), seq calls yield(k, v) for each pair (k, v) in the sequence, // stopping early if yield returns false. type Seq2[K, V any] func(yield func(K, V) bool) map 包已经使用 iter 来添加了诸如 All 和 Keys 等方法。这里是它的实现参考：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 //https://go.googlesource.com/go/blob/c83b1a7013784098c2061ae7be832b2ab7241424/src/maps/iter.go#L12 // All returns an iterator over key-value pairs from m. // The iteration order is not specified and is not guaranteed // to be the same from one call to the next. func All[Map ~map[K]V, K comparable, V any](m Map) iter.Seq2[K, V] { return func(yield func(K, V) bool) { for k, v := range m { if !yield(k, v) { return } } } } // Keys returns an iterator over keys in m. // The iteration order is not specified and is not guaranteed // to be the same from one call to the next. func Keys[Map ~map[K]V, K comparable](m Map) iter.Seq[K] { return func(yield func(K) bool) { for k := range m { if !yield(k) { return } } } } 争论 “在我看来，yield 是一个足够复杂的概念，会导致出现大量糟糕的、难以理解的代码。这个建议只提供了语法糖，用于编写语言中已经超出可能范围的内容。我认为这违背了“一个问题 - 一个解决方案”的规则。拜托，让 Go 保持无聊。” 来源\n这是社区内常见的反对意见。yield 不容易理解，并且我们可以通过多种方式实现迭代器。\n结论 我支持添加iter。\niter包为开发人员提供了许多可能性，旨在简化代码并采用更多的函数式编程实践。然而，由于对性能、复杂性和学习曲线的担忧，它的接受度存在分歧。\n与任何新工具一样，关键是在提供明显好处的地方平衡其使用，并同时注意潜在缺点。毫无疑问，Go社区将继续探索和辩论如何利用iter的力量而不损害该语言的基本原则。\n参考资料 61405 56413 iterators_in_go_123 ","date":"2024-06-11T17:33:16+08:00","permalink":"https://huizhou92.com/zh-cn/p/go-1.23-new-iter-package/","title":"Go 1.23: 新包 Iter"},{"content":"上周，Go 1.23 进入冻结期，这意味着不会添加任何新功能，并且任何已添加的功能不太可能被删除。这是一个预览即将发生的变化的好机会。\n这篇文章，我们来介绍引入的新包unique\nThis article is first published in the medium MPP plan. If you are a medium user, please follow me in medium. Thank you very much.\n根据wikipedia的描述，interning是按需重复使用具有同等值对象的技术，减少创建新对象的动作。这种创建模式经常用于不同编程语言中的数和字符串，可以避免不必要的对象重复分配的开销。\nunique 参考了go4.org/intern ,将它移动到了 官方库，并且做了相应的修改。 issue #62483\n就像官方描述的一样 unique 这个包提供了一种轻量化（unique仅仅八个字节）的比较两个变量是否相等的实现。比如下面这段代码\n性能提升还是很明显的\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 ➜ unique git:(master) ✗ /Users/hxzhouh/workspace/googlesource/go/bin/go test -bench=\u0026#39;BenchmarkMake1\u0026#39; -count=5 goos: darwin goarch: arm64 pkg: unique cpu: Apple M1 Pro BenchmarkMake1-10 122033748 9.692 ns/op BenchmarkMake1-10 123878858 9.688 ns/op BenchmarkMake1-10 123927121 9.706 ns/op BenchmarkMake1-10 123849468 9.759 ns/op BenchmarkMake1-10 123306187 9.673 ns/op PASS ok unique 11.055s ➜ unique git:(master) ✗ /Users/hxzhouh/workspace/googlesource/go/bin/go test -bench=\u0026#39;BenchmarkMake2\u0026#39; -count=5 goos: darwin goarch: arm64 pkg: unique cpu: Apple M1 Pro BenchmarkMake2-10 1000000000 0.3118 ns/op BenchmarkMake2-10 1000000000 0.3114 ns/op BenchmarkMake2-10 1000000000 0.3119 ns/op BenchmarkMake2-10 1000000000 0.3136 ns/op BenchmarkMake2-10 1000000000 0.3115 ns/op PASS ok unique 1.875s 但是 你不应该把他当作一个全局变量来用,存储共享数据，unique 的底层实现其实是一个map,查询的成本也是很高的。\n比如\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 ➜ huizhou92_test git:(master) ✗ /Users/hxzhouh/workspace/googlesource/go/bin/go test --bench=BenchmarkBusinessUnique --count=5 goos: darwin goarch: arm64 pkg: huizhou92_test cpu: Apple M1 Pro BenchmarkBusinessUnique-10 3114 373867 ns/op BenchmarkBusinessUnique-10 3280 390818 ns/op BenchmarkBusinessUnique-10 2941 376503 ns/op BenchmarkBusinessUnique-10 3291 389665 ns/op BenchmarkBusinessUnique-10 2954 398610 ns/op PASS ok huizhou92_test 6.320s ➜ huizhou92_test git:(master) ✗ /Users/hxzhouh/workspace/googlesource/go/bin/go test --bench=BenchmarkBusinessString --count=5 goos: darwin goarch: arm64 pkg: huizhou92_test cpu: Apple M1 Pro BenchmarkBusinessString-10 526721706 2.185 ns/op BenchmarkBusinessString-10 548612287 2.183 ns/op BenchmarkBusinessString-10 549425077 2.188 ns/op BenchmarkBusinessString-10 549012100 2.182 ns/op BenchmarkBusinessString-10 548929644 2.183 ns/op PASS ok huizhou92_test 7.237s 正是因为这样，关于unique的讨论其实还在继续，可能是因为用到的地方不是很多？不管怎么样， 这个新的包进入标准库已经是事实了。 net/netip 已经用unique 重构了它，用来比对IP地址的详细信息。\n","date":"2024-06-04T09:54:42+08:00","image":"https://images.hxzhouh.com/blog-images/2024/06/0a8a9a271b2db6d5922f8e58e589b187.png","permalink":"https://huizhou92.com/zh-cn/p/golang-1.23-%E6%96%B0%E7%9A%84-unique-%E5%8C%85/","title":"Golang 1.23: 新的 unique 包"},{"content":"众所周知，HTTPS可以解决HTTP明文传输过程中的安全性问题，尤其是中间人攻击问题。其最初的全称是HTTP over SSL（或者说 http Security）。其中的SSL是指Secure Sockets Layer，后来SSL被TLS（Transport Layer Security ）所取代。今天我们就来总结一下HTTPS的要点\nThis article is first published in the medium MPP plan. If you are a medium user, please follow me in medium. Thank you very much.\nHTTPS 版本 当前人们一般将SSL,TLS这两个协议统称为SSL/TLS协议，但大家日常说SSL的时，默认还是指TLS协议。\nTLS 协议在版本上有1.1、1.2、1.3，其中1.2曾经是主流，现在推荐使用改进后的 TLS 1.3，它升级了HandShake和Record协议，会使得通信更加安全和高效。\n安全上，TLS 1.3 移除了一些在 TLS 1.2 中被认为是不安全的加密算法，如 RC4、DES、3DES、AES-CBC 和 MD5 等，这样可以减少安全漏洞的风险。\n性能上，TLS 1.3 减少了握手过程中的往返次数（RTT），从而加快了连接的建立速度。在最佳情况下，TLS 1.3 只需要一次往返就可以完成握手，同时支持0-RTT扩展，而 TLS 1.2 需要两次或更多。\n当然，作为设计精良的互联网协议，TLS 1.3也通过hello握手消息的扩展协议考虑了最大化向前兼容，这点不再赘述。\nHTTPS 核心流程 依据不同版本的差异，细节流程会略有不同，不追求严谨细致的情况下，HTTPS工作流程如下。\nbytebytego 的这个图非常具有表现力，展示了关键的交互和核心的加密流程。最关键的几步在于如何建立TCP链接，如何通过非对称加密协商获取对称加密的密钥，以及最后通过对称加密进行通信。\nHTTPS，准确来说是TLS，设计严密，其中最关键的是Record Layer和几种Protocol，前者是数据承载管道，各种子Protocol都跑在它上面 ，其中的Record是TLS数据收发传输的基本单位，类似TCP的segment，IP的Packet，这也是下面这幅图的含义。\n上图中Protocol里最重要的是Handshake协议，针对Client Hello进行抓包后，在Wireshark中体现得会更清晰。\nHTTPS SNI 扩展 互联网早期，单机服务器没那么强大，配套的HTTPS比如SSL v2也有设计缺陷。那时有一个假定，认为拥有一个IP的单台服务器只会托管一个域名服务，所以DNS解析以后，直连IP时就能非常确定要使用具体某个域名的证书。但后面云计算、虚拟主机大爆发，以及IPv4中IP的稀缺性，一台服务器托管多个域名的场景无可避免，这时服务器面临无法知道客户端到底想要访问哪个域名的SSL证书的问题，从而导致了HTTPS SNI的出现。\nSNI（Server Name Indication）是TLS协议的一个扩展，它允许客户端在握手过程中向服务器发送目标主机名信息。这样，服务器就可以在同一个IP地址上托管多个域名的HTTPS服务，并为每个域名提供正确的证书。\n这个问题看似简单，在HTTPS逐渐普及，各互联网服务商走向全站HTTPS化的早期，很多CDN厂商甚至都是不支持SNI的。当然在2024年的今天，无论是Nginx等软件生态，还是各厂商，都已经支持了的。\nSNI信息是通过TLS握手协议传输的，抓包示意大概是下面这样子。\n具体到实操，可以使用openssl s_client子命令中的-servername选项来指定SNI：\n1 openssl s_client -connect example.com:443 -servername example.com 如果使用OpenSSL Library，也可以使用SSL_set_tlsext_host_name和BIO_set_conn_hostname等函数来在代码中设置。\nHTTPS 证书机制 HTTPS通过公钥 体系里的非对称、对称及摘要算法，实现了一系列的加解密、签名、验签等功能，基本实现了安全四大特性：机密性、完整性，身份认证和不可否认。如典型的中间人攻击（Man-in-the-middle attack，MITM），也都有了解决方案。\n这里为了解决公钥的信任问题，又引入了证书和信任链机制。证书（Certificate）是由第三方CA（Certificate Authority，证书认证机构）颁发的，本质上是一个文件，通常是.crt、.cer 或 .pem 等扩展名存储。这个文件按照一定的标准（如X.509）编码，包含了公钥、证书持有者信息、颁发机构信息、有效期和数字签名等信息。\n有一些世界知名的 CA 机构，比如 DigiCert、VeriSign、Entrust、Let’s Encrypt 等，它们签发的证书分 DV、OV、EV 三种，对应不同的可信程度。但CA自己也有信任问题，小CA的信任靠大CA签名认证，但逐层向上到了链条的最后，就是 Root CA，就只能用“自签名证书”（Self-Signed Certificate）或者“根证书”（Root Certificate）了。\n大部分操作系统和浏览器都内置了各大 CA 的根证书，HTTPS通信时会顺着证书链（Certificate Chain）逐层验证到根证书。\nHTTPS 软件生态 HTTPS，或是说TLS，生态虽然丰富，但OpenSSL一家独大。它几乎支持所有公开的加密算法和协议，已经成为了事实上的标准，许多应用软件都会使用它作为底层库来实现 TLS 功能，比如著名的 Apache、Nginx 等。\nOpenSSL源于SSLeay，其后开枝散叶，形成众多分支，如 Google 的 BoringSSL、OpenBSD 的 LibreSSL。OpenSSL的内容也极其庞杂，可以优先使用openssl命令进行学习，具体可以参考ChatGPT。\nHTTPS 加速方案 HTTPS很美好，但美好的事物都有成本。所以关于HTTPS全站铺开后的各种优化，基本上可以写成独立的一篇文章，这里先简单提下。\n首先是优化RTT，这个在IO密集型的互联网场景下尤为重要，主要是通过升级协议，如升级HTTP/3，升级TLS 1.3，都可以通过不同原理来优化RTT。其次是优化单步骤性能，如增加TLS加速卡，设置单独的TLS集群或模块等，还有一些TLS session resumption等名词也可以关注。\n我以前写过一篇文章分享为什么HTTPS为什么这么慢的文章，有兴趣可以阅读一下。\nWhy does HTTPS need 7 handshakes and 9 times delay?\n参考资料 What\u0026rsquo;s the difference between HTTP and HTTPS?\nhow-does-https-work\n","date":"2024-05-27T18:30:32+08:00","image":"https://images.hxzhouh.com/blog-images/2024/05/9113c36ee94b362ffe79a997b75c8efe.png","permalink":"https://huizhou92.com/zh-cn/p/the-key-points-of-https/","title":"了解 HTTPS：关键点和流程详解"},{"content":"上周 go1.23 已经进入冻结期了，应该不会再添加新功能，相应的已经添加了的功能 也不太可能会被移除。\n这正好可以让我们提前尝鲜这些即将到来的新特性。\nhttps://groups.google.com/g/golang-dev/c/vXE304_MnKM\nThis article is first published in the medium MPP plan. If you are a medium user, please follow me in medium. Thank you very much.\n今天要说的就是1.23中对//go:linkname指令的变更。\n相关讨论的issue 在这里：\nhttps://github.com/golang/go/issues/67401\nTL;DR //go:linkname指令官方并不推荐使用，且不保证任何向前或者向后兼容性，因此明智的做法是尽量别用\n牢记这一点之后，我们可以接着往下看了。至于为啥和“我”也就是本文的作者有关，我们先看完新版本带来的新变化再说。\nlinkname指令是做什么的 简单的说，linkname指令用于向编译器和链接器传递信息。具体的含义根据用法可以分为三类。\n第一类叫做“pull”，意思是拉取，使用方式如下：\n1 2 3 4 5 6 import _ \u0026#34;unsafe\u0026#34; // 必须有这行才能用linkname import _ \u0026#34;fmt\u0026#34; // 被拉取的包需要显式导入（除了runtime包） //go:linkname my_func fmt.Println func my_func(...any) (n int, err error) 这种用法的指令格式是//go:linkname \u0026lt;指令下方的只有声明的函数或包级别变量名\u0026gt; \u0026lt;本包或者其他包中的有完整定义的函数或变量\u0026gt;。\n这个指令的作用就是告诉编译器和连接器，my_func的函数体直接使用fmt.Println的，my_func类似fmt.Println的别名，和它共享同一份代码，就像把指令第二个参数指定的函数和变量拉取下来给第一个参数使用一样。\n正因如此，指令下方给出的声明必须和被拉取的函数/变量完全一致，否则很容易因为类型不匹配导致panic（是的没错，除非拉取的对象不存在，否则都不会出现编译错误）。\n这个指令最恐怖的地方在于它能无视函数或者变量是否是export的，包私有的东西也能被拉取出来使用。因为这一点这种用法在早期的社区中很常见，比如很多人喜欢这么干：//go:linkname myRand runtime.fastrand，因为runtime提供了一个性能还不错的随机数实现，但没有公开出来，所以有人会用linkname指令把它导出为己所用，当然随着1.21的发布这种用法不再有任何意义了，请永远都不要去模仿。\n第二种用法叫做“push”，即推送。形式上是下面这样：\n1 2 3 4 5 6 7 8 9 10 11 12 import _ \u0026#34;unsafe\u0026#34; // 必须有这行才能用linkname //go:linkname main.fastHandle func fastHandle(input io.Writer) error { ... } // package main func fastHandle(input io.Writer) error // 后面main包中可以直接使用fastHandle // 这种情况下需要在main包下创建一个空的asm文件（通常以.s作为扩展名），以告诉编译器fastHandle的定义在别处 在这种用法中，我们只需要把函数/变量名当作第一个参数传给指令，注意需要给出想用这个函数/变量的包的名字，这里是main。同时指令声明的变量或函数必须要在同包内有完整的定义，通常推荐直接把完整定义写在linkname指令下方。\n这种用法是告诉编译器和链接器这个函数/变量的名字就是xxx.yyy，如果遇到这个函数就使用linkname指定的函数/变量的代码，这个模式下甚至能在本包定义别的包里的函数。\n当然这种用法的语义作用更明显，它意味着这个函数会在任何地方被使用，修改它需要小心，因为改变了函数的行为可能会让其他调用它的代码出bug；修改了函数的签名则很可能导致运行时panic；删除了这个函数则会导致代码无法编译。\n最后一类叫做“handshake”，即握手。他是把第一类和第二类方法结合使用：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 package mypkg import _ \u0026#34;unsafe\u0026#34; // 必须有这行才能用linkname //go:linkname fastHandle func fastHandle(input io.Writer) error { ... } package main import _ \u0026#34;unsafe\u0026#34; // 必须有这行才能用linkname //go:linkname fastHandle mypkg.fastHandle func fastHandle(input io.Writer) error “pull”的一方没什么区别，但“push”的一方不用再写包名，同时用来告诉编译器函数定义在别的地方的空的asm文件也不需要了。这种就像通讯协议中的“握手”，一方告诉编译器这边允许某个函数/变量被linkname操作，另一边则明确像编译器要求它要使用某个包的某个函数/变量。\n通常“pull”和“push”应该成对出现，也就是你只应该使用“handshake”模式。\n然而不幸的是，当前（1.22）的go语言支持“pull-only”的用法，即可以随便拉取任何包里的任何函数/变量，但不需要被拉取的对象使用“push”标记自己。而被linkname拉取的一方是完全无感知的。\n这就导致了非常大的隐患。\nlinkname带来的隐患 最大的隐患在于这个指令可以在不通知被拉取的packages的情况下随意使用包中私有的函数/变量。\n举个例子：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 // pkg/mymath/mymath.go package mymath func uintPow(n uint) uint { return n*n } // main.go package main import ( \u0026#34;fmt\u0026#34; _ \u0026#34;linkname/pkg/mymath\u0026#34; _ \u0026#34;unsafe\u0026#34; ) //go:linkname pow linkname/pkg/mymath.uintPow func pow(n uint) uint func main() { fmt.Println(pow(6)) // 36 } 正常来说，uintPow是不可能被外部使用的，然而通过linkname指令我们直接无视了接口的公开和私有，有什么就能用什么了。\n这当然是非常危险的，比如我们把uintPow的参数类型改成string：\n1 2 3 4 5 package mymath func uintPow(n string) string { return n + n } 这时候编译还是能正常编译，但运行的时候就会出现各种bug，在我的机器上表现是卡死和段错误。为什么呢？因为我们把uint强行传递了过去，但参数需要是string，类型对不上，自然会出现稀奇古怪的bug。这种在别的语言里是严重的类型相关的内存错误。\n另外如果我们直接删了uintPow或者给他改个名，链接器会在编译期间报错：\n1 2 3 4 $ go build # linkname main.main: relocation target linkname/pkg/mymath.uintPow not defined 而且我们导出的是私有函数，通常没人会认为自己写的私有级别的帮助函数会被导出到包外并被使用，因此在开发时大家都是保证公开接口的稳定性，私有的函数/变量是随时可以被大规模修改甚至删除的。\n而linkname将这种在别的语言里最基本的规矩给粉碎了。\n而且事实上也是如此，从1.18开始几乎每个版本都有因为编译器或者标准库内部的私有函数被修改/删除从而导致某些第三方库在新版本无法使用的问题，因为这些库在内部悄悄用//go:linkname用了一些未公开的功能。最近一次发生在广泛使用的知名json库上类似的问题可以在这里看到。\nlinkname的正面作用 既然这个指令如此危险，为什么还一直存在呢？答案是有不得不用的理由，其中一个就在启动go程序的时候。\n我们来看下go的runtime里是怎么用linkname的：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 // runtime/proc.go //go:linkname main_main main.main func main_main() // runtime.main // 所有go程序的入口 func main() { // 初始化runtime // 调用main.main fn := main_main // make an indirect call, as the linker doesn\u0026#39;t know the address of the main package when laying down the runtime fn() // main退出后做清理工作 } 因为程序的入口在runtime里（要初始化runtime，比如gc等），所以入口函数必须在runtime包里。而我们又需要调用用户定义在main包里的main函数，但main包不能被import，因此只能靠linkname指令让链接器绕过所有编译器附加的限制来调用main函数。\n这是目前在go自身的源代码里看到的唯一一处不得不使用“pull-only”模式的地方。\n另外“handshake”模式也有存在的必要性，因为像runtime和reflect需要共享很多实现上的细节，因此reflect作为pull的一方，runtime作为push的一方，可以极大减少代码维护的复杂度。\n除了上述这些情况，绝大数linkname的使用都可以算作_abuse_。\ngolang1.23对linkname指令的改动 鉴于上述情况，golang核心团队决定限制linkname的使用。\n第一个改动是标准库里新添加的包全部禁止使用linkname导出其中的内容，目前是通过黑名单实现的，1.23中新添加的几个包以及它们的internal依赖都在名单上，这样可以防止已有的linkname问题继续扩大。这对已有的代码也是完全无害的。\n第二个变更时添加了新的ldflags: -checklinkname=1。1代表开启对linkname的限制，0代表维持1.22的行为不变。目前默认是0，但官方决定在1.23发布时默认值为1开启限制。个人建议尽量不要关闭这个限制。这个限制眼下只针对标准库，但按官方的说法效果好的话以后所有的代码不管标准库还是第三方都会启用限制。\n最后也是最大的变动，禁止对标准库的 “pull-only” linkname指令，但允许“handshake”模式。\n虽然go从来不保证linkname的向后兼容性，但这样还是会大量较大的破坏，因此官方已经对常见的go第三方库做了扫描，会把一些经常被人用linkname拉取的接口改成符合“handshake”模式的形式，这种改动只用加一行指令即可。而且该限制目前只针对标准库，其他第三方库暂时不受影响。\n因为这个变更，下面的代码在1.23是无法编译通过的：\n1 2 3 4 5 6 7 8 package main import _ \u0026#34;unsafe\u0026#34; //go:linkname corostart runtime.corostart func corostart() func main() { corostart() } 因为runtime.corostart并不符合handshake模式，所以对它的linkname被禁止了：\n1 2 3 4 5 $ go version go version devel go1.23-13d36a9b46 Wed May 27 21:51:49 2024 +0000 windows/amd64 $ go build -ldflags=-checklinkname=1 # linkname link: main: invalid reference to runtime.corostart linkname指令今后的发展 大趋势肯定是以后只允许handshake模式。不过作为过渡目前还是允许push模式的，并且官方应该会在进入功能冻结后把之前说的扫描到的常用的内部函数添加上linkname指令。\n这里比较重要的是作为开发者的我们应该怎么办：\n1.23发布之后或者现在就开始利用-checklinkname=1排查代码，及时清除不必要的linkname指令。 如果linkname指令非用不可，建议马上提issue或者熟悉go开发流程的立刻提pr补上handshake模式需要的指令，不过我不怎么推荐这种做法，因为内部api尤其是runtime以外的库的本来就不该随便被导出使用，没有一个强力的能说服所有人的理由，这些issue和pr多半不会被接受。 向官方提案，尝试把你要用的私有api变成公开接口，这一步难度也很高，私有api之所以当初不公开一定是有原因的，现在再想公开可能性也不高。 你的追求比较低，只要代码能跑就行，那可以在构建脚本里加上-ldflags=-checklinkname=0关闭限制，这样也许能岁月静好几个版本，直到某一天程序突然没法编译或者运行了一半被莫名其妙的panic打断。 4是万不得已时的保底方案，按优先度我推荐1 \u0026gt; 3 \u0026gt; 2的顺序去适配go1.23。2和3不仅仅适用于go标准库，常用的第三方库也可以。通过这些适配工作说不定也有机会让你成为go或者知名第三方库的贡献者。\n从现在开始完全是来得及的，毕竟离1.23的第一个测试版发布还有一个月左右，离正式版发布还有两个月。而且方案2的修改并不算作新功能，不受功能冻结的影响。\n当然，大部分开发者应该不用担心，比较linkname的使用是少数，一些主动使用linkname的库比如quic-go也知道兼容性问题，很小心地做了不同版本的适配，加上官方承诺的兜底这一对linkname指令的改动的影响应该比想象中小，但是是提高代码安全性的一大步。\n总结 最后总结就一句话：没事别用//go:linkname 可能会留下不可预知的隐患。\n","date":"2024-05-27T09:37:25+08:00","permalink":"https://huizhou92.com/zh-cn/p/%23-golang-1.23-changes-to-/golinkname-and-what-it-means-for-developers/","title":"Golang 1.23：`//go:linkname` 的变更及其对开发人员的意义"},{"content":"背景 gRPC是google开源的高性能跨语言的RPC方案。gRPC的设计目标是在任何环境下运行，支持可插拔的负载均衡，跟踪，运行状况检查和身份验证。它不仅支持数据中心内部和跨数据中心的服务调用，它也适用于分布式计算的最后一公里，将设备，移动应用程序和浏览器连接到后端服务。\n关于 GRPC设计的动机和原则 我们可以从这篇文章里面找到答案，gRPC Motivation and Design Principles\nThis article is first published in the medium MPP plan. If you are a medium user, please follow me in medium. Thank you very much.\n官方的文章令人印象深刻的点：\n内部有Stubby的框架，但是它不是基于任何一个标准的 支持任意环境使用，支持物联网、手机、浏览器 支持stream和流控 实际上：性能不是gRPC 设计的第一目标。那么为什么选择HTTP/2?\nHTTP/2是什么 在正式讨论gRPC为什么选择HTTP/2之前，我们先来简单了解下HTTP/2。\nHTTP/2可以简单用一个图片来介绍：\n来自：https://hpbn.co/\nHTTP/1里的header对应HTTP/2里的 HEADERS frame HTTP/1里的payload对应HTTP/2里的 DATA frame\n在Chrome浏览器里，打开chrome://net-internals/#http2，可以看到http2链接的信息。\n目前很多网站都已经跑在HTTP/2上了。\ngRPC Over HTTP/2 准确来说gRPC设计上是分层的，底层支持不同的协议，目前gRPC支持：\ngRPC over HTTP2 gRPC Web 但是大多数情况下，讨论都是基于gRPC over HTTP2。\n下面从一个真实的gRPC SayHello请求，查看它在HTTP/2上是怎样实现的。用Wireshark抓包：\n可以看到下面这些Header：\n1 2 3 4 5 6 Header: :authority: localhost:50051 Header: :path: /helloworld.Greeter/SayHello Header: :method: POST Header: :scheme: http Header: content-type: application/grpc Header: user-agent: grpc-java-netty/1.11.0 然后请求的参数在DATA frame里：\nGRPC Message: /helloworld.Greeter/SayHello, Request\n简而言之，gGRPC把元数据放到HTTP/2 Headers里，请求参数序列化之后放到 DATA frame里。\n基于HTTP/2 协议的优点 HTTP/2 是一个公开的标准 Google本身把这个事情想清楚了，它并没有把内部的Stubby开源，而是选择重新做。现在技术越来越开放，私有协议的空间越来越小。\nHTTP/2 是一个经过实践检验的标准 HTTP/2是先有实践再有标准，这个很重要。很多不成功的标准都是先有一大堆厂商讨论出标准后有实现，导致混乱而不可用，比如CORBA。HTTP/2的前身是Google的SPDY，没有Google的实践和推动，可能都不会有HTTP/2。\nHTTP/2 天然支持物联网、手机、浏览器 实际上先用上HTTP/2的也是手机和手机浏览器。移动互联网推动了HTTP/2的发展和普及。\n基于HTTP/2 多语言的实现容易 只讨论协议本身的实现，不考虑序列化。\n每个流行的编程语言都会有成熟的HTTP/2 Client HTTP/2 Client是经过充分测试，可靠的 用Client发送HTTP/2请求的难度远低于用socket发送数据包/解析数据包 HTTP/2支持Stream和流控 在业界，有很多支持stream的方案，比如基于websocket的，或者rsocket。但是这些方案都不是通用的。\nHTTP/2里的Stream还可以设置优先级，尽管在rpc里可能用的比较少，但是一些复杂的场景可能会用到。\n基于HTTP/2 在Gateway/Proxy很容易支持 nginx对gRPC的支持 envoy对gRPC的支持 HTTP/2 安全性有保证 HTTP/2 天然支持SSL，当然gRPC可以跑在clear text协议（即不加密）上。 很多私有协议的rpc可能自己包装了一层TLS支持，使用起来也非常复杂。开发者是否有足够的安全知识？使用者是否配置对了？运维者是否能正确理解？ HTTP/2 在公有网络上的传输上有保证。比如这个CRIME攻击，私有协议很难保证没有这样子的漏洞。 HTTP/2 鉴权成熟 从HTTP/1发展起来的鉴权系统已经很成熟了，可以无缝用在HTTP/2上 可以从前端到后端完全打通的鉴权，不需要做任何转换适配\n比如传统的rpc dubbo，需要写一个dubbo filter，还要考虑把鉴权相关的信息通过thread local传递进去。rpc协议本身也需要支持。总之，非常复杂。实际上绝大部分公司里的rpc都是没有鉴权的，可以随便调。 基于HTTP/2 的缺点 rpc的元数据的传输不够高效 尽管HPAC可以压缩HTTP Header，但是对于rpc来说，确定一个函数调用，可以简化为一个int，只要两端去协商过一次，后面直接查表就可以了，不需要像HPAC那样编码解码。\n可以考虑专门对gRPC做一个优化过的HTTP/2解析器，减少一些通用的处理，感觉可以提升性能。\nHTTP/2 里一次gRPC调用需要解码两次 一次是HEADERS frame，一次是DATA frame。\nHTTP/2 标准本身是只有一个TCP连接，但是实际在gRPC里是会有多个TCP连接，使用时需要注意。\ngRPC选择基于HTTP/2，那么它的性能肯定不会是最顶尖的。但是对于rpc来说中庸的qps可以接受，通用和兼容性才是最重要的事情。我们可以参考一下官方的benchmark：https://grpc.io/docs/guides/benchmarking.html\nhttps://github.com/hank-whu/rpc-benchmark\n如果您的场景是搞 Google制定标准的能力 近10年来，Google制定标准的能力越来越强。下面列举一些标准：\nHTTP/2 WebP图片格式 WebRTC 网页即时通信 VP9/AV1 视频编码标准 Service Worker/PWA QUIC/ HTTP/3\n当然google也并不都会成功，很多事情它想推也失败了，比如Chrome的Native Client。 gRPC目前是k8s生态里的事实标准。 gRPC是否会成为更多地方，更大领域的RPC标准？\n为什么会出现gRPC 准确来说为什么会出现基于HTTP/2的RPC？\n个人认为一个重要的原因是，在Cloud Native的潮流下，开放互通的需求必然会产生基于HTTP/2的RPC。即使没有gRPC，也会有其它基于HTTP/2的RPC。\ngRPC在Google的内部也是先用在Google Cloud Platform和公开的API上：https://opensource.google.com/projects/grpc\n总结 尽管gRPC它可能替换不了内部的RPC实现，但是在开放互通的时代，不止在k8s上，gRPC会有越来越多的舞台可以施展。\n参考资料 https://grpc.io/ https://hpbn.co/ https://grpc.io/blog/loadbalancing https://http2.github.io/faq https://github.com/grpc/grpc ","date":"2024-05-23T10:25:02+08:00","image":"https://huizhou92.com/cb553b8f542344f88169374915cb1819.png","permalink":"https://huizhou92.com/zh-cn/p/why-did-google-choose-to-implement-grpc-using-http2/","title":"为什么 Google 选择使用HTTP 2 实现 gRPC"},{"content":"摘要 wireshark 是一个 流行的抓取网络报文的工具,他不仅自己可以抓包，也可以解析tcpdump抓包的文件。\ngRPC 是Google开发的一个高性能RPC框架，基于HTTP/2协议+protobuf序列化协议.\n本文主要介绍如何使用wireshark抓取gRPC的报文，并解析报文内容。\nThis article is first published in the medium MPP plan. If you are a medium user, please follow me in medium. Thank you very much.\nWireshark version: 4.2.2\n配置 因为gRPC 是基于protobuf序列化协议，所以我们需要先添加protobuf的文件地址。\n点击 Wireshark -\u0026gt; Preferences\u0026hellip; -\u0026gt; Protocols -\u0026gt; Protobuf -\u0026gt; Protobuf search paths -\u0026gt; Edit\u0026hellip;\n点击+ 添加您要抓包的protobuf 文件路径，不要忘记勾选右边的 Load all files\n具体操作 首先我们写一个最简单的gRPC服务，\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 syntax = \u0026#34;proto3\u0026#34;; option go_package = \u0026#34;example.com/hxzhouh/go-example/grpc/helloworld/api\u0026#34;; package api; // The greeting service definition. service Greeter { // Sends a greeting rpc SayHello (HelloRequest) returns (HelloReply) {} } // The request message containing the user\u0026#39;s name. message HelloRequest { string name = 1; } // The response message containing the greetings message HelloReply { string message = 1; } 它仅仅就一个函数 Greeter ,补充完服务端代码，把它运行起来。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 type server struct { api.UnimplementedGreeterServer } func (s *server) SayHello(ctx context.Context, in *api.HelloRequest) (*api.HelloReply, error) { log.Printf(\u0026#34;Received: %v\u0026#34;, in.GetName()) return \u0026amp;api.HelloReply{Message: \u0026#34;Hello \u0026#34; + in.GetName()}, nil } func main() { lis, err := net.Listen(\u0026#34;tcp\u0026#34;, \u0026#34;:50051\u0026#34;) if err != nil { log.Fatalf(\u0026#34;failed to listen: %v\u0026#34;, err) } s := grpc.NewServer() api.RegisterGreeterServer(s, \u0026amp;server{}) if err := s.Serve(lis); err != nil { log.Fatalf(\u0026#34;failed to serve: %v\u0026#34;, err) } } 然后我们打开 wireshark ，选择本地网卡，监听 tcp.port == 50051\n如果您以前没接触过 wireshark，我建议您先看看这篇文章：https://www.lifewire.com/wireshark-tutorial-4143298\n一元函数 现在我们有一个gRPC 服务运行再本地的50051 端口， 我们可以使用BloomRPC 或者其他您任何喜欢的工具对服务端发起一个RPC请求,或者直接像我一样使用下面的代码\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 func Test_server_SayHello(t *testing.T) { // Set up a connection to the server. conn, err := grpc.Dial(\u0026#34;localhost:50051\u0026#34;, grpc.WithInsecure(), grpc.WithBlock()) if err != nil { log.Fatalf(\u0026#34;did not connect: %v\u0026#34;, err) } defer conn.Close() c := api.NewGreeterClient(conn) // Contact the server and print out its response. name := \u0026#34;Hello\u0026#34; ctx, cancel := context.WithTimeout(context.Background(), time.Second) defer cancel() r, err := c.SayHello(ctx, \u0026amp;api.HelloRequest{Name: name}) if err != nil { log.Fatalf(\u0026#34;could not greet: %v\u0026#34;, err) } log.Printf(\u0026#34;Greeting: %s\u0026#34;, r.GetMessage()) } 这个时候，wireshark 应该就能抓到流量包了。\n前面我们说过，gRPC = http2+protobuf, 并且我们前面已经加载了protobuf 文件，理论上我们现在已经能解析报文了。\n使用wireshark快捷键 shift+command+U 或者 用鼠标点击 Analyze -\u0026gt; Decode As... 然后设置一下将报文解析成HTTP2 格式。\n这个时候，我们就能很清晰的看到这个请求了\nmetadata 我们知道 gRPC 的metadata 是通过 http2 的header 来传递的。 现在我们通过抓包来验证一下。\n稍微改造一下客户端代码\n1 2 3 4 5 6 7 8 9 10 11 12 func Test_server_SayHello(t *testing.T) { // Set up a connection to the server. ..... // add md md := map[string][]string{\u0026#34;timestamp\u0026#34;: {time.Now().Format(time.Stamp)}} md[\u0026#34;testmd\u0026#34;] = []string{\u0026#34;testmd\u0026#34;} ctx := metadata.NewOutgoingContext(context.Background(), md) // Contact the server and print out its response. name := \u0026#34;Hello\u0026#34; ctx, cancel := context.WithTimeout(ctx, time.Second) .... } 然后重新抓包。 我们就能看到 md 确实放在 header 里面。\n并且我们还在header 看到了grpc-timeout 可见请求超时操作也是房子啊header 里面的。里面涉及的具体细节，我可能会出一篇专门的文章来说明，今天我们只关注抓包。\nTLS 上面使用的例子都是明文 传输的 我们再Dial 的时候使用了 grpc.WithInsecure() ,但是在生产环境中，我们一般使用TLS 对进行加密传输。具体的细节可以参考我以前写的文章。\nhttps://medium.com/gitconnected/secure-communication-with-grpc-from-ssl-tls-certification-to-san-certification-d9464c3d706f\n我们改造一下 服务端代码\nhttps://gist.github.com/hxzhouh/e08546cf0457d28a614d59ec28870b11\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 func main() { certificate, err := tls.LoadX509KeyPair(\u0026#34;./keys/server.crt\u0026#34;, \u0026#34;./keys/server.key\u0026#34;) if err != nil { log.Fatalf(\u0026#34;Failed to load key pair: %v\u0026#34;, err) } certPool := x509.NewCertPool() ca, err := os.ReadFile(\u0026#34;./keys/ca.crt\u0026#34;) if err != nil { log.Fatalf(\u0026#34;Failed to read ca: %v\u0026#34;, err) } if ok := certPool.AppendCertsFromPEM(ca); !ok { log.Fatalf(\u0026#34;Failed to append ca certificate\u0026#34;) } opts := []grpc.ServerOption{ grpc.Creds( // 为所有传入的连接启用TLS credentials.NewTLS(\u0026amp;tls.Config{ ClientAuth: tls.RequireAndVerifyClientCert, Certificates: []tls.Certificate{certificate}, ClientCAs: certPool, }, )), } listen, err := net.Listen(\u0026#34;tcp\u0026#34;, fmt.Sprintf(\u0026#34;0.0.0.0:%d\u0026#34;, 50051)) if err != nil { log.Fatalf(\u0026#34;failed to listen %d port\u0026#34;, 50051) } // 通过传入的TLS服务器凭证创建新的gRPC服务实例 s := grpc.NewServer(opts...) api.RegisterGreeterServer(s, \u0026amp;server{}) log.Printf(\u0026#34;server listening at %v\u0026#34;, listen.Addr()) if err := s.Serve(listen); err != nil { log.Fatalf(\u0026#34;Failed to serve: %v\u0026#34;, err) } } client\nhttps://gist.github.com/hxzhouh/46a7a31e2696b87fe6fb83c8ce7e036c\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 func Test_server_SayHello(t *testing.T) { certificate, err := tls.LoadX509KeyPair(\u0026#34;./keys/client.crt\u0026#34;, \u0026#34;./keys/client.key\u0026#34;) if err != nil { log.Fatalf(\u0026#34;Failed to load client key pair, %v\u0026#34;, err) } certPool := x509.NewCertPool() ca, err := os.ReadFile(\u0026#34;./keys/ca.crt\u0026#34;) if err != nil { log.Fatalf(\u0026#34;Failed to read %s, error: %v\u0026#34;, \u0026#34;./keys/ca.crt\u0026#34;, err) } if ok := certPool.AppendCertsFromPEM(ca); !ok { log.Fatalf(\u0026#34;Failed to append ca certs\u0026#34;) } opts := []grpc.DialOption{ grpc.WithTransportCredentials(credentials.NewTLS( \u0026amp;tls.Config{ ServerName: \u0026#34;localhost\u0026#34;, Certificates: []tls.Certificate{certificate}, RootCAs: certPool, })), } // conn, err := grpc.Dial(*addr, grpc.WithTransportCredentials(insecure.NewCredentials())) conn, err := grpc.Dial(\u0026#34;localhost:50051\u0026#34;, opts...) if err != nil { log.Fatalf(\u0026#34;Connect to %s failed\u0026#34;, \u0026#34;localhost:50051\u0026#34;) } defer conn.Close() client := api.NewGreeterClient(conn) ctx, cancel := context.WithTimeout(context.Background(), time.Second*5) defer cancel() r, err := client.SayHello(ctx, \u0026amp;api.HelloRequest{Name: \u0026#34;Hello\u0026#34;}) if err != nil { log.Printf(\u0026#34;Failed to greet, error: %v\u0026#34;, err) } else { log.Printf(\u0026#34;Greeting: %v\u0026#34;, r.GetMessage()) } } 这个时候我们再抓包，然后使用相同的方式解析。但是，我们会发现，使用HTTP2 已经无法解密了，但是可以解码成 TLS1.3\n总结 这篇文章，首先总结了使用 Wireshark 抓gRPC 包的一个基本流程。\n然后我们通过抓包知道了gRPC的参数传递是通过 HTTP2 的data-frame，CTX 等meta 是通过 header 传递的。这些知识我们以前肯定听过，但是只有动手实验才能加深理解。\n通过TLS 我们可以实现 安全的gRPC 通信，下一篇文章，我们将尝试解密TLS 报文。\n参考资料 Wireshark Tutorial https://grpc.io/blog/wireshark/ https://www.lifewire.com/wireshark-tutorial-4143298 ","date":"2024-05-19T21:36:25Z","image":"https://images.hxzhouh.com/blog-images/2024/05/a8ca43282aece789e1e0b1d2a2db7a5f.png","permalink":"https://huizhou92.com/zh-cn/p/how-to-capture-and-analyze-grpc-packets/","title":"使用 wireshark 抓包GRPC"},{"content":"gRPC 一般不在 message 中定义错误。\n毕竟每个 gRPC 服务本身就带一个 error 的返回值，这是用来传输错误的专用通道。\ngRPC 中所有的错误返回都应该是 nil 或者 由 status.Status 产生的一个error。这样error可以直接被调用方Client识别。\nThis article is first published in the medium MPP plan. If you are a medium user, please follow me in medium. Thank you very much.\n1. 常规用法 当遇到一个go错误的时候，直接返回是无法被下游client识别的。\n恰当的做法是：\n调用 status.New 方法，并传入一个适当的错误码，生成一个 status.Status 对象 调用该 status.Err 方法生成一个能被调用方识别的error，然后返回 1 2 st := status.New(codes.NotFound, \u0026#34;some description\u0026#34;) err := st.Err() 传入的错误码是 codes.Code 类型。\n此外还有更便捷的办法：使用 status.Error。它避免了手动转换的操作。\n1 err := status.Error(codes.NotFound, \u0026#34;some description\u0026#34;) 2. 进阶用法 上面的错误有个问题，就是 code.Code 定义的错误码只有固定的几种，无法详尽地表达业务中遇到的错误场景。\ngRPC 提供了在错误中补充信息的机制：status.WithDetails 方法\nClient 通过将 error 重新转换位 status.Status ，就可以通过 status.Details 方法直接获取其中的内容。\nstatus.Details 返回的是个slice， 是interface{}的slice，然而go已经自动做了类型转换，可以通过断言直接使用。\n服务端示例服务端示例 生成一个 status.Status 对象 填充错误的补充信息 // 生成一个 status.Status\n1 2 3 4 5 6 7 8 9 10 11 12 func ErrorWithDetails() error { st := status.Newf(codes.Internal, fmt.Sprintf(\u0026#34;something went wrong: %v\u0026#34;, \u0026#34;api.Getter\u0026#34;)) v := \u0026amp;errdetails.PreconditionFailure_Violation{ //errDetails Type: \u0026#34;test\u0026#34;, Subject: \u0026#34;12\u0026#34;, Description: \u0026#34;32\u0026#34;, } br := \u0026amp;errdetails.PreconditionFailure{} br.Violations = append(br.Violations, v) st, _ = st.WithDetails(br) return st.Err() } 客户端的示例 调用RPC错误后，解析错误信息 通过断言直接获取错误详情 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 resp, err := odinApp.CreatePlan(cli.StaffId.AssetId, gentRatePlanMeta(cli.StaffId)) ​ if status.Code(err) != codes.InvalidArgument { logger.Error(\u0026#34;create plan error:%v\u0026#34;, err) } else { for _, d := range status.Convert(err).Details() { // switch info := d.(type) { case *errdetails.QuotaFailure: logger.Info(\u0026#34;Quota failure: %s\u0026#34;, info) case *errdetails.PreconditionFailure: detail := d.(*errdetails.PreconditionFailure).Violations for _, v1 := range detail { logger.Info(fmt.Sprintf(\u0026#34;details: %+v\u0026#34;, v1)) } case *errdetails.ResourceInfo: logger.Info(\u0026#34;ResourceInfo: %s\u0026#34;, info) ​ case *errdetails.BadRequest: logger.Info(\u0026#34;ResourceInfo: %s\u0026#34;, info) ​ default: logger.Info(\u0026#34;Unexpected type: %s\u0026#34;, info) } } } logger.Infof(\u0026#34;create plan success,resp=%v\u0026#34;, resp) 原理 这个错误是如何传递给调用方Client的呢？\n是放到 metadata中的，而metadata是放到HTTP的header中的。\nmetadata是key：value格式的数据。错误的传递中，key是个固定值：grpc-status-details-bin。\n而value，是被proto编码过的，是二进制安全的。\n目前大多数语言都实现了这个机制。\n注意 gRPC对响应头做了限制，上限为8K，所以错误不能太大。\n参考资料\nhttps://protobuf.dev/getting-started/gotutorial/\nhttps://pkg.go.dev/google.golang.org/genproto/googleapis/rpc/errdetails ","date":"2024-05-14T16:10:00Z","permalink":"https://huizhou92.com/zh-cn/p/go-action-error-handling-in-grpc/","title":"gRPC中的错误处理"},{"content":"我最近几年一直再打造自己的第二大脑，下面是我的几个经验教训。\n频繁切换笔记软件/博客系统 我先后使用过 EverNote，WizNote，VNote，CSDN blog，Google blogspot, WordPress，最终只造成博客散落在多个互联网角落。解决办法就是 all in one 。我现在选择的是Obsidian\n频繁切换笔记格式 我先后使用过 txt, orgmode, markdown，富文本等多种格式，最终只造成各种格式转换烦恼，跟第一条一样，每个笔记系统的格式可能不通用，选择Obsidian的原因就是它的markdown语法。如果我需要，我可以轻易的将它迁移到任何笔记系统，\n闪念笔记和真正有用的笔记混杂 闪念笔记用于快速捕捉一瞬间的灵感，但只有你在一两天内回顾它并把它变成有用的合适的笔记才有意义。如果不及时回顾，好的想法将淹没在大量的突发奇想中。我们每天大多数的想法没有太大意义应该被丢弃，而那些可以成为重大有意义的想法我们必须将他们识别出来。\n项目笔记和知识笔记混杂 只记录特定项目相关的笔记，将导致项目期间有趣的观点或者想法信息丢失。正确的做法是在项目中提取通用的知识。我推荐使用P.A.R.A 方法来整理笔记，有关P.A.R.A 您可以参考 这个网页\n频繁整理笔记的「洁癖」 大量堆积的笔记将造成知识整理冲动，多来几次就会影响坚持记录的信心。解决方法是，确定自己关注的领域和负责的责任范围，并不完全采用自下而上的知识管理方法。在达到心理挤压点时，使用 MOCS（Maps of Content）的方法整理笔记（双链绝对是你值得尝试的。）。知识管理系统最重要的是在同一个地方，用同样的格式和一致的标准记录你的洞见。\n","date":"2024-05-06T10:19:00+08:00","image":"https://images.hxzhouh.com/blog-images/2024/05/5ab6b54893dc2241704444526269572a.jpg","permalink":"https://huizhou92.com/zh-cn/p/crafting-your-second-brain-lessons-learned-from-my-note-taking-journey/","title":"知识管理的几个误区"},{"content":"进程是操作系统的伟大发明之一，对应用程序屏蔽了CPU调度、内存管理等硬件细节，而抽象出一个进程的概念，让应用程序专心于实现自己的业务逻辑既可，而且在有限的CPU上可以“同时”进行许多个任务。但是它为用户带来方便的同时，也引入了一些额外的开销。如下图，在进程运行中间的时间里，虽然CPU也在忙于干活，但是却没有完成任何的用户工作，这就是进程机制带来的额外开销。\n在进程A切换到进程B的过程中，先保存A进程的上下文，以便于等A恢复运行的时候，能够知道A进程的下一条指令是啥。然后将要运行的B进程的上下文恢复到寄存器中。这个过程被称为上下文切换。上下文切换开销在进程不多、切换不频繁的应用场景下问题不大。但是现在Linux操作系统被用到了高并发的网络程序后端服务器。在单机支持成千上万个用户请求的时候，这个开销就得拿出来说道说道了。因为用户进程在请求Redis、Mysql数据等网络IO阻塞掉的时候，或者在进程时间片到了，都会引发上下文切换。\n一个简单的进程上下文切换开销测试实验 废话不多说，我们先用个实验测试一下，到底一次上下文切换需要多长的CPU时间！实验方法是创建两个进程并在它们之间传送一个令牌。其中一个进程在读取令牌时就会引起阻塞。另一个进程发送令牌后等待其返回时也处于阻塞状态。如此往返传送一定的次数，然后统计他们的平均单次切换时间开销。\ntest04\n1 2 3 4 # gcc main.c -o main # ./main./main Before Context Switch Time1565352257 s, 774767 us After Context SWitch Time1565352257 s, 842852 us 每次执行的时间会有差异，多次运行后平均每次上下文切换耗时3.5us左右。当然了这个数字因机器而异，而且建议在实机上测试。\n前面我们测试系统调用的时候，最低值是200ns。可见，上下文切换开销要比系统调用的开销要大。系统调用只是在进程内将用户态切换到内核态，然后再切回来，而上下文切换可是直接从进程A切换到了进程B。显然这个上下文切换需要完成的工作量更大。\n进程上下文切换开销都有哪些 那么上下文切换的时候，CPU的开销都具体有哪些呢？开销分成两种，一种是直接开销、一种是间接开销。\n直接开销就是在切换时，cpu必须做的事情，包括：\n1、==切换页表全局目录== 2、==切换内核态堆栈== 3、==切换硬件上下文==（进程恢复前，必须装入寄存器的数据统称为硬件上下文） ip(instruction pointer)：指向当前执行指令的下一条指令 bp(base pointer): 用于存放执行中的函数对应的栈帧的栈底地址 sp(stack poinger): 用于存放执行中的函数对应的栈帧的栈顶地址 cr3:页目录基址寄存器，保存页目录表的物理地址 \u0026hellip;\u0026hellip; 4、刷新TLB 5、系统调度器的代码执行 间接开销主要指的是虽然切换到一个新进程后，==由于各种缓存并不热，速度运行会慢一些==。如果进程始终都在一个CPU上调度还好一些，如果跨CPU的话，之前热起来的TLB、L1、L2、L3因为运行的进程已经变了，所以以局部性原理cache起来的代码、数据也都没有用了，导致新进程穿透到内存的IO会变多。 其实我们上面的实验并没有很好地测量到这种情况，所以实际的上下文切换开销可能比3.5us要大。\n想了解更详细操作过程的同学请参考《深入理解Linux内核》中的第三章和第九章。\n一个更为专业的测试工具-lmbench lmbench用于评价系统综合性能的多平台开源benchmark，能够测试包括文档读写、内存操作、进程创建销毁开销、网络等性能。使用方法简单，但就是跑有点慢，感兴趣的同学可以自己试一试。\n这个工具的优势是是进行了多组实验，每组2个进程、8个、16个。每个进程使用的数据大小也在变，充分模拟cache miss造成的影响。我用他测了一下结果如下：\n1 2 3 4 5 ------------------------------------------------------------------------- Host OS 2p/0K 2p/16K 2p/64K 8p/16K 8p/64K 16p/16K 16p/64K ctxsw ctxsw ctxsw ctxsw ctxsw ctxsw ctxsw --------- ------------- ------ ------ ------ ------ ------ ------- ------- bjzw_46_7 Linux 2.6.32- 2.7800 2.7800 2.7000 4.3800 4.0400 4.75000 5.48000 lmbench显示的进程上下文切换耗时从2.7us到5.48之间。\n线程上下文切换耗时 前面我们测试了进程上下文切换的开销，我们再继续在Linux测试一下线程。看看究竟比进程能不能快一些，快的话能快多少。\n在Linux下其实本并没有线程，只是为了迎合开发者口味，搞了个轻量级进程出来就叫做了线程。轻量级进程和进程一样，都有自己独立的task_struct进程描述符，也都有自己独立的pid。从操作系统视角看，调度上和进程没有什么区别，都是在等待队列的双向链表里选择一个task_struct切到运行态而已。只不过轻量级进程和普通进程的区别是可以共享同一内存地址空间、代码段、全局变量、同一打开文件集合而已。\n同一进程下的线程之所有getpid()看到的pid是一样的，其实task_struct里还有一个tgid字段。 对于多线程程序来说，getpid()系统调用获取的实际上是这个tgid，因此隶属同一进程的多线程看起来PID相同。\n我们用一个实验来测试一下test06。其原理和进程测试差不多，创建了20个线程，在线程之间通过管道来传递信号。接到信号就唤醒，然后再传递信号给下一个线程，自己睡眠。 这个实验里单独考虑了给管道传递信号的额外开销，并在第一步就统计了出来。\n1 2 3 # gcc -lpthread main.c -o main 0.508250 4.363495 每次实验结果会有一些差异，上面的结果是取了多次的结果之后然后平均的，大约每次线程切换开销大约是3.8us左右。从上下文切换的耗时上来看，Linux线程（轻量级进程）其实和进程差别不太大。\nLinux相关命令 既然我们知道了上下文切换比较的消耗CPU时间，那么我们通过什么工具可以查看一下Linux里究竟在发生多少切换呢？如果上下文切换已经影响到了系统整体性能，我们有没有办法把有问题的进程揪出来，并把它优化掉呢？\n1 2 3 4 5 6 7 8 # vmstat 1 procs -----------memory---------- ---swap-- -----io---- --system-- -----cpu----- r b swpd free buff cache si so bi bo in cs us sy id wa st 2 0 0 595504 5724 190884 0 0 295 297 0 0 14 6 75 0 4 5 0 0 593016 5732 193288 0 0 0 92 19889 29104 20 6 67 0 7 3 0 0 591292 5732 195476 0 0 0 0 20151 28487 20 6 66 0 8 4 0 0 589296 5732 196800 0 0 116 384 19326 27693 20 7 67 0 7 4 0 0 586956 5740 199496 0 0 216 24 18321 24018 22 8 62 0 8 或者是\n1 2 3 4 5 6 7 8 9 10 11 12 13 # sar -w 1 proc/s Total number of tasks created per second. cswch/s Total number of context switches per second. 11:19:20 AM proc/s cswch/s 11:19:21 AM 110.28 23468.22 11:19:22 AM 128.85 33910.58 11:19:23 AM 47.52 40733.66 11:19:24 AM 35.85 30972.64 11:19:25 AM 47.62 24951.43 11:19:26 AM 47.52 42950.50 ...... 上图的环境是一台生产环境机器，配置是8核8G的KVM虚机，环境是在nginx+fpm的，fpm数量为1000，平均每秒处理的用户接口请求大约100左右。其中cs列表示的就是在1s内系统发生的上下文切换次数，大约1s切换次数都达到4W次了。粗略估算一下，每核大约每秒需要切换5K次，则1s内需要花将近20ms在上下文切换上。要知道这是虚机，本身在虚拟化上还会有一些额外开销，而且还要真正消耗CPU在用户接口逻辑处理、系统调用内核逻辑处理、以及网络连接的处理以及软中断，所以20ms的开销实际上不低了。\n那么进一步，我们看下到底是哪些进程导致了频繁的上下文切换？\n1 2 3 4 5 6 # pidstat -w 1 11:07:56 AM PID cswch/s nvcswch/s Command 11:07:56 AM 32316 4.00 0.00 php-fpm 11:07:56 AM 32508 160.00 34.00 php-fpm 11:07:56 AM 32726 131.00 8.00 php-fpm ...... 由于fpm是同步阻塞的模式，每当请求Redis、Memcache、Mysql的时候就会阻塞导致cswch/s自愿上下文切换，而只有时间片到了之后才会触发nvcswch/s非自愿切换。可见fpm进程大部分的切换都是自愿的、非自愿的比较少。\n如果想查看具体某个进程的上下文切换总情况，可以在/proc接口下直接看，不过这个是总值。\n1 2 3 grep ctxt /proc/32583/status voluntary_ctxt_switches: 573066 nonvoluntary_ctxt_switches: 89260 结论 上下文切换具体做哪些事情我们没有必要记，只需要记住一个结论既可，在我的工作机上下文切换的开销大约是2.7-5.48us左右，你自己的机器可以用我提供的代码或工具进行一番测试。 可以使用 vmstat sar 等工具查看进程的上下文切换，进而定位性能问题。 lmbench相对更准确一些，因为考虑了切换后Cache miss导致的额外开销。 ","date":"2024-03-19T18:45:00Z","permalink":"https://huizhou92.com/zh-cn/p/the-time-in-the-computers-context-switching/","title":"计算机中的时间 线程上下文切换会用掉你多少CPU？"},{"content":"\ngRPC 是Google开发的一个高性能RPC框架，gRPC 默认内置了两种认证方式：\nSSL/TLS 认证方式 基于 Token 的认证方式\n没有启用证书的gRPC服务和客户端进行的是明文通信，信息面临被任何第三方监听的风险。为了保证gRPC通信不被第三方监听、篡改或伪造，可以对服务器启动TLS加密特性。\n从 go 1.15 版本开始废弃 CommonName，因此推荐使用 SAN 证书。如果按照之前的步骤通过 OpenSSL 来生成密钥、CSR、证书，会出现这样的错误： 1 rpc error: code = Unavailable desc = connection error: desc = \u0026#34;transport: authentication handshake failed: x509: certificate relies on legacy Common Name field, use SANs instead\u0026#34;| 什么是SAN SAN(Subject Alternative Name) 是 SSL 标准 x509 中定义的一个扩展。使用了 SAN 字段的 SSL 证书，可以扩展此证书支持的域名，使得一个证书可以支持多个不同域名的解析。\n通俗点就是，在 SAN 证书中，可以有多个完整的 CN（CommonName），这样只需要购买一个证书就可以用在多个 URL。比如 skype.com 的证书，它就有很多 SAN。\n在本地创建SAN 证书 下面 我们将用一个例子在本地生成 客户端\u0026amp;服务端双向SAN 证书。\n假设gRPC服务端的主机名为localhost，需要为gRPC服务端和客户端之间的通信配置tls双向认证加密。\n新建 openssl.conf 来放相关信息 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 [req] req_extensions = v3_req distinguished_name = req_distinguished_name prompt = no [req_distinguished_name] countryName = CN stateOrProvinceName = state localityName = city organizationName = huizhou92 commonName = hello-world [v3_req] subjectAltName = @alt_names [alt_names] DNS.1 = localhost 其中内容 跟 以前创建ca的时候差不多。\n2. 生成ca根证书\n1 openssl req -x509 -newkey rsa:4096 -keyout ca.key -out ca.crt -subj \u0026#34;/CN=localhost\u0026#34; -days 3650 -nodes -nodes 是忽略密码,方便使用，但是请注意，这可能会降低私钥的安全性，因为任何人都可以读取未加密的私钥。\n3. 生成服务端证书\n1 2 openssl req -newkey rsa:2048 -nodes -keyout server.key -out server.csr -subj \u0026#34;/CN=localhost\u0026#34; -config openssl.cnf openssl x509 -req -in server.csr -out server.crt -CA ca.crt -CAkey ca.key -CAcreateserial -days 365 -extensions v3_req -extfile openssl.cnf 生成客户端证书 1 2 3 openssl req -newkey rsa:2048 -nodes -keyout client.key -out client.csr -subj \u0026#34;/CN=localhost\u0026#34; -config openssl.cnf openssl x509 -req -in client.csr -out client.crt -CA ca.crt -CAkey ca.key -CAcreateserial -days 365 -extensions v3_req -extfile openssl.cnf 最终生成的结果如下\n1 2 ➜ keys git:(day1) ✗ ls ca.crt ca.key ca.srl client.crt client.csr client.key openssl.cnf server.crt server.csr server.key 测试 我们定义一个最简单的grpc接口\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 // helloworld.proto syntax = \u0026#34;proto3\u0026#34;; option go_package = \u0026#34;./api;api\u0026#34;; package api; // The greeting service definition. service Greeter { // Sends a greeting rpc SayHello (HelloRequest) returns (HelloReply) {} } // The request message containing the user\u0026#39;s name. message HelloRequest { string name = 1; } // The response message containing the greetings message HelloReply { string message = 1; } 服务端实现 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 package main import ( \u0026#34;context\u0026#34; \u0026#34;crypto/tls\u0026#34; \u0026#34;crypto/x509\u0026#34; \u0026#34;fmt\u0026#34; \u0026#34;google.golang.org/genproto/googleapis/rpc/errdetails\u0026#34; \u0026#34;google.golang.org/grpc\u0026#34; \u0026#34;google.golang.org/grpc/codes\u0026#34; \u0026#34;google.golang.org/grpc/credentials\u0026#34; \u0026#34;google.golang.org/grpc/status\u0026#34; \u0026#34;hello-world/api\u0026#34; \u0026#34;io\u0026#34; \u0026#34;log\u0026#34; \u0026#34;net\u0026#34; \u0026#34;os\u0026#34; \u0026#34;time\u0026#34; ) type server struct { api.UnimplementedGreeterServer } func (s *server) SayHello(ctx context.Context, in *api.HelloRequest) (*api.HelloReply, error) { log.Printf(\u0026#34;Received: %v\u0026#34;, in.GetName()) select { case \u0026lt;-ctx.Done(): log.Println(\u0026#34;client timeout return\u0026#34;) return nil, ErrorWithDetails() case \u0026lt;-time.After(3 * time.Second): return \u0026amp;api.HelloReply{Message: \u0026#34;Hello \u0026#34; + in.GetName()}, nil } } func main() { certificate, err := tls.LoadX509KeyPair(\u0026#34;./keys/server.crt\u0026#34;, \u0026#34;./keys/server.key\u0026#34;) if err != nil { log.Fatalf(\u0026#34;Failed to load key pair: %v\u0026#34;, err) } // 通过CA创建证书池 certPool := x509.NewCertPool() ca, err := os.ReadFile(\u0026#34;./keys/ca.crt\u0026#34;) if err != nil { log.Fatalf(\u0026#34;Failed to read ca: %v\u0026#34;, err) } // 将来自CA的客户端证书附加到证书池 if ok := certPool.AppendCertsFromPEM(ca); !ok { log.Fatalf(\u0026#34;Failed to append ca certificate\u0026#34;) } opts := []grpc.ServerOption{ grpc.Creds( // 为所有传入的连接启用TLS credentials.NewTLS(\u0026amp;tls.Config{ ClientAuth: tls.RequireAndVerifyClientCert, Certificates: []tls.Certificate{certificate}, ClientCAs: certPool, }, )), } listen, err := net.Listen(\u0026#34;tcp\u0026#34;, fmt.Sprintf(\u0026#34;0.0.0.0:%d\u0026#34;, 50051)) if err != nil { log.Fatalf(\u0026#34;failed to listen %d port\u0026#34;, 50051) } // 通过传入的TLS服务器凭证创建新的gRPC服务实例 s := grpc.NewServer(opts...) api.RegisterGreeterServer(s, \u0026amp;server{}) log.Printf(\u0026#34;server listening at %v\u0026#34;, listen.Addr()) if err := s.Serve(listen); err != nil { log.Fatalf(\u0026#34;Failed to serve: %v\u0026#34;, err) } } func ErrorWithDetails() error { st := status.Newf(codes.Internal, fmt.Sprintf(\u0026#34;something went wrong: %v\u0026#34;, \u0026#34;api.Getter\u0026#34;)) v := \u0026amp;errdetails.PreconditionFailure_Violation{ //errDetails Type: \u0026#34;test\u0026#34;, Subject: \u0026#34;12\u0026#34;, Description: \u0026#34;32\u0026#34;, } br := \u0026amp;errdetails.PreconditionFailure{} br.Violations = append(br.Violations, v) st, _ = st.WithDetails(br) return st.Err() } 我们直接运行服务端 go run main.go\n客户端 首先我们使用一个不带证书的请求\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 func Test_server_SayHello_No_Cert(t *testing.T) { conn, err := grpc.Dial(\u0026#34;localhost:50051\u0026#34;, grpc.WithTransportCredentials(insecure.NewCredentials())) if err != nil { log.Fatalf(\u0026#34;Connect to %s failed\u0026#34;, \u0026#34;localhost:50051\u0026#34;) } defer conn.Close() client := api.NewGreeterClient(conn) // 创建带有超时时间的上下文, cancel可以取消上下文 ctx, cancel := context.WithTimeout(context.Background(), time.Second*5) defer cancel() // 业务代码处理部分 ... r, err := client.SayHello(ctx, \u0026amp;api.HelloRequest{Name: \u0026#34;Hello\u0026#34;}) if err != nil { log.Printf(\u0026#34;Failed to greet, error: %v\u0026#34;, err) } else { log.Printf(\u0026#34;Greeting: %v\u0026#34;, r.GetMessage()) } // Set up a connection to the server. log.Printf(\u0026#34;Greeting: %s\u0026#34;, r.GetMessage()) } 输出\n1 2024/05/12 19:18:51 Failed to greet, error: rpc error: code = Unavailable desc = connection error: desc = \u0026#34;error reading server preface: EOF\u0026#34; 服务不可用\n我们再使用一个携带证书的请请求\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 func Test_server_SayHello(t *testing.T) { certificate, err := tls.LoadX509KeyPair(\u0026#34;./keys/client.crt\u0026#34;, \u0026#34;./keys/client.key\u0026#34;) if err != nil { log.Fatalf(\u0026#34;Failed to load client key pair, %v\u0026#34;, err) } certPool := x509.NewCertPool() ca, err := os.ReadFile(\u0026#34;./keys/ca.crt\u0026#34;) if err != nil { log.Fatalf(\u0026#34;Failed to read %s, error: %v\u0026#34;, \u0026#34;./keys/ca.crt\u0026#34;, err) } if ok := certPool.AppendCertsFromPEM(ca); !ok { log.Fatalf(\u0026#34;Failed to append ca certs\u0026#34;) } opts := []grpc.DialOption{ grpc.WithTransportCredentials(credentials.NewTLS( \u0026amp;tls.Config{ ServerName: \u0026#34;localhost\u0026#34;, Certificates: []tls.Certificate{certificate}, RootCAs: certPool, })), } // conn, err := grpc.Dial(*addr, grpc.WithTransportCredentials(insecure.NewCredentials())) conn, err := grpc.Dial(\u0026#34;localhost:50051\u0026#34;, opts...) if err != nil { log.Fatalf(\u0026#34;Connect to %s failed\u0026#34;, \u0026#34;localhost:50051\u0026#34;) } defer conn.Close() client := api.NewGreeterClient(conn) // 创建带有超时时间的上下文, cancel可以取消上下文 ctx, cancel := context.WithTimeout(context.Background(), time.Second*5) defer cancel() // 业务代码处理部分 ... r, err := client.SayHello(ctx, \u0026amp;api.HelloRequest{Name: \u0026#34;Hello\u0026#34;}) if err != nil { log.Printf(\u0026#34;Failed to greet, error: %v\u0026#34;, err) } else { log.Printf(\u0026#34;Greeting: %v\u0026#34;, r.GetMessage()) } // Set up a connection to the server. log.Printf(\u0026#34;Greeting: %s\u0026#34;, r.GetMessage()) } 输出\n1 2 === RUN Test_server_SayHello 2024/05/12 19:20:17 Greeting: Hello Hello 总结\n我们可以使用tls实现gRPC 的加密通信， 从go1.15 开始，go不建议使用CA而是使用SAN证书 ","date":"0001-01-01T00:00:00Z","permalink":"https://huizhou92.com/zh-cn/p/","title":""}]