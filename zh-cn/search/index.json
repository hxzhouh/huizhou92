[{"content":"昨天涛叔的博客 发布了一篇关于友情链接的博客，我毛遂自荐向涛叔请求添加友情链接。涛叔很快回应了我，并且在邮件中友好的提醒我，可以给博客添加一个favicon(icon)，这样方便RSS订阅用户快速的区分博客。当时我心想 favicon 是什么？（后端程序员伤不起）\n后面我咨询了DeepSeek:\n在网页设计中，图标（icon）是一个小而重要的元素。它不仅帮助用户快速识别网站，还能提升用户体验。\n常见使用场景： 浏览器标签页：显示在网页标题旁边。 书签栏：用户收藏网页时显示。 主屏幕图标：移动设备将网页添加到主屏幕时显示。 PWA（渐进式网页应用）：作为应用图标使用。\n比如这样\n在浏览器标签页展示图标。\n在书签栏显示图标。 甚至在安卓手机 上，使用chrome浏览器的将网页添加到主屏幕功能。可以显示icon图标。\n如何设置 设置icon 最简单的方式是在 网页的 \u0026lt;head\u0026gt; 中添加 一行。\n1 \u0026lt;link rel=\u0026#34;icon\u0026#34; type=\u0026#34;image/png\u0026#34; href=\u0026#34;/favicon.png\u0026#34;\u0026gt; 如果您是使用 hugo 或者其他工具的话，可能会有favicon的设置。\n一些大型网站 比如 google.com、 apple.com 它们可能需要考虑的问题更多，设置也并不完全一样。\n一些需要注意的地方 为了优化使用体验，在各个场景下都达到最佳的显示效果， icon的的尺寸也是有说法。\n常见尺寸： 16x16：浏览器标签页图标。 32x32：书签栏图标。 64x64：高分辨率屏幕图标。 180x180：iOS 设备主屏幕图标。 192x192 和 512x512：PWA 图标。\n所以我们在一些网站上会看到设置多个icon 的现象。比如 Hugo官网 现代浏览器都支持根据不同的场景，屏幕的PPI 选择不同尺寸的图标，尽量做到所有场景下都达到最好的显示效果。\n图标格式的选择 icon 可以使用不同的图片格式，通过 type指定即可，常见的图标格式包括：\nICO：传统格式，兼容性好，支持多尺寸。 PNG：现代格式，支持透明背景，适合高分辨率屏幕。 SVG：矢量格式，无限缩放不失真，适合响应式设计。 多合一 Icon 如果觉得需要维护多个 icon 文件 比较麻烦的话，可以使用多合一icon（Multi-Resolution ICO 或 Multi-Size ICO）是一种包含多种尺寸和色深的图标文件。允许在一个文件中存储多个位图（BMP 或 PNG 格式）。每个位图可以具有不同的尺寸。\nICO 文件包含：\n文件头（Header）：定义 ICO 文件类型及包含的图像数量。 图像目录（Image Directory）：描述每个图像的尺寸、色深、偏移量等信息。 图像数据（Image Data）：实际存储图像像素数据。\n浏览器需要一个图标时，它会从 ICO 文件中选择最合适的尺寸。缺点就是包含多个尺寸的 .ico 文件可能会比单个尺寸的文件大。\n本篇文章没有继续深挖，比如 Android Chrome 独有的 manifest.json 苹果设备 apple-mobile-web-app-capable 等。 感兴趣的朋友可以继续深挖。 本文长期链接 如果您觉得我的博客对你有帮助，请通过 RSS订阅我。 或者在X上关注我。 如果您有Medium账号，能给我个关注嘛？我的文章第一时间都会发布在Medium。 ","date":"2025-02-18T11:30:38+08:00","image":"https://images.hxzhouh.com/blog-images/2025/02/65e64661a046efca8dcbc39b98ae2b91.png","permalink":"https://huizhou92.com/zh-cn/p/%E7%BD%91%E9%A1%B5%E5%9B%BE%E6%A0%87icon%E9%82%A3%E4%BA%9B%E4%BA%8B/","title":"网页图标（Icon）那些事"},{"content":"原文链接：https://medium.com/wise-engineering/wise-tech-stack-2025-update-d0e63fe718c7\nWise工程：2025年技术栈更新 截至2024财年，Wise已经为1280万活跃客户提供服务，每季度处理的跨境转账金额高达300亿英镑。超过60%的转账实现了即时到账，我们的Wise平台为全球银行和非银行机构提供支付服务。这一成就离不开我们以技术为核心的理念、稳健的架构以及专注的工程团队。\nWise的工作方式 Wise在全球主要地点拥有850多名工程师，他们被组织成独立的小组和部落。这些团队被赋予了创新和独立决策的权力，促进了透明度、信任和协作。\n本文基于我们2022年的技术栈，涵盖了Wise技术栈的最新改进，帮助我们实现无国界的资金流动——即时、便捷、透明，最终实现免费。\n使用Wise转账 我们的网页和移动应用 我们的网页应用基于CRAB（Wise特有的抽象层，构建在流行的Next.js框架之上），包含40个独立的应用程序，每个应用负责特定的产品功能，使得部署更加安全和易于管理。\n在测试方法上，我们最大的变化之一是引入了Storybook，用于在开发过程中可视化单个React组件。Storybook与Chromatic配合使用，能够在每次更改后捕获快照，并突出组件的视觉差异。这些快照在代码更改过程中非常有效，帮助我们防止错误影响到客户。\nWise移动应用：更快、更智能、更高效\n我们的iOS工程师通过将250多个Xcode模块从Xcodegen迁移到Tuist，并将Cocoapods切换到Swift Package Manager（SPM），升级了基础设施，从而实现了构建缓存的改进。团队还提高了灵活性，将零变更构建时间从28秒减少到2秒。借助先进的构建缓存，开发变得更加顺畅，并朝着使用SPM的Swift可组合架构方向发展。\n我们的Android工程师则专注于大规模应用开发。主要Android代码库包含300多个Gradle模块和大约100万行代码，涵盖2个生产应用、6个示例应用、17个JVM模块、221个Android模块和65个多平台模块。我们提高Android开发速度的努力集中在以下几个关键领域：\n使用更多的BFFs在Android、iOS和网页团队之间共享代码逻辑。 基于KSP构建代码生成工具。 探索Kotlin多平台的应用。 在用户界面方面，我们已经全面转向Compose——首先用于设计系统，现在用于整个屏幕和导航。我们迅速采用了Kotlin 2.0和2.1版本。为了处理异步任务，我们使用协程和流，而我们的架构遵循标准的MVVM模式，并得到Google的Jetpack库的支持。\n后端服务 Wise总共运行超过1000个服务。在后端，我们主要使用Java和Kotlin。自上次更新以来，我们专注于通过开发内部工具来提高自动化和效率，从而加快开发速度，并提供跨不同服务使用的标准库。\n更快构建优秀应用\n自上次更新以来，我们一直专注于通过自动化代码更新和可扩展的依赖管理解决方案来实现大规模工程。为此，我们：\n引入了一个内部微服务底层框架，基于最小配置原则构建，并作为构件发布，使我们能够更快地构建标准微服务。它配置了服务使用的常见功能，提供推荐的默认设置：安全性、可观察性、数据库通信、与Kafka的交互等，使团队能够专注于业务逻辑。 通过内部Gradle插件集合改善构建管道的标准化。一个显著的例子是我们的插件，它标准化了GitHub Actions工作流。这使得通过简单的插件版本更新实现组织范围内的工作流更改变得轻而易举，使得在700多个Java代码库中推出SLSA等倡议变得轻松。 引入了一种语言无关的自动化服务，使我们能够在大规模上对代码库进行复杂更改，并为拥有团队创建拉取请求进行审查。通过使用该服务，我们进一步推进了集中式Java依赖管理平台，通过自动化Java服务的依赖升级。 直接与本地支付系统集成 我们已在菲律宾上线了即时支付系统InstaPay，并获得了加入日本即时支付系统Zengin的许可。我们还获得了巴西PIX的接入权限。\n在Wise，我们投入了大量精力来创建尽可能一致的架构，网络通过AWS Transit Gateways集中管理。英国、匈牙利和澳大利亚的物理数据中心集成的细节存在显著差异。我们的澳大利亚数据中心是AWS Outpost Servers的首次部署之一，使我们能够在尽可能多的基础设施中保持一致的AWS工具。\n允许企业使用我们的API 我们的公共API允许企业直接集成Wise的跨境支付服务，使用安全的REST API，支持OAuth认证。这为企业提供了转账、货币兑换和账户管理的功能，以及全面的文档和开发者工具，以简化集成过程。\nWise平台支持超过70种货币和多种支付路线，提供无缝的全球连接解决方案。该平台包括内置的合规功能，允许在利用Wise广泛的全球基础设施的同时，实现无缝的跨境操作。\n扩展Wise的基础设施平台 为了适应快速增长，我们专注于重建基础设施，以确保效率和灵活性，同时减少团队的运营负担。\n引入我们的新Kubernetes支持的计算运行时平台 **计算运行时平台（CRP）**是我们新的可扩展平台，利用Kubernetes，使工程团队能够轻松托管应用程序，而无需管理复杂的基础设施设置。\n发展我们的Kubernetes栈\n自2018年以来，Wise一直依赖于使用Terraform、JSONNET和ConcourseCI构建的Kubernetes，以支持服务网格控制（Envoy）、PCI-DSS合规性和无摩擦的部署。虽然这一模型为我们提供了良好的服务，但我们需要一种更可扩展和标准化的方法。这就是我们引入CRP的原因：\nTerraform仍然负责基础设施的配置，但我们从头开始重写了代码库，以提高灵活性和可维护性。 RKE2处理集群引导，Rancher管理整体集群状态。 Helm取代JSONNET，以提高可维护性和上游兼容性。 ArgoCD与自定义插件确保完全自动化的配置和一致性。 我们的Envoy服务代理现在包括服务之间的无缝集成和发现，提高了平台的灵活性、弹性和监督。 因此，我们的Kubernetes集群数量从6个增长到超过20个，同时保持可维护性和效率。\n更智能的自动扩展和成本优化\n除了更好地配置和维护基础设施的能力外，我们还通过CRP引入了效率改进：\n我们正在构建一个灵活的、可选择的自动扩展解决方案，以降低云成本和团队的认知负担。 自动化容器CPU调整大小（通过垂直Pod自动扩展器）现在在非生产环境中上线，并正在向非关键工作负载的生产环境推广。 完全托管的边车容器（如Envoy代理）现在简化了产品团队的部署。 扩展水平扩展，使用KEDA，根据每日和每周的流量模式优化工作负载。 对成本优化的关注使Wise更接近于零任务。\n构建可扩展、可靠和智能的数据基础设施 在Wise，我们的许多工作都与数据的移动和理解有关。无论是转账、更新实时仪表板，还是为后台的机器学习模型提供动力，我们的系统都在不断处理和分发大量信息。随着我们全球足迹的扩大，我们对更快、更安全和更灵活的数据处理方式的需求也在增加。以下是我们如何发展数据技术栈，以继续为客户提供可靠、便捷和高效的体验的快速概述。\n为我们的数据骨干提供动力 在Wise，我们的数据库是我们所有工作的基础之一，因此我们在使其既稳健又易于管理方面投入了大量精力。在幕后，我们的数据库工程师正在解决一些引人入胜的技术挑战，推动金融数据管理的可能性。\n我们努力将大部分MariaDB和Postgres工作负载从EC2迁移到Amazon RDS。这一转变减少了维护任务，降低了运营开销，并提供了更强大的安全功能。 同样，我们正在将自托管的MongoDB迁移到MongoDB Atlas，这使我们能够专注于构建新功能，而不是与扩展作斗争。 Redis继续为我们的内存工作负载提供支持。 我们还在探索分布式数据库，以实现更大的关系可扩展性。 更智能的工作流编排和可观察性 我们采用了一种名为Temporal的工作流引擎，以自动化关键任务，如切换和恢复测试。这有助于我们将停机时间降至最低，并保持符合严格的弹性法规。 像RDS性能洞察和Percona监控与管理（PMM）这样的工具为我们提供了清晰的数据库运行状况视图，使我们能够及早解决问题。 我们还在尝试使用直接的云SDK来管理我们的基础设施——逐步从Terraform Enterprise转向简化我们的配置流程。 保持数据流动 Kafka支撑着我们大多数实时数据的移动——无论是服务之间的异步消息传递、日志收集，还是分析的流式更新。 我们的Kafka集群容量显著增长，并引入了诸如机架感知备用副本等功能，以提高容错能力。 我们的内部数据移动服务帮助将信息从Kafka或数据库引导到Snowflake、S3 Parquet、Iceberg或其他目标。 配置过程中的自动检查减少了人为错误，其日益增长的使用表明团队发现设置新管道变得更简单、更快捷。 另一个内部服务，数据归档，现在在多个数据库中归档超过1000亿条记录。这不仅节省了成本，还使我们的数据库更易于备份和恢复。 将数据转化为洞察 Wise各团队使用我们的商业智能工具做出战略性、数据驱动的决策，以提升客户体验——从欺诈检测到个性化营销和预测分析。\n尽管我们仍然依赖Snowflake作为分析的核心组成部分，但我们已经在Amazon S3上建立了数据湖的基础，使用Apache Iceberg。得益于其强大的开放表格式，Apache Iceberg使我们能够更高效地在S3上存储大量数据。它允许我们在不需要重写所有数据的情况下修改表结构，从而加快查询速度并控制存储成本。此外，其活跃的开源社区不断推动改进，惠及我们的长期可扩展性。 在我们的数据源和商业智能工具之间是Trino，它使我们能够在一个地方查询Iceberg表、Snowflake或甚至Kafka流。 一个新的Trino网关处理工作负载分离和容错查询，而复杂的工作流仍由Airflow和dbt-core管理。有关此主题的深入了解，请观看我们数据工程师最近的会议演讲。 报告和仪表板使用Looker或Superset构建——团队选择最适合的工具集。 推动智能解决方案 我们的机器学习架构旨在支持探索和生产，无缝集成机器学习功能到产品中，以改善客户入职和欺诈预防，并利用负责任的人工智能技术。\n我们的数据科学家在Amazon SageMaker Studio中工作，选择JupyterLab或VSCode来构建实验和探索数据。 大规模处理在EMR上使用Spark进行，而Airflow则协调数据收集、清理、模型训练和定期再训练，以保持每个步骤按计划进行。 我们使用SageMaker特征存储来保持数百个特征在训练和推理中的同步，MLflow跟踪实验、指标和模型版本。这种设置简化了模型变体的比较或在需要时的回滚。 当模型准备好投入生产时，我们通过基于Ray Serve的内部预测服务进行部署。 多亏了MLflow插件，我们的数据科学家可以以最小的摩擦推出模型——加快欺诈检测、KYC或其他用例的推理时间，在这些情况下每毫秒都至关重要。 自动检查有助于在数据漂移或特征不一致变成严重问题之前捕捉到它们。 解锁新的人工智能能力 我们创建了一个安全的网关，连接多个大型语言模型提供商，包括Anthropic（Claude）、AWS（Bedrock）、Google（Gemini）和OpenAI（gpt和o系列）。这种方法使我们能够在不处理单独凭证或复杂合规检查的情况下实验不同的模型。一个受LangChain启发的Python库封装了这些API，以加快原型设计。\n对于需要引用内部文档、知识库或用户数据的情况，我们提供了一个自定义的检索增强生成（RAG）服务。它在生成响应之前从各种数据存储中提取最新信息——这是总结复杂文档或自动化客户服务工作流的便捷功能。\n智能数据管理 我们的数据架构既庞大又复杂，因此我们建立了一个全面的库存系统和专门的治理门户，以显示数据存储的位置及其分类。\n我们已在整个数据资产中实现了自动化数据发现，以了解创建了什么数据；谁创建了它；以及数据的类别是什么。我们正在利用我们的数据库存来支持数据删除、数据合规和数据发现的工作。这种设置不仅支持审计和法规的合规工作，还提高了开发者的生产力。\n随着越来越多的工程师加入治理工作，我们能够推出更严格的政策、增强的隐私检查和自动化的数据生命周期管理。\n开发者赋能——Wise的CI/CD演变 为了加强我们的交付管道和开发者体验，我们不断发展我们的CI/CD平台，以使开发者能够比以往更快、更可靠地将功能交付给客户。\nCI改进：速度和安全性 从CircleCI迁移到GitHub Actions带来了优化的新可能性。通过实施详细的指标跟踪，我们发现了构建性能的关键见解。例如，通过预填充常用容器的缓存，我们将构建时间缩短了15%。在我们每月50万次构建的规模下，这相当于每月节省超过1000小时。\n我们一直在有条不紊地在我们的构建过程中实施SLSA框架，逐步加强我们的供应链安全。\nCD转型：从Octopus到Spinnaker 在我们之前的文章中提到的CI/CD管道状态之后，我们的部署策略随着从Octopus（我们的内部工具）转向Spinnaker而发生了变化。这不仅仅是工具的更换——它代表了一种范式转变，从将部署视为简单的事务转变为将其视为有序事件序列。\n这一转变使我们能够减少工程师在部署管理上花费的时间，并最小化缺陷到达客户的风险。这提高了开发者的交付速度，使我们能够更快地为客户提供服务，而不牺牲质量和稳定性。\n高级金丝雀测试 Spinnaker的自动金丝雀分析已成为我们部署管道的基石。该过程在其简单性中优雅而强大：\n仅5%的流量路由到新服务版本进行测试 对技术和业务指标进行全面的30分钟分析 对重大异常触发自动回滚 因此，仅在2024年，这一系统自动阻止了数百次可能导致事件的部署，节省了数千小时的工程时间。\n目前，Wise的超过一半服务已在Spinnaker上运行，预计到2025年中期将完成全面迁移，我们准备迈出下一步：实施托管交付，以协调整个SDLC，包括测试和数据管理。\nLGTM堆栈的可观察性 我们改善了可观察性生态系统，以更好地监控、理解和优化Wise产品。可靠性工程师专注于构建一个更强大、高效和富有洞察力的可观察性平台，以应对我们快速扩展环境中的关键挑战。\n专用的可观察性基础设施 我们实施了专用的可观察性CRP集群。这为在不同环境中运行的服务提供了开箱即用的可观察性。因此，我们简化了监控设置，减少了手动配置的负担。\n统一的指标和监控堆栈 为了解决可扩展性问题，我们已从Thanos迁移到Grafana Mimir。这意味着我们现在完全运行在LGTM堆栈上：Loki用于日志，Grafana用于仪表板和可视化，Tempo用于跟踪，Mimir用于指标。作为我们在可观察性方面持续改进的一部分，我们正在试点测试Grafana Pyroscope，以对选定服务进行分析，探索性能洞察和优化的新维度。\n我们的指标堆栈每秒接收约600万个指标样本，并处理我们最大指标租户的1.5亿个活动系列。\n通过统一我们的堆栈，我们：\n在整个技术生态系统中标准化可观察性。 增强日志、指标、跟踪和仪表板之间的关联。 改善监控基础设施的性能和可扩展性。 可观察性的成本优化和效率 最后，我们继续投资于优化我们的可观察性堆栈。我们能够降低运营成本，提高资源利用率，并最终拥有更可持续的长期可观察性战略。请查看我们之前的文章，详细介绍了我们在这些倡议上所做的工作。\n这一战略演变使我们的工程团队能够获得更深入、更具可操作性的洞察，同时确保我们的可观察性基础设施既强大又具有成本效益。\n结论 总之，我们2025年的技术栈证明了Wise如何引领潮流，为全球1280万活跃客户提供最快、最可靠和最具成本效益的资金转移方式。对标准化和集成的高度关注意味着我们的系统旨在高效扩展，同时确保稳健的风险和合规管理。\n我们的工程团队继续在所有领域精炼我们的基础设施，从移动和网页应用到后端服务和机器学习。这些努力简化并加速了跨境资金流动，确保我们为当前需求和未来增长做好准备。\n我们致力于长期投资，构建最佳基础设施，以无缝管理您在全球范围内的资金。随着每一次技术增强和与支付系统的新直接连接，我们正稳步朝着实现无国界资金流动的愿景迈进。\n","date":"2025-02-13T09:46:39+08:00","permalink":"https://huizhou92.com/zh-cn/p/%E8%AF%91wise%E5%B7%A5%E7%A8%8B2025%E5%B9%B4%E6%8A%80%E6%9C%AF%E6%A0%88%E6%9B%B4%E6%96%B0/","title":"【译】Wise工程：2025年技术栈更新"},{"content":"背景 Rhys Hiltner 在 2024 年提出了改进互斥锁的性能优化诉求。现在这个优化已经合并到即将发布的Go1.24中，在锁竞争激烈的场景下最多会提升70%的性能。\n在基准测试 ChanContended 中，作者发现随着 GOMAXPROCS 的增加，mutex 的性能明显下降。\nIntel i7-13700H (linux/amd64)：\n当允许使用 4 个线程时，整个进程的吞吐量是单线程时的一半。 当允许使用 8 个线程时，吞吐量再次减半。 当允许使用 12 个线程时，吞吐量再次减半。 在 GOMAXPROCS=20 时，200 次channel操作平均耗时 44 微秒，平均每 220 纳秒调用一次 unlock2，每次都有机会唤醒一个睡眠线程。\n另一个角度是考虑进程的 CPU占用时间。\n下面的数据显示，在 1.78 秒的Wall-Clock Time内，进程的20个线程在lock2调用中总共有27.74秒处于CPU(自旋)上。 这些 lock2 相关的线程并没有休眠，而是一直在自旋，这将消耗大量的CPU资源。\n新提案：增加spinning状态 通过上述的分析，作者发现在当前的lock2实现中，虽然理论上允许线程睡眠，但实际上导致所有线程都在自旋，导致了更慢的锁传递，带来了不少的性能损耗。\n于是提出了新的设计方案《Proposal: Improve scalability of runtime.lock2》\n核心优化点 mutex 的状态字添加了一个个新的标志位，称为 “spinning”。\n1 2 3 4 5 6 7 https://github.com/golang/go/blob/608acff8479640b00c85371d91280b64f5ec9594/src/runtime/lock_spinbit.go#L57 const ( mutexLocked = 0x001 mutexSleeping = 0x002 mutexSpinning = 0x100 ... ) 使用这个 spinning位来表示是否有一个等待的线程处于 “醒着并循环尝试获取锁” 的状态。线程之间会互相排除进入 spinning状态，但它们不会因为尝试获取这个标志位而阻塞。\nmetux 的介绍可以参考以前的文章\nhttps://pub.huizhou92.com/go-source-code-sync-mutex-3082a25ef092\nMutex 获取锁分析 1. 快速路径尝试获取锁 1 2 3 4 5 6 7 8 9 //https://github.com/golang/go/blob/adc9c455873fef97c5759e4811f0d9c8217fe27b/src/runtime/lock_spinbit.go#L160 k8 := key8(\u0026amp;l.key) v8 := atomic.Xchg8(k8, mutexLocked) if v8\u0026amp;mutexLocked == 0 { if v8\u0026amp;mutexSleeping != 0 { atomic.Or8(k8, mutexSleeping) } return } fast 模式跟以前变化不大。如果成功(锁之前未被持有)则快速返回。这是最理想的情况，无竞争时的快速路径。\n2. 自旋等待阶段 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 //https://github.com/golang/go/blob/adc9c455873fef97c5759e4811f0d9c8217fe27b/src/runtime/lock_spinbit.go#L208 if !weSpin \u0026amp;\u0026amp; v\u0026amp;mutexSpinning == 0 \u0026amp;\u0026amp; atomic.Casuintptr(\u0026amp;l.key, v, v|mutexSpinning) { v |= mutexSpinning weSpin = true } if weSpin || atTail || mutexPreferLowLatency(l) { if i \u0026lt; spin { procyield(mutexActiveSpinSize) //主动自旋 // ... } else if i \u0026lt; spin+mutexPassiveSpinCount { osyield() //被动自旋 // ... } } 如果快速路径失败，进入自旋等待阶段。 通过 mutexSpinning 标志控制同时只允许一个 goroutine 自旋 自旋分为procyield与osyield，两者的区别是:procyield会持续占有CPU，响应会更快，适合极短时间的等待，osyield会临时释放CPU，响应较慢，但是不会占用较多CPU，适用于较长时间的等待。\n这种两阶段自旋设计能够在不同竞争强度下都保持较好的性能表现。 轻度竞争时主要使用主动自旋，保证低延迟 重度竞争时快速进入被动自旋，避免CPU资源浪费 休眠等待阶段 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 //https://github.com/golang/go/blob/adc9c455873fef97c5759e4811f0d9c8217fe27b/src/runtime/lock_spinbit.go#L231 // Store the current head of the list of sleeping Ms in our gp.m.mWaitList.next field gp.m.mWaitList.next = mutexWaitListHead(v) // Pack a (partial) pointer to this M with the current lock state bits next := (uintptr(unsafe.Pointer(gp.m)) \u0026amp;^ mutexMMask) | v\u0026amp;mutexMMask | mutexSleeping if weSpin { next = next \u0026amp;^ mutexSpinning } if atomic.Casuintptr(\u0026amp;l.key, v, next) { weSpin = false semasleep(-1) atTail = gp.m.mWaitList.next == 0 i = 0 } 如果自旋失败，goroutine 将进入休眠等待，然后将当前 M 加入等待队列(通过 mWaitList 链表)，通过信号量(semasleep)使当前 goroutine 进入休眠，等待持有锁的 goroutine 在解锁时唤醒。\n当某个线程解锁互斥锁时，如果发现已经有线程处于 “醒着并旋转” 的状态，就不会唤醒其他线程。在 Go 运行时的背景下，这种设计被称为 spinbit。\n这个设计的核心目的是：通过让一个线程负责 “旋转尝试获取锁”，避免所有线程都同时竞争资源，从而减少争用和不必要的线程切换。\n效果 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 goos: linux goarch: amd64 pkg: runtime cpu: 13th Gen Intel(R) Core(TM) i7-13700H │ old │ new │ │ sec/op │ sec/op vs base │ ChanContended 3.147µ ± 0% 3.703µ ± 0% +17.65% (p=0.000 n=10) ChanContended-2 4.511µ ± 2% 5.280µ ± 7% +17.06% (p=0.000 n=10) ChanContended-3 5.726µ ± 2% 12.125µ ± 2% +111.75% (p=0.000 n=10) ChanContended-4 6.574µ ± 1% 13.356µ ± 4% +103.16% (p=0.000 n=10) ChanContended-5 7.706µ ± 1% 13.717µ ± 3% +78.00% (p=0.000 n=10) ChanContended-6 8.830µ ± 1% 13.674µ ± 2% +54.85% (p=0.000 n=10) ChanContended-7 11.07µ ± 0% 13.59µ ± 2% +22.77% (p=0.000 n=10) ChanContended-8 13.99µ ± 1% 14.06µ ± 1% ~ (p=0.190 n=10) ChanContended-9 16.93µ ± 2% 14.04µ ± 3% -17.04% (p=0.000 n=10) ChanContended-10 20.12µ ± 4% 14.12µ ± 1% -29.80% (p=0.000 n=10) ChanContended-11 23.96µ ± 2% 14.44µ ± 3% -39.74% (p=0.000 n=10) ChanContended-12 29.65µ ± 6% 14.61µ ± 3% -50.74% (p=0.000 n=10) ChanContended-13 33.98µ ± 7% 14.69µ ± 3% -56.76% (p=0.000 n=10) ChanContended-14 37.90µ ± 1% 14.69µ ± 3% -61.23% (p=0.000 n=10) ChanContended-15 37.94µ ± 4% 14.89µ ± 5% -60.75% (p=0.000 n=10) ChanContended-16 39.56µ ± 0% 13.89µ ± 1% -64.89% (p=0.000 n=10) ChanContended-17 39.56µ ± 0% 14.45µ ± 4% -63.47% (p=0.000 n=10) ChanContended-18 41.24µ ± 2% 13.95µ ± 3% -66.17% (p=0.000 n=10) ChanContended-19 42.77µ ± 5% 13.80µ ± 2% -67.74% (p=0.000 n=10) ChanContended-20 44.26µ ± 2% 13.74µ ± 1% -68.96% (p=0.000 n=10) geomean 17.60µ 12.46µ -29.22% source https://github.com/golang/go/issues/68578#issuecomment-2256792628\n虽然在竞争较少的情况下，性能有降低，但是在竞争比较多的地方性能提升显著。平均来说，大约获得 29%的性能提升。期待后续能够优化这种情况吧。\nmutex本次修改没涉及API层面改动，所以只要等 Go1.24 正式发布就能自动使用了。该特性通过GOEXPERIMENT=spinbitmutex 来控制，默认是开启的，也可以将它关闭，来使用原来的Mutex。\n本文长期链接 如果您觉得我的博客对你有帮助，请通过 RSS订阅我。 或者在X上关注我。 如果您有Medium账号，能给我个关注嘛？我的文章第一时间都会发布在Medium。 ","date":"2025-02-11T11:16:36+08:00","image":"https://images.hxzhouh.com/blog-images/2025/02/aee1ae007540f5e7191e3ac7cd6b4f8d.png","permalink":"https://huizhou92.com/zh-cn/p/go124-mutex%E8%87%AA%E6%97%8B%E4%BC%98%E5%8C%96%E6%9C%80%E5%A4%A7%E6%8F%90%E5%8D%8770%E7%9A%84%E6%80%A7%E8%83%BD/","title":"Go1.24: mutex自旋优化,最大提升70%的性能"},{"content":"œ\n随着项目规模不断扩大，代码库的维护与更新变得越来越繁琐。每当某个函数、常量或包路径需要替换时，手动查找和修改不仅费时费力，还容易出错。幸运的是，Go 语言在不断进步，最新接受的提案 go:fix工具为开发者提供了一种自动化迁移的解决方案。本文将带你从浅入深地了解 go:fix 的原理、应用场景以及具体使用示例。\n一、go:fix 背景简介 在日常开发过程中，API 的弃用与替换是不可避免的。举例来说，当一个函数被标记为弃用时，我们可能希望所有对该函数的调用都替换为新的实现；当一个常量被重命名或迁移到其他包中时，我们也希望工具能够自动更新所有引用。 #32816 提出的这一方案正是为了实现这样的目标——通过在代码中添加特定指令，实现简单弃用项的自动迁移。\ngo:fix 工具主要通过两种机制完成自动化迁移：\n函数内联（Inlining） 常量转发（Forwarding）\n接下来，我们将详细介绍这两种机制及其使用示例。 二、函数内联与常量转发 1. 函数内联（Inline Functions） 当一个函数被标记为需要内联时（例如通过 //go:fix inline 注释），go:fix 会自动将对该函数的调用替换为其函数体内的实现。这种机制常用于两种场景：\n弃用函数的替换：当某个函数不再推荐使用时，可以直接将其内部逻辑迁移到新函数。例如： 1 2 3 4 5 // Deprecated: prefer Pow(x, 2). //go:fix inline func Square(x int) int { return Pow(x, 2) } 如果代码中存在对 Square 的调用，工具会自动替换为 Pow(x, 2)，从而逐步淘汰旧函数。\n包迁移：在包升级或重构过程中，可能需要将原先某个包中的函数调用替换为新包中的实现。例如：\n1 2 3 4 5 6 7 8 package pkg import pkg2 \u0026#34;pkg/v2\u0026#34; //go:fix inline func F() { pkg2.F(nil) } 这样，调用 pkg.F() 的代码将自动更新为 pkg2.F(nil)，简化包路径更新的过程。\n2. 常量转发（Forward Constants） 常量转发机制适用于常量重命名或跨包迁移的场景。只需在常量定义前添加 //go:fix forward 注释，工具便能将所有对该常量的引用替换为其目标常量。例如：\n1 2 3 4 package example //go:fix forward const Ptr = Pointer 如果其他地方有如下调用：\n1 fmt.Println(example.Ptr) 运行 go:fix 工具后，该调用会被替换为：\n1 fmt.Println(example.Pointer) 此机制不仅支持单个常量，也可以对常量组同时生效。\n三 go:fix 的优势与挑战 优势 低风险迁移：自动替换确保新旧代码行为一致，降低因手动修改引入错误的风险。 提高开发效率：通过自动化工具处理重复性修改任务，开发者可以将更多精力投入到核心业务逻辑中。 一致性更新：确保代码库中所有弃用项都被统一更新，避免遗漏。 无缝集成：GoFix 与 gopls（Go 语言服务器协议）等工具紧密集成，提供实时反馈，方便开发者及时发现和修正问题。 挑战 复杂场景处理：对于一些特殊情况（例如常量组、iota 的用法）需要特别处理。 跨包依赖：当替换项来自不同包时，可能涉及更多细节问题，需要确保新包的导入和引用正确。 非确定性行为：工具在处理 map 遍历等非确定性场景时，需要特别注意替换的一致性。 四、结语 go:fix 的引入为Go语言的自动化代码迁移带来了新的可能性。通过简单的注释指令（如 //go:fix inline、//go:fix forward ），开发者可以轻松实现对弃用函数、常量甚至包路径的自动替换，从而保持代码库的现代性和一致性。无论是大规模重构，还是逐步淘汰旧 API，go:fix 都能为你的项目维护工作提供极大的便利。\n随着工具的不断完善和更多社区反馈的积累，相信未来 go:fix 能够覆盖更多复杂场景，进一步提升 Go 开发的生产力。如果你也在为手动修改代码而烦恼，不妨期待一下这款新工具，体验自动化带来的高效与便捷。\n五、参考资料 https://github.com/golang/go/issues/32816\nhttps://github.com/golang/tools/blob/master/gopls/internal/analysis/gofix/doc.go\n本文长期链接 如果您觉得我的博客对你有帮助，请通过 RSS订阅我。 或者在X上关注我。 如果您有Medium账号，能给我个关注嘛？我的文章第一时间都会发布在Medium。 ","date":"2025-02-08T15:05:21+08:00","image":"https://images.hxzhouh.com/blog-images/2025/02/69886f43f924640d4703312dc480bdca.png","permalink":"https://huizhou92.com/zh-cn/p/go_fix-%E8%87%AA%E5%8A%A8%E5%8C%96%E4%BB%A3%E7%A0%81%E8%BF%81%E7%A7%BB%E7%9A%84%E5%85%A8%E6%96%B0%E5%88%A9%E5%99%A8/","title":"go_fix 自动化代码迁移的全新利器"},{"content":"原始链接 https://blog.bytebytego.com/p/how-google-spanner-powers-trillions | 作者 ByteByteGo\n免责声明：本文中的所有细节均来源于 Google 博客和研究论文，所有技术细节的原始版权均归 Google 工程团队所有。文末附有原始文章的链接。我们对这些细节进行了分析并提供了我们的解读。如果您发现任何不准确或遗漏之处，请留言，我们会尽力修正。\nGoogle Cloud Spanner 是 Google 开发的一款革命性数据库系统，它巧妙地将传统关系型数据库的优势与 NoSQL 系统通常具备的可扩展性相结合。\n专为跨多个区域处理海量工作负载而设计，Cloud Spanner 提供了一个全球分布、强一致性且高可用的数据管理平台。其独特之处在于，它既支持 SQL 查询和关系型数据结构，同时又实现了水平扩展能力，使其能够满足现代高负载应用的需求。\nCloud Spanner 的主要特性 多版本数据库 采用同步复制技术，即使在区域故障的情况下也能保证数据的持久性与可用性。 TrueTime 技术 整合了 GPS 和原子钟，提供全球一致的时间线。 简化数据管理 提供熟悉的 SQL 接口，同时在后台处理分布式数据处理的复杂性。 数据切分与动态分片 将数据按照连续的键范围（称为 splits）进行分区，并根据负载或数据量动态调整分片以优化性能。 总体而言，Google Spanner 为需要支持全球规模操作，同时保持传统关系型系统的稳健性和可靠性的企业提供了一种极具竞争力的数据库解决方案。\n在本文中，我们将深入探讨 Google Cloud Spanner 的架构，以及它如何支持构成这一出色数据库选项的各项能力。\nCloud Spanner 架构概述 Spanner 的架构旨在支持其作为一个全球分布、强一致性及高可用性数据库的角色。\n在最高层次上，Spanner 被组织为一个被称为 “Universe” 的逻辑实体，该实体跨越多个物理或逻辑位置，这些位置被称为“区域（zones）”。\n每个区域都具有一定的独立性，并包含专用的 spanservers。这些服务器负责数据存储和事务处理，基于 Google 早期分布式存储系统 Bigtable 的概念，并在此基础上进行了增强以支持复杂事务和多版本数据。\n关键架构组件 Cloud Spanner 通过将数据划分成更小的单元来进行管理，这些单元称为 tablets，并分布在多个 spanservers 上。\nTablets：每个 tablet 存储键值对数据，并附带时间戳用于版本控制。这种结构使得 Spanner 成为一个多版本数据库，能够根据需要访问数据的旧版本。 Colossus 文件系统：Tablets 存储在 Colossus 上，这是 Google 的分布式文件系统。Colossus 提供了容错性和高性能存储，使得 Spanner 能够实现存储与计算资源的独立扩展。 Splits：表中的数据依据连续的键值范围进行划分，这些范围称为 splits。当某个 split 变得过大或流量过高时，系统会自动将其分割成更小的部分并重新分布到不同的 spanservers，这一过程称为动态分片（dynamic sharding）。 跨区域复制：每个 split 都会在多个区域间进行复制，以实现冗余和故障容错。 为了保证数据一致性，Spanner 采用了 Paxos 共识算法来管理跨区域的复制。每个 split 都有多个副本，Paxos 算法确保这些副本保持一致性。\nLeader选举：在这些副本中，一个副本被选为领导者，负责处理该 split 的所有写事务，确保更新以一致的顺序进行。如果领导者出现故障，Paxos 会自动选举出新的领导者，从而在无需人工干预的情况下保持系统可用性。同时，非领导者副本可以处理读操作，从而减轻领导者的负载并提高扩展性。 Spanner 实例通常跨越某一地区内的多个区域，并将副本分布在这些区域中。这样的架构提高了系统的可用性，因为即便某个区域发生故障，其他区域仍能继续处理请求。对于全球部署，还可以将数据复制到不同大陆，以便为全球用户提供低延迟访问。\n所有数据均存储在 Colossus 上，该系统为分布式、复制的文件存储而设计，通过在多台物理机器间复制数据来确保高耐久性，从而在硬件故障时能够恢复数据。文件系统与计算资源分离，使得数据库可以独立扩展并高效运行。\nPaxos 共识机制 Paxos 是 Spanner 架构中的核心组件之一。其基本原理是通过分布式共识，让一组副本（称为 Paxos 组）就一个值（例如某事务的提交或负责更新的领导者）达成一致。\n领导者分配机制 每个数据 split（即连续键范围）都关联有一个横跨多个区域的 Paxos 组。 在 Paxos 组中，一个副本被指定为领导者，该领导者负责处理该 split 的所有写操作，从而保证更新协调一致。 其他副本作为跟随者，不仅帮助分担读操作的负载，还为系统的扩展性做出贡献。 Paxos 领导者的主要职责包括：\n处理写操作：领导者接收写请求，并确保这些请求在多数副本确认后才进行提交，从而确保数据的持久性和一致性，即便部分副本出现故障。 维护顺序：通过 TrueTime 为事务分配时间戳，确保写操作按照全局一致的顺序执行。 与跟随者通信：领导者向跟随者广播提案，并收集确认信息来协调更新。 即使在分布式系统中不可避免会出现故障，Paxos 机制也能确保 Spanner 在面对这些问题时依旧保持可用性与一致性。若当前领导者因机器或区域故障而失效，Paxos 组将检测到这一情况并选举出新的领导者，从而避免系统停机。\n事务处理机制 Cloud Spanner 使用强大而稳健的事务处理方法，确保数据一致性、可靠性和高性能。下面介绍写事务和读事务的工作原理：\n写事务 写事务确保了原子性（全有或全无）和一致性（所有副本数据一致），由 Paxos 领导者协调处理，即便在出现故障时也能保证数据完整性。其基本步骤如下：\n加锁：在修改数据之前，负责该 split 的 Paxos 领导者会对相关行加写锁。如果另一事务已持有冲突锁，则当前事务需等待锁释放。 通过 TrueTime 分配时间戳：利用 TrueTime 为事务分配全局一致的时间戳，该时间戳总是大于之前任何已提交事务的时间戳，从而保证时间顺序的一致性。 多数副本复制保证持久性：领导者在加锁并分配时间戳后，会将事务细节发送给 Paxos 组中超过半数的副本。只有在多数副本确认后，事务才被认为已提交，确保即便部分副本故障，数据也能得到持久保存。 提交等待：领导者会等待一个短暂的时段，确保提交时间戳对所有副本均已生效，然后再最终提交事务，使得后续所有读取操作都能反映该变更。 对于单个 split 内的写操作，例如用户希望在表中添加一个 ID 为 7、值为 “Seven” 的行：\nSpanner API 会确定 ID 7 所在的 split，并将请求发送至该 split 的 Paxos 领导者。 领导者对 ID 7 加锁、分配时间戳，并将变更复制给多数副本。 在确保时间戳生效后，事务提交，所有副本应用该变更。 而对于涉及多个 split 的写操作（例如修改多个 split 中的 ID 2000、3000 和 4000），Spanner 则采用两阶段提交协议：\n每个参与的 split 都成为事务的参与者，其中一个 split 的领导者担当协调者角色。 协调者确保所有参与者都已加锁并同意提交事务，然后再进行下一步操作。 在所有参与者确认后，协调者提交事务，并通知其他参与者应用变更。 读事务 读事务经过优化，可在高负载下提供高性能的强一致性读取，同时无需加锁。\n强一致性读取：这类读取始终返回最新的已提交数据。系统通过 TrueTime 检查数据最新的时间戳，确保返回的数据是最新状态。例如，当客户端请求读取 ID 为 1000 的行时，系统会路由该请求至某个副本，并在返回结果前与领导者确认数据的最新性。 陈旧读取：允许在一定程度上返回稍微过时的数据（例如最多延迟 10 秒），以换取更低的延迟。客户端在请求时，可以直接从副本读取数据，而无需等待领导者确认，从而加速响应。 下面的图示展示了强一致性读取的场景：\n而下图则展示了陈旧读取的场景：\n为了避免死锁——即多个事务相互等待释放锁的情况——Spanner 采用了 wound-wait 算法。其基本规则如下：\n如果一个较晚启动的（年轻的）事务请求被较早启动（较老）的事务所持有的锁，则该年轻事务等待。 如果较老事务请求较年轻事务所持有的锁，则较年轻事务会被 “wound” （即中止），以便较老事务继续执行。 这种策略确保事务始终能够推进，避免形成死锁循环。 Spanner 的设计确保了数据即使在故障情况下也能保持一致性和可用性。所有写操作的数据均存储于 Google 的 Colossus 分布式文件系统中，该系统通过将数据复制到多台物理机器上，即使部分机器或区域出现故障，也能从其他副本中恢复数据。TrueTime 则确保了在分布式环境中事务的全局一致排序，保证一旦某事务对一个客户端可见，则对所有客户端均可见。\nTrueTime 技术 TrueTime 是 Cloud Spanner 的一项关键创新，使其能够作为一个全球分布、强一致性的数据库运行。TrueTime 解决了分布式系统中最具挑战性的问题之一：如何在分布于多个区域和数据中心的节点间提供全球同步和一致的时间视图。\nTrueTime 基于原子钟和 GPS 时钟的组合工作，二者协同提供高度准确和可靠的时间同步：\n原子钟：基于原子振动频率计时，提供极高精度、漂移极小的时间测量。在 GPS 信号中断或不准确时，原子钟能保证时间的准确性。 GPS 时钟：依靠卫星信号提供准确的全球同步时间。但 GPS 系统可能会遇到干扰、天线故障，甚至伪造攻击的问题。 TrueTime 不将时间表示为单一的点，而是表示为一个时间区间，明确体现了分布式系统中固有的不确定性：\nTTInterval：TrueTime 提供一个时间范围 [earliest, latest]，保证实际的全球时间落在此区间内。区间宽度由时钟漂移和网络延迟等因素决定。 误差范围与同步：通过大约每 30 秒与时间主机（原子钟和 GPS 时钟）同步一次，系统可将不确定性区间保持在一个较小的范围内（通常在 10 毫秒以内）。 TrueTime 具有以下重要特性，使其在分布式数据库中发挥关键作用：\n全局外部一致性：确保所有副本中事务以相同的全局顺序进行序列化。例如，如果某事务提交早于另一事务开始，TrueTime 能保证时间戳反映这种全局顺序。 无锁读取事务：允许 Spanner 执行无锁的只读请求，这些事务可以在不加锁的情况下访问数据的一致快照，从而提升系统扩展性和性能。 原子模式更新：在分布式系统中，模式更改（如修改表结构）通常十分复杂。TrueTime 将模式更新视为具有特定时间戳的事务，确保所有服务器一致地应用更改。 历史数据读取：TrueTime 允许基于指定时间戳读取数据的一致快照，方便进行审计或调试。 总结 Google Spanner 在数据库工程领域是一项重大突破，它完美地将传统关系型数据库的可靠性和结构性与 NoSQL 系统的可扩展性和全球可用性相结合。通过创新的架构设计，依靠 Paxos 共识机制以及 TrueTime 技术，Spanner 能够高效地处理分布式事务、保证外部一致性，并在全球范围内保持高性能运行。\nGoogle Spanner 正在重新定义分布式数据库系统的可能性，为可扩展性、可靠性和创新设定了新的标准。\n参考文献 Spanner: Google’s Globally-Distributed Database Life of Spanner Reads and Writes What is Cloud Spanner? Long Time Link If you find my blog helpful, please subscribe to me via RSS Or follow me on X If you have a Medium account, follow me there. My articles will be published there as soon as possible. ","date":"2025-02-06T10:01:23+08:00","permalink":"https://huizhou92.com/zh-cn/p/%E8%AF%91%E5%A6%82%E4%BD%95%E9%80%9A%E8%BF%87-google-spanner-%E5%AE%9E%E7%8E%B0%E4%B8%87%E4%BA%BF%E7%BA%A7%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8%E4%B8%8E5%E4%B8%AA%E4%B9%9D%E7%9A%84%E9%AB%98%E5%8F%AF%E7%94%A8%E6%80%A7/","title":"【译】如何通过 Google Spanner 实现万亿级数据存储与5个九的高可用性"},{"content":" 本文是最近一次关于DeepSeek在线讨论的总结，感兴趣的读者可以可以观看在线会议。\n录像录制文件：https://meeting.tencent.com/crm/Nxg95wna26 密码：2PBC\n最近，DeepSeek 在 AI 领域引发了广泛讨论。作为一个 AI 模型，其性能表现让整个行业为之一震，甚至被称为“AI 领域的拼多多”。这次技术突破不仅挑战了英伟达和 OpenAI 等巨头的传统叙事，也让全球 AI 产业重新评估开源模型的竞争力。\n在这篇文章中，我们将深入探讨 DeepSeek 的核心技术、其带来的产业冲击，以及未来 AI 发展可能的路径。\n一、推理效率的革命：从硬件优化到算法创新 近期AI领域最引人注目的进展之一，是推理效率的显著提升。通过KV缓存压缩、低精度计算（FP8) 等技术，模型的推理成本被压缩至传统方法的十分之一以下。这一突破并非依赖算力的简单堆砌，而是通过算法与硬件的协同设计实现。例如，动态剪裁冗余的中间状态生成、基于规则验证的奖励机制（Verifiable Reward），使得模型在长上下文推理中减少重复探索，显著提升有效token利用率。实验表明，优化后的模型在相同硬件条件下，推理速度可提升6-7倍，且错误率未出现显著波动。\n这一趋势对行业产生深远影响：边缘设备部署成为可能（如手机端运行复杂COT任务），同时倒逼闭源模型重新评估其商业逻辑——当开源模型以1/10 的成本实现95% 性能时，\u0026ldquo;算力霸权\u0026quot;叙事面临挑战。\n二、蒸馏技术的双刃剑：捷径还是天花板？ 蒸馏（Distillation）作为追赶闭源模型的核心手段，其本质是通过模仿教师模型的输出分布快速提升小模型性能。然而会议揭示了两大隐患：\n多样性丧失：过度依赖蒸馏会导致模型陷入\u0026quot;参考答案陷阱\u0026rdquo;，放弃独立探索能力。例如在数学推理中，模型可能通过记忆高频解题路径而非真正理解逻辑来\u0026quot;欺骗\u0026quot;评测指标； 能力天花板：蒸馏数据的质量直接受限于教师模型的能力边界。当闭源模型转向新一代架构（如非Transformer设计）时，蒸馏路径可能因底层能力不匹配而失效。 有趣的是，部分团队通过混合训练策略找到了平衡点：使用蒸馏数据冷启动模型，再通过强化学习（RL）注入自主探索能力。这种\u0026quot;先模仿后创新\u0026quot;的路径，或将成为追赶者的标准范式。\n三、开源VS闭源：生态博弈的新平衡 开源模型的爆发（如DeepSeek-R1）正在重构行业格局。其核心价值不仅在于技术透明性，更在于开发范式的根本转变\n场景定制化：开发者可通过微调小模型（如7B参数级别）在垂直领域达到商用级表现，而无需依赖闭源API的通用能力； 硬件去中心化：配合AMD MI300等异构计算架构，开源模型在非英伟达生态中展现出惊人适配性，打破算力垄断的潜在威胁； 安全可控性：闭源模型因数据隐私和监管风险，在金融、医疗等敏感领域的落地受阻，而开源方案提供了自主可控的替代路径。 但闭源阵营并非被动：OpenAI等头部玩家正通过超级算力押注（如500B StarGate项目),探索下一代架构，试图在智能边界上拉开代际差距。这场竞赛的本质，是\u0026quot;工程优化红利\u0026quot;与\u0026quot;原始创新风险\u0026quot;的博弈。\n四、算力需求的再思考：短期扰动与长期确定性 尽管高效模型降低了单次训练成本，但行业对算力的渴求并未减弱，而是呈现结构性分化：\n探索者：仍需投入天量算力验证新架构（如非Transformer模型）、多模态融合等高风险方向，单次实验成本可达千万美元级； 追赶者：通过算法改进（如MoE动态路由、数据筛选流水线）将同等性能的模型训练成本压缩80%，但需持续投入以应对闭源模型的代际跃迁； 应用层：推理算力需求呈指数增长，尤其是在实时Agent、多模态交互场景中，模型需在百毫秒内完成复杂决策链。 Meta等公司的资本开支指引（2025年同比增长60%）印证了这一点：算力投入正从\u0026quot;军备竞赛\u0026quot;转向\u0026quot;精准打击\u0026quot;，更强调单位算力的智能产出效率。\n五、中国团队的启示：小米加步枪的破局之道 中国AI团队的技术突破揭示了一条独特路径——在算力约束下极致优化工程能力。典型案例包括：\n数据效率革命：通过奖励验证机制（如数学问题可自动评判），将强化学习的数据需求量降低90%； 训练流水线创新：采用\u0026quot;预训练-蒸馏-强化学习\u0026quot;三阶段Pipeline，在2000张GPU集群上实现对标万卡规模的效果； 硬件异构适配：与国产芯片厂商深度合作，探索FPGA、ASIC等定制化方案替代通用GPU。 这种\u0026quot;压强式创新\u0026quot;虽难以突破绝对技术边界，却在应用落地上构建了独特优势。当行业进入\u0026quot;拼落地\u0026quot;阶段时，这种能力可能比单纯的技术领先更具杀伤力。\n六、未来展望：智能进化的下一站 推理与训练的边界消融：AlphaGo式的蒙特卡洛树搜索（MCTS）可能被引入语言模型，实现\u0026quot;动态思考-验证-迭代\u0026quot;的闭环推理； 过程奖励的突破：当前结果导向的奖励机制将被过程质量评估取代，如同围棋中对每一步棋的胜率预测； 多模态的本质价值：视觉-语言联合训练并非为了生成炫酷的图片，而是通过空间推理能力提升抽象问题解决水平（如几何证明）。 DeepSeek 的成功并非偶然，它代表了一种 AI 发展路线的变革，即更高效、低成本的 AI 训练方法。这场技术革命的核心矛盾，始终是探索者与追赶者的共生关系。 尽管短期内它无法彻底改变 AI 产业的格局，但其所引发的行业讨论，可能会对未来 AI 发展方向产生深远影响。开源 VS 闭源、高效优化 VS 极端算力派，这些问题将在未来几年持续主导 AI 产业的发展。\n本文长期链接 如果您觉得我的博客对你有帮助，请通过 RSS订阅我。 或者在X上关注我。 如果您有Medium账号，能给我个关注嘛？我的文章第一时间都会发布在Medium。 ","date":"2025-02-04T18:22:30+08:00","image":"https://images.hxzhouh.com/blog-images/2025/02/2a985170a85b4e9ac863fdbcfc54deb2.png","permalink":"https://huizhou92.com/zh-cn/p/deepseekai-%E7%AB%9E%E8%B5%9B%E4%B8%AD%E7%9A%84%E9%BB%91%E5%A4%A9%E9%B9%85zh-cn/","title":"DeepSeek：AI 竞赛中的黑天鹅"},{"content":"Go 1.24 引入了许多工具方面的重要更新，这些更新让开发者在管理依赖、调试问题以及编写更高质量代码时变得更加高效。尽管人们通常会将注意力集中在标准库或语言特性上的变化，但 Go 工具生态系统的改进同样值得关注。在本文中，我们将重点探讨两个关键领域的改进：go tool和vet工具，并通过实际示例展示这些更新如何优化你的工作流程。\nGo 命令的增强功能 在 Go 1.24 中，go 命令进行了多项改进，使得依赖管理和工具执行更加高效且易于使用。其中最显著的变化之一是 go.mod 文件中新增了 tool 指令，允许你直接跟踪可执行工具依赖，而无需依赖诸如空导入等不直观的解决方案。\n使用 Tool 指令跟踪可执行工具依赖 我们在项目中大量使用mockery[1]（一个流行的 Mock 代码生成器），使用方式是通过brew 安装或者直接下载特定版本的exe 执行文件。但是这样有个问题，如果不同开发者使用的mockery 版本不一致，会造成非预期的代码冲突。在过去，如果您想将这样的工具作为项目的一部分，你需要创建一个文件（通常命名为 tools.go），并通过空导入来声明这些工具。比如 go-modules-by-example[2] 中的 stringer\n而在 Go 1.24 中，你可以直接在 go.mod 文件中使用新的 tool 指令来显式声明这些依赖。例如：\n1 2 # 使用新 tool 指令安装 mockery $ gotip get -tool github.com/vektra/mockery/v2@v2.52.1 这条命令会在你的 go.mod 文件中添加一个 tool 指令：\n1 2 3 4 5 6 7 8 9 10 module your-project.com go 1.24 tool github.com/vektra/mockery/v2 require ( github.com/vektra/mockery/v2 v2.52.1 // indirect ... ) 现在，你可以通过 gotip install tool 安装特定版本的工具，或者直接使用下面的命令运行 mockery：\n1 gotip tool github.com/vektra/mockery/v2 --all --output ./mocks 我本地安装的mockery是2.32.3\n这种方式消除了单独管理安装过程或维护专门文件的需求。\n缓存可执行文件以加速运行 #69290[3] 另一个改进是，通过诸如 go run 或通过 go tool 执行的命令生成的可执行文件，现在会被缓存到 Go 的构建缓存中（Go 1.24 之前，cmd/go 仅缓存编译后的包文件）。这一改变显著加快了重复执行的速度。但是这样会增加缓存的使用。\nGo 会自动清理五天前[4]的编译后的包文件的缓存， 对于可执行文件的缓存，这个数字可能会是 2天。\n如果你正在开发过程中频繁使用自定义工具或脚本，这种缓存机制能够节省宝贵时间。\nVet 工具的增强功能 Go 的静态分析工具 Vet 在 1.24 中新增了一些分析器，并改进了诊断能力，可以帮助开发者更早地发现潜在问题和常见错误。\n新增 Tests 分析器 一个亮点是新增了 Tests 分析器，它可以识别测试声明中的问题，例如名称格式错误、不正确的函数签名或文档化不存在标识符的问题。这些问题可能导致测试未按预期运行。\n例如，以下代码存在错误：\n1 2 3 4 // 错误的测试函数签名（缺少 *testing.T 参数） func TestMyFunction() { fmt.Println(\u0026#34;This test will not run\u0026#34;) } 运行 go vet ./... 将会产生如下诊断信息：\n1 blog-example/go/go1.24/tools/demo_test.go:5:1: wrong signature for TestMyFunction, must be: func TestMyFunction(t *testing.T) 通过提前捕获此类错误，可以确保所有测试都能正确运行，而不会在 CI/CD 流程中出现意外问题。\n改进 Printf 分析器 现有的 Printf 分析器也得到了升级，可以检测到非常量格式字符串被传递但没有附加参数的问题——这通常会导致运行时错误或意外行为。例如：\n1 s := \u0026#34;Hello %s\u0026#34;fmt.Printf(s) // 如果 s 包含格式化占位符，将导致运行时问题。 Go1.23 版本不会出现错误，借助 Go 1.24 改进后的 Vet 工具诊断能力，会提示如下信息：\n1 ➜ tools git:(main) ✗ go vet ./...➜ tools git:(main) ✗ gotip vet ./...# blog-example/go/go1.24/tools# [blog-example/go/go1.24/tools]./demo_test.go:10:13: non-constant format string in call to fmt.Printf 要修复此问题，只需将 fmt.Printf(s) 替换为不需要格式化参数时更合适的方法，例如：fmt.Print(s)。\n结论 Go1.24 中还对以下工具进行了修改或者增强\nGo build支持生成伪版本号 #50603[5] 默认使能GOCACHEPROG以支持外部缓存 #64876[6] go 工具链支持HTTP扩展认证：GOAUTH#26232[7] go build支持-json #62067[8] \u0026hellip;. Go 1.24 中对工具生态系统的更新表明，即使是看似微小但实用性的变化，也能极大地提升开发者生产力和代码质量。通过 tool 指令直接跟踪可执行工具依赖，简化了依赖管理并减少了样板代码。而 vet 工具增强后的诊断能力，则帮助开发者更早地发现潜在 Bug 和常见错误，从而避免后续阶段的问题。\n随着 Go 的不断发展，密切关注这些工具方面的改进，可以确保你不仅充分利用标准库和语言特性，还能最大限度地提高开发效率与代码可靠性。\n引用链接 [1]mockery: https://github.com/vektra/mockery\n[2]go-modules-by-example: https://github.com/go-modules-by-example/index/blob/master/010_tools/README.md\n[3]#69290: https://github.com/golang/go/issues/69290\n[4]trimLimit: https://github.com/golang/go/blob/2707d42966f8985a6663c93e943b9a44b9399fca/src/cmd/go/internal/cache/cache.go#L335\n[5]#50603: https://github.com/golang/go/issues/50603\n[6]#64876: https://github.com/golang/go/issues/64876\n[7]#26232: https://github.com/golang/go/issues/26232\n[8]#62067: https://github.com/golang/go/issues/62067\n本文长期链接 如果您觉得我的博客对你有帮助，请通过 RSS订阅我。 或者在X上关注我。 如果您有Medium账号，能给我个关注嘛？我的文章第一时间都会发布在Medium。 ","date":"2025-02-02T12:00:49+08:00","permalink":"https://huizhou92.com/zh-cn/p/go124-%E9%99%A4%E4%BA%86%E6%A0%87%E5%87%86%E5%BA%93%E4%B9%8B%E5%A4%96%E6%82%A8%E4%B9%9F%E8%AE%B8%E5%BA%94%E8%AF%A5%E6%9B%B4%E5%8A%A0%E5%85%B3%E6%B3%A8-go-%E5%B7%A5%E5%85%B7%E7%9A%84%E5%8F%98%E5%8C%96/","title":"Go1.24: 除了标准库之外，您也许应该更加关注 Go 工具的变化"},{"content":"\nGo 1.24 的 Swiss Map：兼容性、扩展哈希与遗留问题 在 上一篇文章中，我介绍了swiss map跟 Dolthub 实现的一个Go语言版本。对于 swiss map 不太熟悉的读者，可以先去看看那篇文章。\n在即将正式发布的Go1.24中swiss map 将作为现有map的替代者正式进入gosrc。它完全兼容现有API，并且在部分benchmark场景下带来了超过50%的性能提升。到目前为止，swiss map是我对于Go1.24最期待的功能了。可是它真的有期待中的那么好嘛？本文将从兼容性、扩展哈希（Extendible Hashing的实现与优势，以及遗留问题三个方面，深入剖析这一新设计的核心逻辑。\n兼容性：无痛迁移的底层支持 Go 的swiss map 设计目标之一是与旧版 map 兼容。通过条件编译标签和类型转换，实现在新旧版本间的无缝切换。例如，在 export_swiss_test.go 中，newTestMapType 函数直接通过类型转换将旧版 map 的元数据转换为 swiss map 的类型结构：\n1 2 3 4 5 6 7 //https://github.com/golang/go/blob/3f4164f508b8148eb526fc096884dba2609f5835/src/internal/runtime/maps/export_swiss_test.go#L14 func newTestMapType[K comparable, V any]() *abi.SwissMapType { var m map[K]V mTyp := abi.TypeOf(m) mt := (*abi.SwissMapType)(unsafe.Pointer(mTyp)) // 直接类型转换 return mt } 这种设计允许现有代码无需修改即可通过实验性标志启用 swiss map，同时保留了旧版哈希表的内存布局兼容性。当前gotip(go1.24-3f4164f5) 中GOEXPERIMENT=swissmap 编译选项已经默认打开，也就是默认使用的是swiss map。\n如果您还是想用 原来的map可以使用 GOEXPERIMENT=noswissmap\nSwiss Map 的数据结构 Extendible Hashing：如何实现动态扩展？ 与其他其他几个社区实现，除了在兼容性方面的改进之外，swiss map的核心创新之一是采用了Extendible Hashing（扩展哈希），以支持高效的增量扩容。传统哈希表在扩容时需要全量迁移数据，而 Extendible Hashing 通过多级目录和表拆分，将扩容开销分摊到多次操作中。\nDir与table的层级结构 在 map.go 的 Map 结构体中，globalDepth 和 directory 字段是关键：\n1 2 3 4 5 6 //https://github.com/golang/go/blob/3f4164f508b8148eb526fc096884dba2609f5835/src/internal/runtime/maps/map.go#L194 type Map struct { globalDepth uint8 // dir的全局深度 dirPtr unsafe.Pointer // dir指针（指向多个 table） // ... } dir大小为 1 \u0026lt;\u0026lt; globalDepth，每个dir项指向一个 table。当某个 table 的负载过高时，会触发拆分（Split），而非全局扩容。\n拆分操作 拆分（Split）是 swiss map在单个表容量达到 maxTableCapacity（默认为 1024）时触发的动态扩容机制。其核心目标是将一个表的负载分摊到两个新表中，避免全局扩容的高延迟。以下是拆分的关键步骤与地址变化：\n拆分时，原表（假设为 table A）会创建两个子表 table Left 和 table Right。它们的 localDepth（本地深度）比原表大 1，表示其哈希掩码多使用了一个高位比特。\n1 2 3 4 5 6 7 8 //https://github.com/golang/go/blob/3f4164f508b8148eb526fc096884dba2609f5835/src/internal/runtime/maps/table.go#L1043 func (t *table) split(typ *abi.SwissMapType, m *Map) { localDepth := t.localDepth localDepth++ // 子表的 localDepth 比原表大 1 left := newTable(typ, maxTableCapacity, -1, localDepth) right := newTable(typ, maxTableCapacity, -1, localDepth) // ... } left 和 right 是新分配的内存对象，其 groups.data 指向新分配的连续内存块（通过 newarray 函数）。\n数据分配：哈希掩码与比特位判定 拆分时，根据哈希值的高位比特（由 localDepth 决定）将原表的数据分配到左表或右表。例如，若 localDepth 为 2，则使用哈希值的第 2 个高位比特（从最高位开始计数）作为分配依据。\n1 2 3 4 5 6 7 8 9 10 //https://github.com/golang/go/blob/3f4164f508b8148eb526fc096884dba2609f5835/src/internal/runtime/maps/table.go#L1052 mask := localDepthMask(localDepth) // 生成掩码，例如 0x80000000（第 32 位） for ... { hash := typ.Hasher(key, m.seed) if hash \u0026amp; mask == 0 { left.uncheckedPutSlot(...) // 分配到左表 } else { right.uncheckedPutSlot(...) // 分配到右表 } } 掩码计算：localDepthMask 根据 localDepth 生成一个掩码，例如： localDepth=1 → 0x80000000（32 位系统）或 0x8000000000000000（64 位系统）。 该掩码用于提取哈希值的第 localDepth 个高位比特。 3. 目录的更新与扩展 拆分完成后，需要更新全局目录（Map.directory），使原表的索引范围指向新的子表。如果原表的 localDepth 等于全局的 globalDepth，则目录需要扩展（翻倍）。\n目录扩展示例 假设原表 table A 的 localDepth=1，globalDepth=1，目录大小为 2（1 \u0026lt;\u0026lt; 1）。拆分后：\n目录翻倍：globalDepth 增加到 2，目录大小变为 4（1 \u0026lt;\u0026lt; 2）。 索引重映射：原表的目录项（例如索引 0-1）被替换为指向 left 和 right 表。 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 // map.go func (m *Map) installTableSplit(old, left, right *table) { if old.localDepth == m.globalDepth { // 目录扩展：大小翻倍 newDir := make([]*table, m.dirLen*2) // 复制旧目录项并指向新表 for i := range m.dirLen { newDir[2*i] = left newDir[2*i+1] = right } m.dirPtr = unsafe.Pointer(\u0026amp;newDir[0]) m.globalDepth++ } else { // 不扩展目录，仅替换部分项 entries := 1 \u0026lt;\u0026lt; (m.globalDepth - left.localDepth) for i := 0; i \u0026lt; entries; i++ { m.directorySet(uintptr(old.index+i), left) m.directorySet(uintptr(old.index+i+entries), right) } } } 地址变化： 原表 table A 的 dirPtr 指向的目录项被更新为新表的地址。 例如，原目录项 [A, A] 变为 [Left, Right]（扩展后目录为 [Left, Right, Left, Right]）。 示例：拆分前后的地址与目录变化 初始状态 全局目录：globalDepth=1，目录大小为 2，指向同一个表 A。 1 2 directory[0] → A (localDepth=1) directory[1] → A (localDepth=1) 触发拆分 创建子表：Left（localDepth=2）和 Right（localDepth=2）。 目录扩展：globalDepth 增加到 2，目录大小变为 4。 更新目录项： 1 2 3 4 directory[0] → Left // 哈希前缀 00 directory[1] → Left // 哈希前缀 01（原属于 A 的低半区） directory[2] → Right // 哈希前缀 10 directory[3] → Right // 哈希前缀 11（原属于 A 的高半区） 地址变化： directory[0] 和 directory[1] 的指针从 A 变为 Left。 directory[2] 和 directory[3] 的指针从 A 变为 Right。 拆分后的数据分布 假设原表 A 的哈希键分布如下：\n哈希值高位为 00 或 01 → 分配到 Left。 哈希值高位为 10 或 11 → 分配到 Right。 通过掩码 localDepthMask(2)（例如 0x40000000），提取哈希值的第 2 个高位比特，决定数据归属。\n关键设计优势 局部性：仅拆分负载高的表，其他表不受影响。 渐进式扩容：目录按需扩展，避免一次性全量迁移。 地址连续性：新表的 groups.data 是连续内存块，利于缓存优化。 其他优化 此外，swiss map 针对一些特定场景也有优化，比如针对于少量元素(\u0026lt;=8)就直接使用一个group来存储数据，尽量降低 swiss map 在少量数据的时候的性能劣势。\n遗留问题与挑战 尽管 swiss map 在设计与性能上迈出了一大步，但仍存在以下待优化点：\n并发支持的局限性 当前实现通过 writing 标志检测并发写入，但缺乏细粒度锁：\n1 2 3 4 5 6 //https://github.com/golang/go/blob/3f4164f508b8148eb526fc096884dba2609f5835/src/internal/runtime/maps/map.go#L478 func (m *Map) PutSlot(typ *abi.SwissMapType, key unsafe.Pointer) unsafe.Pointer { m.writing ^= 1 // 简单标志位，非原子操作 // ... } 这在多线程高并发场景下可能导致竞争条件。官方文档提到未来可能引入更复杂的同步机制，但目前仍需依赖外部锁。\n内存碎片化 swiss map 的 group 结构（8 控制字节 + 8 键值槽）可能导致内存对齐浪费，尤其是键值类型较小时。例如，若键为 int32、值为 int8，每个槽位将浪费 3 字节。\n迭代器复杂度 Iter 的实现（table.go）需处理目录扩展和表拆分，逻辑复杂：\n1 2 3 4 5 6 7 8 // https://github.com/golang/go/blob/3f4164f508b8148eb526fc096884dba2609f5835/src/internal/runtime/maps/table.go#L742 func (it *Iter) Next() { if it.globalDepth != it.m.globalDepth { // 处理目录扩展后的索引调整 it.dirIdx \u0026lt;\u0026lt;= (it.m.globalDepth - it.globalDepth) } // ... } 在频繁扩容的场景下，迭代器的性能可能受到影响。\n此外，在最新的代码中，遗留了很多TODO\n我甚至都不知道如何总结这些TODO， 目前距离 Go 1.24 正式发布还有不到一个月的时间，不知道这些TODO会不会全部解决。\n在社区中关于swiss map 的讨论也还有很多，主要集中在性能优化方面，可以想象未来 还会出现很多变动。\n一切都要等到2月份正式发布。\n性能测试 完整的测试代码：https://github.com/hxzhouh/gomapbench\ngo version devel go1.24-3f4164f5 Mon Jan 20 09:25:11 2025 -0800 darwin/arm64\n平均性能提升 28% 大约，在某些场景下，甚至高达 50%。不愧是Go1.24 最期待的功能。\n但是，这是一份不严谨的性能测试，测试机器也仅限于我自己的笔记本电脑，有一些报告显示swiss map 在某些地方的性能甚至出现了下降。\nhttps://x.com/valyala/status/1879988053076504761\nhttps://x.com/zigo_101/status/1882311256541102178\n最终swiss map 如何，还是要看后续的演化。\n总结 Go 1.24 的 swiss map 通过兼容性设计、Extendible Hashing 和优化的探测序列，显著提升了哈希表在高负载场景下的性能。然而，其并发模型和内存效率仍有改进空间。对于开发者而言，这一新特性值得在性能敏感的场景中尝试，但也需关注其当前限制。\n参考资料 https://tonybai.com/2024/11/14/go-map-use-swiss-table/\nhttps://github.com/golang/go/issues/54766\nhttps://pub.huizhou92.com/swisstable-a-high-performance-hash-table-implementation-3e13bfe8c79b\nhttps://www.geeksforgeeks.org/extendible-hashing-dynamic-approach-to-dbms/\n本文长期链接 如果您觉得我的博客对你有帮助，请通过 RSS订阅我。 或者在X上关注我。 如果您有Medium账号，能给我个关注嘛？我的文章第一时间都会发布在Medium。 ","date":"2025-01-23T14:19:09+08:00","permalink":"https://huizhou92.com/zh-cn/p/go-124-%E7%9A%84-swiss-map%E5%85%BC%E5%AE%B9%E6%80%A7%E6%89%A9%E5%B1%95%E5%93%88%E5%B8%8C%E4%B8%8E%E9%81%97%E7%95%99%E9%97%AE%E9%A2%98/","title":"Go 1.24 的 Swiss Map：兼容性、扩展哈希与遗留问题"},{"content":"对冲请求模式出现在论文The Tail At Scale中，是Google 解决微服务长尾效应的一个办法.也是gRPC中两种重试模式之一。\n对冲请求客户端将同一个请求发送到不同的节点，一旦收到第一个结果，客户端就会取消剩余的未处理请求。\n这种模式主要作用是为了实现可以预测的延迟。假设我们的服务的一个调用链路是20个节点，每个节点的P99是1s，从概率上讲，一定有 18.2% 的请求时间大于1s。\n通过对冲模式，我们每次都是从最快的节点那里得到结果，所以不会存在不可预测的长尾延迟(服务故障不在考虑范围之内) 。\n在Golang中，我们可以使用context很方便的实现对冲请求，比如在下面的例子中：对于同一个后端服务，我们发起五次请求，只取最先返回的那次。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 func hedgedRequest() string { ch := make(chan string) // chan used to abort other requests ctx, cancel := context.WithCancel(context.Background()) for i := 0; i \u0026lt; 5; i++ { go func(ctx *context.Context, ch chan string, i int) { log.Println(\u0026#34;in goroutine: \u0026#34;, i) if request(ctx, \u0026#34;http://localhost:8090\u0026#34;, i) { ch \u0026lt;- fmt.Sprintf(\u0026#34;finsh [from %v]\u0026#34;, i) log.Println(\u0026#34;completed goroutine: \u0026#34;, i) } }(\u0026amp;ctx, ch, i) } select { case s := \u0026lt;-ch: cancel() log.Println(\u0026#34;cancelled all inflight requests\u0026#34;) return s case \u0026lt;-time.After(5 * time.Second): cancel() return \u0026#34;all requests timeout after 5 secs\u0026#34; } } 完整的代码 请访问：https://go.dev/play/p/fY9Lj_M7ZYE\n这样做的好处就是，我们可以规避服务的长尾延迟，使服务的之间的延迟控制在可控的范围内。不过直接这么实现会造成额外的多倍负载。需要仔细设计。\n为什么会出现长尾延迟？ 出现长尾延迟的原因有很多，比如\n现在混合部署已经成为主流，意味着一台物理机上有很多人跟你抢夺关键资源，所以可能会因为关键资源调度，导致长尾效应 GC，这个不需要过多解释，Golang的 STW会放大长尾延迟 排队, 包括 消息队列、 网络等。 \u0026hellip;. 有什么办法可以避免对冲请求模式造成的 请求放大嘛？Go High-Performance Programming EP7: Use singleflight To Merge The Same Request 中详细介绍了如何使用 SingleFlight 来合并相同的请求。这个场景下面，使用SingleFlight 能够一定程度的缓解重复请求。\n还有一种做法是只发送一个请求, 到P95的时候，如果还没有收到返回，那么就立即向第二个节点发送请求。这样做的好处就是将重复请求缩小到5%。并且大大缩短了长尾请求。\n在这篇论文中，还有一些方法可以用来解决，长尾请求\n服务分级 \u0026amp;\u0026amp; 优先级队列(Differentiating service classes and\nhigher-level queuing)。差异化服务类别可以用来优先调度用户正在等待的请求，而不是非交互式请求。保持低级队列较短，以便更高级别的策略更快生效。 减少队头阻塞 ，将耗费时间比较多的请求，转换成比较小的请求。Web性能优化的时候有时候也会使用这种方式。 微分区(Micro-partition) 以细粒度来调整负载便可以尽量降低负载不均导致的延迟影响。 对于性能比较差的机器，采用熔断。 \u0026hellip;\u0026hellip; 你还有其他处理长尾请求的好方法吗？\n本文长期连接 如果您觉得我的博客对你有帮助，请通过 RSS订阅我。 或者在X上关注我。 如果您有Medium账号，能给我个关注嘛？我的文章第一时间都会发布在Medium。 ","date":"2025-01-16T14:44:41+08:00","permalink":"https://huizhou92.com/zh-cn/p/%E4%BD%BF%E7%94%A8%E5%AF%B9%E5%86%B2%E6%A8%A1%E5%BC%8F%E9%99%8D%E4%BD%8E%E9%95%BF%E5%B0%BE%E8%AF%B7%E6%B1%82/","title":"使用对冲模式降低长尾请求"},{"content":"场景描述 假设有这么一个场景： 假设100w个Uber司机，司机客户端每隔10分钟上报一次数据，如果十分钟没有上报数据，服务端会将这个司机设置为离线状态，不给他派单。\n我们应该如何实现这个功能？\n通常的情况下，我们会使用redis的zset等第三方组件来实现这个功能，但是如果不使用第三方组件呢？只使用内存呢？大概有这么几种方案：\n使用 Timer 用一个Map\u0026lt;uid, last_time\u0026gt;来记录每一个uid最近一次上报时间； 当某个用户uid存活上报时，实时更新这个Map； 启动一个timer，轮询扫描这个Map，看每个uid的last_time是否超过30s，如果超过则进行超时处理； 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 var ( userMap sync.Map timeout = 10 * time.Minute ) func checkTimeout() { now := time.Now().Unix() userMap.Range(func(key, value any) bool { uid := key.(string) lastTime := value.(int64) if now-lastTime \u0026gt; int64(timeout) { fmt.Printf(\u0026#34;User %s timed out. Last reported at %d\\n\u0026#34;, uid, lastTime) userMap.Delete(uid) } return true }) } 缺点：这种方式效率不高，因为需要定期轮询整个Map，时间复杂度较高。\n使用gorutine 管理 另一种方案是为每个司机分配一个Goroutine来管理其心跳超时。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 timer := time.NewTimer(timeout * time.Second) for { select { case \u0026lt;-heartbeat: // 收到心跳信号 if !timer.Stop() { \u0026lt;-timer.C } timer.Reset(timeout * time.Second) case \u0026lt;-timer.C: // 超时 fmt.Printf(\u0026#34;Driver %s timed out.\\n\u0026#34;, uid) break } } userMap.Delete(uid) 缺点：虽然不需要轮询，但每个Goroutine都有栈空间，当司机数量非常多时，内存消耗会很大。此外，Timer的创建和删除时间复杂度为O(log n)，效率有待提升。\n前面铺垫了这么久，终于轮到我们的主角了，时间轮。\n时间轮算法 时间轮是一个比较有趣的算法，他最早刊登在George Varghese和Tony Lauck的论文里。 时间轮算法的核心逻辑是：\n使用一个固定大小的数组表示时间轮，每个槽（slot）对应一个时间间隔。 每个slot中保存一个slice，用于存储当前时间段到期的任务，同时有一个Map\u0026lt;uid,slot\u0026gt; 记录uid对应的solt。 使用一个定时器定期(interval)推动时间轮向前走一格(position)，处理当前solt(position)的所有任务. 所以我们可以使用时间轮算法来实现功能。我们可以将interval设置成1s, 时间轮的slots为600，司机上报数据的时候，将记录插入到position-1的slot里面。\n一个简单的Demo:\nhttps://gist.github.com/hxzhouh/5e2cedc633bae0a7cf27d9f5d47bef01\n优势 时间轮算法添加任务只需要将任务append 到对应的slot里面，所以时间复杂度是O(1) 时间轮槽位固定，内存占用可控。 适合处理大量定时任务 劣势 时间轮的精度受限于interval 的大小。 如果任务分配不均匀的话，Delete Task 可能退化到 O(n) 所以时间轮特别适合以下场景的任务：\n大量任务的快速插入 对时间精度要求不是特别高的场景 任务分布相对均匀的情况 时间轮的优化 简单时间轮 将所有任务的换算为多少秒或毫秒(Interval)后到期，维护一个最大过期值(Interval)长度的数组。比如有10个任务，分别是1s，3s，100s 后到期，就建一个100长度的数组，数组的index就是每个任务的过期值(Interval)，当前时间作为第一个元素，那么第二个元素就是1s 后到期的任务，第三个是2s 后到期的任务，依次类推。当前时间随着时钟的前进(tick)，逐步发现过期的任务。\n开始调度一个任务(start_timer): 来一个新的调度任务时，换算任务的到期时间为到期值(Interval)，直接放入相应的数组元素内即可，时间复杂度是O(1)。 时钟走一格，需要做的操作(per_tick_bookkeeping)：时钟走一格直接拿出这一格内的任务执行即可，时间复杂度是O(1)。 Hash有序时间轮 （Demo中使用的就是这种方式的变种） 简单时间轮虽然很完美，所有的操作时间复杂度都是O(1)，但是当任务最大到期时间值非常大时，比如100w，构建这样一个数组是非常耗费内存的。可以改进一下，仍然使用时间轮，但是是用hash的方式将所有任务放到一定大小的数组内。 这个数组长度可以想象为时间轮的格子数量，轮盘大小(W)。\nhash的数值仍然是每个任务的到期值(Interval)，最简单的是轮盘大小(W)取值为2的幂次方，Interval哈希W后取余，余数作为轮盘数组的index，数组每个元素可能会有多个任务，把这些任务按照过期的绝对时间排序，这样就形成了一个链表，或者叫做时间轮上的一个桶。\n但是Hash有序时间轮 还是有一个问题:\n因为只使用了一个时间轮，处理每一格的定时任务列表的时间复杂度是 O(n)，如果定时任务数量很大，分摊到每一格的定时任务列表就会很长，这样的处理性能显然是让人无法接受的。\n层级时间轮 层级时间轮通过使用多个时间轮，并且对每个时间轮采用不同的 u，可以有效地解决简单时间轮及其变体实现的问题。\n参考 Kafka 的 Purgatory 中的层级时间轮实现：\n每一层时间轮的大小都固定为 n，第一层时间轮的时间单位为u，那么第二层时间轮（我们称之为第一层时间轮的溢出时间轮 Overflow Wheel）的时间单位就为 n*u，以此类推。 除了第一层时间轮是固定创建的，其他层的时间轮（均为溢出时间轮）都是按需创建的。 原先插入到高层时间轮（溢出时间轮）的定时任务，随着时间的流逝，会被降级重新插入到低层时间轮中。 总结 总结一下几种算法的性能。\n算法 添加任务复杂度 删除任务复杂度 内存开销 适用场景 Single Timer O(1)O(1) O(1)O(1) 低 适用于任务数量少、精度要求高的场景。 Multi Timer O(log⁡n)O(\\log n) O(log⁡n)O(\\log n) 中 适用于任务数量中等、任务间相互独立的场景，但内存开销较高。 Simple Timing Wheel O(1)O(1) O(n)O(n) 高（大数组） 任务分布均匀、到期时间精度要求较低的场景。 Hash Timing Wheel O(1)O(1) O(n)O(n) 中 任务数量较多、分布不均匀但对精度容忍较高的场景。 Hierarchical Timing Wheel O(1)O(1) O(log⁡n)O(\\log n) 低到中 适用于大规模任务、层级管理复杂任务、需要较长生命周期的任务调度场景（如 Kafka 和 Netty）。 参考资料 真实世界中的时间轮 Netty4 的 HashedWheelTimer。 Kafka 的 Purgatory。 go-zero 的NewTimingWheel Hashed and Hierarchical Timing Wheels 本文长期连接 如果您觉得我的博客对你有帮助，请通过 RSS订阅我。 或者在X上关注我。 如果您有Medium账号，能给我个关注嘛？我的文章第一时间都会发布在Medium。 ","date":"2025-01-14T21:18:02+08:00","image":"https://images.hxzhouh.com/blog-images/2025/01/12ffa89f8829f9122cee1eb9daacc043.webp","permalink":"https://huizhou92.com/zh-cn/p/%E9%AB%98%E6%95%88%E7%AE%A1%E7%90%86%E5%AE%9A%E6%97%B6%E4%BA%8B%E4%BB%B6/","title":"高效管理定时事件"},{"content":"背景 错误处理一直是编程中的重要组成部分, Go语言因为它独特的错误处理模式饱受争议，任何一篇写如何讨厌Go语言的博客中，一定会把“繁琐的错误处理”放在靠前的位置。这个问题在 Go 社区引发了大量讨论，探讨如何在保持清晰性和可维护性的同时减少模板代码。\nProposal 详情 ianlancetaylor提出了一个新的提案#71203 ,在 Go 中引入用于错误处理的操作符?。用来简化Go的错误处理。后续Go的错误处理可能会变成这个样子:\n1 2 3 4 5 6 7 // now result, err := someFunction() if err != nil { return nil, err } // proposal ? result := someFunction()? 在本例中，两种写法的结果是相等的：如果 someFunction()返回错误，就返回。\n这个proposal的 核心内容就是这样了, 主要目的是减少templ代码，同时保持 Go 的显式和简洁理念。？是一个语法糖，在返回多个值的函数调用（例如 (T, error)）之后使用时，它会自动检查最后一个值是否为非零（表示错误)。编译器将为 这种写法生成跟以前一样的代码，保证兼容性。\n在正式提案中，ianlancetaylor详细阐述了?的语法规则：\n?只能出现在赋值语句或表达式语句的末尾，并且表达式必须要有返回值 对于表达式语句，?“吸收”的是表达式的最后一个值（通常是err） 对于赋值语句，?“吸收”的是右侧表达式的最后一个值（通常是err），这样右侧值的数量会比左侧变量的数量多一个。 这个被“吸收”的值称为qvalue, 必须是实现了error接口的接口类型。 ?后面可以跟一个代码块。如果没有代码块，当qvalue不为nil时，函数会立即返回，并将qvalue赋给最后一个返回值。如果?后面有代码块，当qvalue不为nil时，代码块会被执行。在代码块中，会隐式声明一个名为err的变量，其值和类型与qvalue相同。 基本的使用场景可能是这样子的:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 r := os.Open(\u0026#34;file.txt\u0026#34;) ? // ? 吸收了 os.Open 的error, 如果不为空，就会返回。 func Run() error { Start() ? // 如果 Start 返回非 nil 的 error，立即返回该 error return nil } func process() error { result := doSomething() ? { return fmt.Errorf(\u0026#34;something failed: %v\u0026#34;, err) // qvalue } anotherResult := doAnotherThing(result)? return nil } 优点 这个 proposal 最重要（也是唯一的好处）好处是减少 Go 程序中的重复代码数量, 根据proposal 中的描述.\nreduces the error handling boilerplate from 9 tokens to 5, 24 non-whitespace characters to 12, and 3 boilerplate lines to 2.\n跟以前的错误处理提案try 等不同的是, ? 不会引入隐藏的控制流, ?的存在明确地指示了错误处理的逻辑。\n缺点 最大的缺点就是所有的Go图书、资料需要更新，并且对于新人来说，可能需要理解这个概念，因为它跟其他语言的实现都不太一样。并且这个改动，会涉及很多代码，包括go src，所以Go Core Team 的压力也很大，因为机会只有一次。\nErr 是隐式变量 ?后面的代码块会隐式声明一个err变量，这可能会导致变量shadowing的问题。 proposal 中提到了一个例子，\n1 2 3 4 5 6 7 8 9 10 11 for n = 1; !utf8.FullRune(r.buf[:n]); n++ { r.buf[n], err = r.readByte() if err != nil { if err == io.EOF { err = nil // must change outer err break } return } } // code that later returns err In this example, the assignment err = nil has to change the err variable that exists outside of the for loop. Using the ? operator would introduce a new err variable shadowing the outer one.\nIn this example, using the ? operator would cause a compiler error because the assignment err = nil would set a variable that is never used.\n在这个例子中，赋值 err = nil 必须改变存在于 for 循环之外的 err 变量。如果使用 ? 操作符，就会引入一个新的 err 变量，遮蔽外部变量。\n在本例中，使用 ? 操作符还会导致编译器错误，因为赋值 err = nil 会设置一个从未使用过的变量。\n写代码的心智负担会增加 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 func F1() error { err := G1() log.Print(err) G2() ? { log.Print(err) } return nil } func F2() error { err := G1() log.Print(err) G2() ? { log.Print(err) } return nil } 在这个例子中，这两个函数都合法，只有G2的换行符有差异，但它们的行为却完全不同。 这个差异可不能通过fmt等方式找补回来。\n不改变的合理性 尽管Go的错误处理机制经常受到批评，但它仍然是可用的。因此，社区需要权衡是否真的需要进行改变。在proposal中，ianlancetaylor反复提到: \u0026ldquo;Perhaps no change is better than this change. Perhaps no change is better than any change\u0026quot;。这也一定程度上反映出Go Core Team在错误处理改进方面其实并不那么坚定，感觉更多是迫于Go社区的舆论和压力。\n泛型: 别Q我\n总结 新的proposal可以看出Go Core Team 还是在听社区的声音。?操作符提案为Go语言的错误处理机制提供了一种新的思路。该提案通过引入简洁的语法，可以显著减少错误处理的代码量，并使代码的主流程更加清晰。尽管现在还存在一些分歧，但是总算有人在推动不是？\n本文长期连接 如果您觉得我的博客对你有帮助，请通过 RSS订阅我。 或者在X上关注我。 如果您有Medium账号，能给我个关注嘛？我的文章第一时间都会发布在Medium。 ","date":"2025-01-11T19:35:01+08:00","image":"https://images.hxzhouh.com/blog-images/2025/02/34ac61629c8b0d315d037016a7283331.png","permalink":"https://huizhou92.com/zh-cn/p/streamlining-error-handling-in-go-exploring-the-new-proposal/","title":"Go 中的错误处理:新的?运算符"},{"content":"原文链接：Go is a Well-Designed Language, Actually\n哈哈，没有泛型 —— 这是一句古老的程序员谚语。\n从诸多方面来看，2009 年为我未来的职业生涯埋下了伏笔。那时我 13 岁，刚在一场足球赛里打进了人生中的第一粒进球。那是一次精彩的二过一配合，最后我一记大力抽射，球直入球门左上角。可惜的是，那天球探不知去向。当我还憧憬着踏入温布利球场的那一刻，Go 语言诞生了。\nGo 语言很快就吸引了大批拥趸。大家钟情于它的简洁性，还有它对 Web 服务的优化，以及像 gofmt 这类实用工具。不过，凡事皆有两面，Go 语言也不例外。有人嫌弃它太过简单，抱怨它只能用来捣鼓蹩脚的 REST API，还吐槽那些过于 “热情” 的工具。\n在过去的 15 年里，人们写下了大量对 Go 语言的批评，甚至是愤怒的吐槽。其中让我格外留意的，是有人认为 Go 语言设计得很糟糕。这一观点在两篇文章里体现得尤为明显 —— 《我想摆脱 Golang 先生的狂野之旅》 和 《我们告诉自己继续使用 Go 的谎言》，均出自 fastthanlime 之手。后者更是直言：\n所以他们没有。他们没有设计语言。它就这么 “冒出来” 了。\n设计究竟是什么？ 在我看来，设计就是达成目标的计划或规范。打个比方，BBC 新闻网站的目标是向用户通报全球发生的、与他们切身相关的大事。为实现这一目标，网站会撰写新闻报道，再依据事件发生地和重要程度进行排序。毕竟，一枚朝我飞来的核弹，可比一只挂在树上的猫要紧要得多。\n所以，判断一个设计好不好，要看它能在多大程度上实现既定的设计目标。\nGo 语言的起源 Go 语言诞生于谷歌，Russ Cox、Rob Pike、Ken Thompson 等众多大咖都效力于谷歌。彼时，谷歌内部主要使用 Java 和 C++。Go 语言的设计者们觉得，这两门语言性能虽优，但用起来实在费劲。编译器慢吞吞的，工具还特别挑剔，而且它们的设计至少都是十年前的老黄历了。与此同时，云计算 —— 大量多核服务器协同作业，正变得日益普及。\n于是，他们决定打造一门属于自己的语言，优先考虑让它能在大规模的计算任务以及人力协作方面游刃有余。Rob Pike 在 Go at Google 一文中解释道：\n硬件规模庞大，软件亦是如此。软件动辄数百万行代码，服务器端大多用 C++ 编写，其余部分则大量采用 Java 和 Python。数千名工程师投身于代码编写工作。\n在别的场合，Rob Pike 一如既往地以谦逊、含蓄的口吻谈及他所面向的那数千名工程师：\n关键在于，我们的程序员是谷歌员工，而非科研人员。高深精妙的语言，他们可玩不转。\n重要提示：要是你正在搞设计，千万要避免贬低、居高临下地对待你的设计受众。\n尽管有这么一段引发争议的言论，不过我们还是能看出一个相当合理的设计目标：这门语言得让编写和维护大型并发服务器代码变得轻松容易，哪怕使用者是数千名技能水平参差不齐的开发人员。\n针对 Go 语言的批评 咱们来瞧瞧人们对 Go 语言的一些怨言，再依据它的设计目标来评判一番。\n文件系统 API Go 语言的文件系统 API 常常遭人诟病，原因是它太偏向 Unix 系统了。Windows 系统不像 Unix 那样有文件权限一说，所以 Go 语言只能返回一些形同虚设的权限。而且，Go 对路径的处理相当简单粗暴。操作系统有自己的路径分隔符，而路径在 Go 里就是 string 类型 —— 仅仅是一串字节，没有任何实质性的检查或限制（译者注：在 go 1.24 版本中使用 os.ROOT 会改善不少）。\n其他语言在这方面就严谨得多。比如 在 Rust 里获取文件修改时间的方法，有可能返回 None。Zig 语言里 文件的元数据会因操作系统而异。\n不过从设计目标的角度来看，这倒也情有可原。Go 语言本就是为谷歌量身打造的，和大多数服务器一样，谷歌的服务器 清一色用的是 Linux。要是你设计一门主打服务器应用的语言，以 Unix 为核心来打造文件系统 API，不失为一个明智之举。\n无运算符或函数重载 在 Go 语言里，和 Java 不同，函数和方法只有单一的定义（一旦指定了构建标签和目标）。与 C++ 迥异的是，运算符是在编译器里预先实现好的，无法重载。在 time 包里，要是想把 Duration 类型的值加到 Time 类型上，得用 Add 方法。要是你想增加两天，可不能像这样调用 Add(0 /*years*/, 0 /*months*/, 2 /*days*/)，而得用 AddDate 方法。\n在有些人眼里，这显得不够优雅，但它胜在简洁明了。在 Go 代码里看到函数调用，你心里清楚只需查看一处定义就行。要是瞅见一个运算符，你也明白它是针对内置类型的，干的肯定是靠谱的事儿，绝不会是 铸造 NFT 这种奇葩操作。\n费力的错误处理 公允地讲，当下编程语言的潮流是追求简洁。也难怪程序员们都反感 Go 语言里那种 if err!= nil 的错误处理风格。\n然而，这也是深思熟虑后的抉择：\n虽说相比之下，Go 语言检查错误的写法更啰嗦，但这种显式设计让控制流程一目了然 —— 就是字面意义上的清晰。\n清晰明了的控制流程让代码的可读性更强。虽说支持异常处理的语言写起代码来可能更快，但生成的代码没那么简洁，而且控制流程藏得很深。\nGo 语言常常因避开异常处理这类特性而饱受批评，有人觉得这简直是开倒车。曾经有人质问设计者：“为啥你们对 20 世纪 70 年代以来有关类型系统的研究成果一概无视？”。类似的论调 在别处也屡见不鲜。\n首先，Rob Pike 可瞧不上这种傲慢，也压根儿不 care：\nGo 旨在解决谷歌在软件开发过程中遭遇的难题，这就使得这门语言虽说算不上开创性的科研语言，但用来搞大型软件项目，那绝对是把好手。\n其次，将错误设计成明确的值，已然成为一种（再度）引领潮流的做法。Go、Rust 和 Zig 都选用了这种方式。Swift 语言即便支持异常，也要求你在函数签名里标明哪些函数可能会出错。\n可怜的 FFI 能力 译者注：FFI，中文名叫语言交互接口 (Foreign Function Interface)，指的是能在某种计算机语言里调用其他语言的接口。\nGo 语言与其他语言的兼容性欠佳。要是你想调用 C 函数，比如使用 SQLite，那就得通过 CGO。要知道，CGO 可不是纯正的 Go，还存在性能损耗。由于 goroutine（拥有由 Go 运行时设定的专属堆栈）是执行单元，Go 就得按照 C 语言的期望来做一些操作以获取堆栈，这成本可不低。\nGo 语言的 FFI 表现不佳，还因为它有自己的编译器、链接器和调试器。Go 生态系统里的好多东西都是定制化的。\n不过，考虑到设计目标的话，这也说得通。服务器软件必须支持并发，所以采用了 goroutine。这必然会让调用 C 代码变得复杂些，但这种权衡利弊，至少适配 Go 用于服务器间通信而非进程间通信的并发系统。\n这些决策也让 Go 语言在工具方面占尽优势。编译器是专为 Go 打造的，这意味着它能一门心思地快速编译 Go 代码。调试器能够理解 goroutine 以及 Go 的所有内置类型。\n那么 Go 语言很棒吗？ 这就见仁见智了。就我个人而言，我挺喜欢它的。我经手过的 Go 代码，读起来、理解起来通常都不费劲。它没有那些花里胡哨的东西，逼着我一门心思写实在的代码，而不是构建些华而不实的抽象概念。我还成功地向一大帮刚从大学毕业的新人传授过 Go 语言。\n但这并不意味着我对它的缺点视而不见。有一回，我跟一位客户通电话，他碰上一个错误，就因为没检查错误，我们费了好大劲才追踪到问题所在。要是开着 Linter，这事儿本可轻松避免，可要是没开，那就麻烦了。Go 语言长久以来都不支持泛型，编写泛型数据结构的时候可费劲了。每次收到一份关于 Windows 系统的错误报告，我都得停下来琢磨琢磨，是不是 Go 语言让我产生了一种错误的安全感？\n说到底，这些问题都是设计过程中有意权衡取舍的结果。你可以说不喜欢 Go 语言，或者它不适合某个应用场景，又或者它满足不了你的需求。甚至，你大可以直言讨厌它。但千万别断言它设计得糟糕。\n本文长期连接 如果您觉得我的博客对你有帮助，请通过 RSS订阅我。 或者在X上关注我。 如果您有Medium账号，能给我个关注嘛？我的文章第一时间都会发布在Medium。 ","date":"2025-01-09T18:42:34+08:00","image":"https://images.hxzhouh.com/blog-images/2025/01/3e744d40ce824be7a086698de46c5324.webp","permalink":"https://huizhou92.com/zh-cn/p/%E8%AF%91%E4%BA%8B%E5%AE%9E%E4%B8%8Ago-%E6%98%AF%E4%B8%80%E7%A7%8D%E8%AE%BE%E8%AE%A1%E8%89%AF%E5%A5%BD%E7%9A%84%E8%AF%AD%E8%A8%80/","title":"[译]事实上,Go 是一种设计良好的语言"},{"content":"近期，Dennis Schubert发布了一则帖子，称 “diaspora*” 项目的网络基础设施因为访问流量过大而陷入了性能瓶颈。令人震惊的是，他发现70% 的请求来自 IT 巨头公司的 LLM（大语言模型）爬虫。这些爬虫无视 robots.txt 文件，贪婪地抓取网站的所有可用数据，甚至是一些无关紧要的内容。\nDennis 感到无比愤怒，因为 ChatGPT 和 Amazon 的爬虫竟然爬取了 Wiki 的全部编辑历史，每一页的每次编辑都被记录下来。他质问：\n“他们到底要做什么？是想研究文本如何随时间变化吗？”\n这种对数据的无底线掠夺，导致服务器负载极高，用户访问体验显著下降。Dennis 尝试了一些反制措施：\n更新 robots.txt：无效，爬虫无视规则。 限制访问速率：失败，爬虫会快速更换 IP。 屏蔽 User Agent：没用，爬虫伪装成普通用户。 最终 Dennis 感慨，这种行为已经接近于对整个互联网的DDoS 攻击。\n为什么 IT 巨头需要爬我们的数据？ 答案是：AI 数据饥荒。\n随着大模型的普及，用于训练 AI 的高质量语料已经见底。正如 OpenAI 工程师 James Betker 所言：\n“模型优劣的关键在于数据集的质量。它们正在以惊人的精度复刻数据集。”\n为了在 AI 竞赛中领先，巨头们不惜一切代价获取更多数据。个人网站、自建 Wiki，这些原本属于小众的内容，正成为巨头们争相攫取的目标。\n我们能够应对吗？ IT 巨头拥有顶尖的爬虫和反爬虫技术团队，能够在抓取与用户体验之间找到平衡。但对于个人网站和小型项目来说，这无疑是一场不对等的战争。\nDennis 提出了以下两种反制策略：\nTarpit 技术：生成无意义的随机文本，诱导爬虫抓取无关内容。 JavaScript 陷阱：让 AI 爬虫加载 JavaScript 才能获得数据，而这些脚本可能暗含挖矿代码。 尽管这些方法可能有效，但实现起来成本不菲。\n没有链接的互联网 巨头公司的终极目标是什么？\n是将用户牢牢锁定在他们的生态系统中。通过 AI 提供“最优内容”，用户无需访问其他网站，甚至看不到其他链接。一切内容直接呈现，广告作为附加品，而创作者只能沦为巨头的数据供应商。\n这种趋势正在瓦解互联网的开放性。\n无论你如何优化 SEO 或产出优质内容，巨头的 AI 会优先抓取并整合，用户永远不会直接访问你的网站。最终，个人创作者将失去流量与收入，整个互联网变成巨头的“金矿”。\n总结 IT 巨头正在用技术手段，掠夺数据，榨取价值，逐步摧毁互联网的多样性与开放性。对于个人网站而言，我们几乎无力抗争，而这场改变已经不可逆。\n引用资源： Dennis Schubert 的帖子 The IT in AI Models is the Dataset TechSpot：The Zero-Click Internet 本文长期连接 如果您觉得我的博客对你有帮助，请通过 RSS订阅我。 或者在X上关注我。 如果您有Medium账号，能给我个关注嘛？我的文章第一时间都会发布在Medium。 ","date":"2025-01-09T16:01:05+08:00","image":"https://images.hxzhouh.com/blog-images/2025/01/589319fe1c17cafde315ff3dab8b3f24.webp","permalink":"https://huizhou92.com/zh-cn/p/it-%E5%B7%A8%E5%A4%B4%E6%AD%A3%E5%9C%A8%E6%9D%80%E6%AD%BB%E4%BB%96%E4%BB%AC%E7%9A%84%E5%AE%A2%E6%88%B7/","title":"IT 巨头正在杀死他们的客户"},{"content":"在软件开发中，你是否遇到过这种情况：\n你正在开发一个购物车的功能，需要在用户添加商品到购物车时，将商品的信息存储到数据库中。你设计了一个简单的方法，如下所示：\n1 2 3 4 func addToCart(item Item) { // add to db .... } 在这个方法中，你假设了将商品信息存储到数据库的操作总是会成功，而没有考虑到可能会出现任何错误。然而，在实际情况中，可能会发生各种错误，例如数据库连接失败、写入失败、数据格式不正确等。\n如果你只是假设操作总是会成功，并且没有考虑到错误情况，那么你就会遇到海勒姆定律的问题。\n什么是海勒姆定律呢？其有什么意义和启示呢，下面我们来具体看一下吧。\n什么是海勒姆定律 海勒姆定律（Hyrum\u0026rsquo;s Law）是一个软件开发中的概念，它指的是：\n“当你依赖于一个 API 的时候，你实际上也依赖于这个 API 的实现细节。”\n换句话说，即使一个 API 已经被定义和文档化了，但由于实现的方式可能存在多种选择，所以你在使用这个 API 的时候也要考虑到其实现的细节，而不仅仅是其所声明的功能。\n海勒姆定律得名于 Google 工程师 Hyrum Wright，他在一次演讲中提出了这个概念。\nHyrum Wright强调了开发者应该更加注意 API 的实现细节，因为这些细节可能会影响到你的代码在未来的可维护性和稳定性。\n海勒姆定的意义 海勒姆定律（Hyrum\u0026rsquo;s Law）是一条关于软件开发中 API 使用的规律。其意义在于以下3点：\n海勒姆定律的意义在于提醒开发人员，当使用 API 时不仅要考虑其功能，还要了解其实现细节和限制。在软件开发过程中，API 是非常常见的工具，它们可以帮助我们快速实现功能，提高开发效率。\n然而，API 的实现方式和细节可能会对代码的行为产生影响，甚至可能导致不可预料的问题。海勒姆定律强调了这一点，提醒开发人员在使用 API 时需要仔细评估其实现细节和稳定性，以避免出现潜在的问题，提高代码的可维护性和稳定性。\n此外，海勒姆定律还强调了软件开发的迭代性和变化性。随着软件需求和技术环境的不断变化，API 的实现方式也可能随之发生变化。因此，及时了解并适应 API 的变化，对于保持软件的可维护性和稳定性也非常重要。\n一个案例 在Golang的源码中，其实也有Hyrum\u0026rsquo;s Law 的影子\n比如 ./src/net/http/request.go:1199\n1 2 3 4 func (e *MaxBytesError) Error() string { // Due to Hyrum\u0026#39;s law, this text cannot be changed. return \u0026#34;http: request body too large\u0026#34; } 是不是有点奇怪？修改一个Error Message 可能会影响到其他用户。\n我自己也遇到过类似问题，上游数据库修改了ErrCode导致我的业务失败。\n海勒姆定律的实践建议 以下是一些有助于在实践中落实海勒姆定律的建议：\n了解 API 的文档和规范。 在使用 API 之前，应该先仔细阅读相关文档和规范，了解 API 的功能、用法、限制和可能的问题。 编写健壮的代码。 在使用 API 时，应该编写健壮的代码，考虑到各种可能的错误和异常情况，以保证代码的可靠性和稳定性。 使用稳定的 API 版本。 如果有多个版本的 API 可以选择，应该尽量选择稳定的版本，并尽量避免使用过时或废弃的版本。 进行集成和单元测试。 在使用 API 时，应该编写集成测试和单元测试，验证 API 的正确性和稳定性，并及时修复可能出现的问题。 注意 API 的依赖关系。 在使用 API 时，应该注意其依赖关系，避免引入不必要的依赖，同时也要确保其依赖的组件或库是可靠的和稳定的。 及时处理 API 的变更。 随着软件需求和技术环境的变化，API 的实现方式也可能随之发生变化。在使用 API 时，应该及时了解并适应 API 的变更，以保持软件的可维护性和稳定性。 综上所述，在通过遵循这些实践建议，可以更好地落实海勒姆定律，提高代码的可维护性和稳定性，同时也能够更好地适应软件开发过程中的变化和创新。\n海勒姆定律的反模式 除了常见的实践建议外，以下是一些常见的反模式，这些做法不利于落实海勒姆定律：\n直接依赖具体实现。 有些开发人员可能会直接依赖具体实现，而忽略了 API 的规范和约定。这种做法会使代码与实现紧密耦合，增加了代码的脆弱性和难以维护性。 忽略 API 的限制和异常。 有些开发人员可能会忽略 API 的限制和异常情况，而直接假定 API 总是能够正常工作。这种做法会增加代码的不确定性和出错概率，导致代码的不可靠性和难以维护性。 直接使用底层库或组件。 有些开发人员可能会直接使用底层库或组件，而忽略了 API 的规范和封装。这种做法会使代码与底层实现紧密耦合，增加了代码的复杂性和难以维护性。 忽略 API 的版本变更。 有些开发人员可能会忽略 API 的版本变更，而仍然使用过时或废弃的版本。这种做法会增加代码的不兼容性和难以维护性，同时也会使代码与技术发展脱节。 不合理地添加或删除依赖。 有些开发人员可能会不合理地添加或删除依赖，而忽略了 API 的依赖关系和稳定性。这种做法会使代码的依赖关系变得混乱和不可控，增加了代码的复杂性和难以维护性。\n综上所述，避免这些常见的反模式，能够更好地落实海勒姆定律，提高代码的可维护性和稳定性，同时也能够更好地适应软件开发过程中的变化和创新。 最后 海勒姆定律是一个非常重要的原则。其告诉我们，在处理复杂系统时，我们不能只关注系统的主要功能，还需要考虑系统中的各种依赖关系和副作用。\n如果我们只是假设一切都是正确的，并没有考虑到系统的各种依赖关系和副作用，那么就会遇到各种意外和问题，这可能会导致系统崩溃或出现其他严重问题。\n在编写代码时，我们应该注意避免海勒姆定律的陷阱，并考虑使用一些最佳实践来确保代码的稳定性和可靠性。\n总之，海勒姆定律的重要性不能被忽视。对于开发人员来说，了解这个原则，并在实践中应用它，将有助于提高代码的质量和稳定性，从而为用户提供更好的体验。\n本文长期连接 如果您觉得我的博客对你有帮助，请通过 RSS订阅我。 或者在X上关注我。 如果您有Medium账号，能给我个关注嘛？我的文章第一时间都会发布在Medium。 ","date":"2025-01-08T11:52:37+08:00","permalink":"https://huizhou92.com/zh-cn/p/%E8%BD%AF%E4%BB%B6%E5%B7%A5%E7%A8%8B%E6%B5%B7%E5%8B%92%E5%A7%86%E5%AE%9A%E5%BE%8B/","title":"软件工程：海勒姆定律"},{"content":"缘起 最近上线了一个新服务，有一个采集接口占用的带宽比较多，这个接口很简单，我有点好奇，一个https 请求会传输多少数据, 他会比HTTP请求多多少数据？\n我写了一个demo在本地测试一下\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 func helloHandler(w http.ResponseWriter, r *http.Request) { fmt.Fprintf(w, \u0026#34;Hello, World!\u0026#34;) } var port int func init() { flag.IntVar(\u0026amp;port, \u0026#34;port\u0026#34;, 8082, \u0026#34;port to listen on\u0026#34;) flag.Parse() } func main() { http.HandleFunc(\u0026#34;/\u0026#34;, helloHandler) fmt.Println(fmt.Sprintf(\u0026#34;Starting server at port %d\u0026#34;, port)) if err := http.ListenAndServe(fmt.Sprintf(\u0026#34;:%d\u0026#34;, port), nil); err != nil { fmt.Println(\u0026#34;Error starting server:\u0026#34;, err) } } 然后在本地使用 caddy 提供https\n1 2 3 4 5 6 7 8 http://your-domain.com { reverse_proxy 127.0.0.1:8082 } https://your-domain.com { reverse_proxy 127.0.0.1:8082 tls internal } 最后用wireshark抓包，我惊奇的发现。 一个简单的HTTPS 请求会传输2164 个 bytes 数据。\n假设 并发为500QPS，那么这个接口所需要的带宽为：\n2164×8×500/1000000 ≈ 8.656Mbps\nHTTPS全称是：HTTP over TLS，每次建立新的TCP连接通常需要进行一次完整的TLS Handshake。在握手过程中，客户端和服务器需要交换证书、公钥、加密算法等信息，这些数据占用了较多的字节数。\nTLS Handshake的内容主要包括：\n客户端和服务器的随机数 支持的加密算法和TLS版本信息 服务器的数字证书（包含公钥） 用于生成对称密钥的“Pre-Master Secret”\n这个过程不仅耗时，还会消耗带宽和CPU资源。\n因此想到最粗暴的解决方案也比较简单，就是直接使用 HTTP，省去TLS Handshake的过程，那么自然就不会有 TLS 的传输了。\n那么是否真的有效呢？验证一下就知道。 相同的请求，http接口只需要 223 bytes，大约只需要https请求的 1/10。\n结论 在绝大多数情况下，HTTPS 是首选，提供了更好的安全性和SEO，但是在一些内部网络或者高性能需求的受控环境，还有传输非敏感数据的时候，比如内网数据采集等，可以选择使用HTTP来优化性能。\n当然，https 也可以优化 TLS Handshake 这个过程，那就是 Keep-Alive 。Keep-Alive是一种连接复用机制，允许在一次 TCP 连接上进行多次请求-响应交互，而无需为每个请求都建立新的连接。它显著减少了 HTTPS 中的连接建立和关闭开销，提升性能。\n","date":"2025-01-06T16:06:24+08:00","permalink":"https://huizhou92.com/zh-cn/p/%E7%9B%B8%E5%90%8C%E7%9A%84%E8%B4%9F%E8%BD%BD-https%E6%95%B0%E6%8D%AE%E5%8C%85%E5%8F%AF%E8%83%BD%E6%AF%94-http%E5%A4%A710%E5%80%8D/","title":"相同的负载, HTTPS数据包可能比 HTTP大10倍"},{"content":"Goroutine 的状态 在 golang 中，我们使用go 创建一个新的gorotine,我们都知道操作系统线程有自己的状态， 比如 在 The time in computers: how long will it take to switch the context? 中，我们总结了线程的状态以及线程调度耗时。\ngoroutine也是一样的，有自己的状态，并且它的状态由 runtime 控制。\n在 rimetime2.go 中定义了goroutine 的数据结构。g.atomicstatus 表示 goroutine 的状态。它的取值范围在源码中也有定义。\n除了几个已经不被使用的以及与 GC 相关的状态之外，Goroutine 可能处于以下 9 种状态：\n状态 描述 _Gidle 刚刚被分配并且还没有被初始化 _Grunnable 没有执行代码，没有栈的所有权，存储在运行队列中 _Grunning 可以执行代码，拥有栈的所有权，被赋予了内核线程 M 和处理器 P _Gsyscall 正在执行系统调用，拥有栈的所有权，没有执行用户代码，被赋予了内核线程 M 但是不在运行队列上 _Gwaiting 由于运行时而被阻塞，没有执行用户代码并且不在运行队列上，但是可能存在于 Channel 的等待队列上 _Gdead 没有被使用，没有执行代码，可能有分配的栈 _Gcopystack 栈正在被拷贝，没有执行代码，不在运行队列上 _Gpreempted 由于抢占而被阻塞，没有执行用户代码并且不在运行队列上，等待唤醒 _Gscan GC 正在扫描栈空间，没有执行代码，可以与其他状态同时存在 上述状态中比较常见是 _Grunnable、_Grunning、_Gsyscall、_Gwaiting 和 _Gpreempted 五个状态，这里会重点介绍这几个状态。Goroutine 的状态迁移是个复杂的过程，触发 Goroutine 状态迁移的方法也很多，在这里我们也没有办法介绍全部的迁移路线，只会从中选择一些介绍。 虽然 Goroutine 在运行时中定义的状态非常多而且复杂，但是我们可以将这些不同的状态聚合成三种：等待中、可运行、运行中，运行期间会在这三种状态来回切换：\n等待中：Goroutine 正在等待某些条件满足，例如：系统调用结束等，包括 _Gwaiting、_Gsyscall 和 _Gpreempted 几个状态； 可运行：Goroutine 已经准备就绪，可以在线程运行，如果当前程序中有非常多的 Goroutine，每个 Goroutine 就可能会等待更多的时间，即 _Grunnable；这个时候Goroutine 在 P的local queue 或者 全局队列中。 运行中：Goroutine 正在某个线程上运行，即 _Grunning；\nGrunnable goroutine在下列几种情况会设置为Grunnable状态：\n创建goroutine 在go中，包括用户入口main.mian在内的所有goroutine都是通过runtime.newproc-\u0026gt;runtime.newproc1创建的，前者是对后者的一层封装。go关键字最终会被编译器映射为对runtime.newproc的调用。当runtime.newproc1完整资源分配及初始化后，新任务的状态会被置为Grunnable，然后被添加到当前P的本地任务队列中。\n1 2 3 4 5 6 7 8 9 10 11 12 13 func newproc1(fn *funcval, argp unsafe.Pointer, narg int32, callergp *g, callerpc uintptr) { // --snip-- // 获取当前g所在的p，从p中创建一个新g(newg) _p_ := _g_.m.p.ptr() newg := gfget(_p_) // --snip-- // 设置Goroutine状态为Grunnable casgstatus(newg, _Gdead, _Grunnable) // --snip-- // // 新创建的g添加到run队列中 runqput(_p_, newg, true) // --snip-- } 阻塞任务唤醒 当某个阻塞任务(Gwaiting)的等待条件满足而被唤醒时。（如g1项channel写入数据将唤醒等待接收的)，g1通过调用runtime.ready将g2状态重新置为Grunnable并添加到任务队列中。关于groutine阻塞，还有更详细的介绍。\n1 2 3 4 5 6 7 8 9 10 func ready(gp *g, traceskip int, next bool) { // --snip-- // 获取current g _g_ := getg() // 将状态从Gwaiting转换至Grunnable casgstatus(gp, _Gwaiting, _Grunnable) // 添加到运行队列中 runqput(_g_.m.p.ptr(), gp, next) // --snip-- } 其他 另外的路径是从Grunning和Gsyscall状态转换到Grunnable，后面再介绍。总之处于Grunnable的任务一定是在某个任务队列中，随时等待被调度执行。\nGrunning 所有状态为Grunnable的任务都可能通过findrunnable函数被调度器(P\u0026amp;M)获取，进而通过execute将其状态切换到Grunning，最后调用runtime.gogo加载context并执行。\n1 2 3 4 5 6 7 8 9 10 11 // One round of scheduler: find a runnable goroutine and execute it. // Never returns. func schedule() { // --snip-- // 挑一个可运行的g，并执行 if gp == nil { gp, inheritTime = findrunnable() // blocks until work is available } // --snip-- execute(gp, inheritTime) } 1 2 3 4 5 6 7 8 9 10 11 12 // Schedules gp to run on the current M. func execute(gp *g, inheritTime bool) { // 将当前g的M切换到新的g上 _g_ := getg() _g_.m.curg = gp gp.m = _g_.m // 将Grunnable状态变更为Grunning casgstatus(gp, _Grunnable, _Grunning) // --snip-- // 真正执行goroutine gogo(\u0026amp;gp.sched) } go采取的是一种协作式调度方案，一个正在运行的任务，需要通过yield的方式显式的让出处理器。\n在Go1.2之后，runtime也支持一定程度的任务抢占–当系统线程sysmon发现某个任务执行时间过长或者runtime判断需要进行垃圾收集时，会将任务置为“可被抢占”的，当该任务下一次函数调用时，就会让出处理器并重新切换到Grunnable状态。\nGsyscall Go运行时为了保证高的并发性能，当会在任务执行OS系统调用前，先调用runtime.entersyscall函数将自己的状态置为Gsyscall(如果系统调用是阻塞式的或者执行过久，则将当前M与P分离)，当系统调用返回后，执行线程调用runtime.exitsyscall尝试重新获取P，如果成功且当前任务没有被抢占，则将状态切换回Grunning并继续执行；否则将状态置为Grunnable，等待再次被调度执行。\n1 2 3 4 5 6 7 8 9 10 11 12 func reentersyscall(pc, sp uintptr) { _g_ := getg() // --snip-- casgstatus(_g_, _Grunning, _Gsyscall) // --snip-- // 将m和p分离 pp := _g_.m.p.ptr() pp.m = 0 _g_.m.oldp.set(pp) _g_.m.p = 0 // --snip-- } 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 func exitsyscall() { _g_ := getg() // --snip-- // 如果P还存在则重新获取P if exitsyscallfast(oldp) { // --snip-- casgstatus(_g_, _Gsyscall, _Grunning) // --snip-- return } // --snip-- // 如果P不存在则Gsyscall-\u0026gt;Grunnable mcall(exitsyscall0) // --snip-- } Gwaiting 当一个任务需要的资源或运行条件不能被满足时，需要调用runtime.park函数进入该状态，之后除非等待条件满足，否则任务将一直处于等待状态不能执行。除了之前举过的channel的例子外，Go的定时器，网络io操作，原子，信号量都可能引起任务的阻塞。\n1 2 3 4 5 6 // park continuation on g0. func park_m(gp *g) { // --snip-- casgstatus(gp, _Grunning, _Gwaiting) // --snip-- } 1 2 3 4 func gopark(unlockf func(*g, unsafe.Pointer) bool, lock unsafe.Pointer, reason waitReason, traceEv byte, traceskip int) { // --snip-- mcall(park_m) } runtime.park中lock是goroutine阻塞时需要释放的锁，(比如channel)，reason是阻塞的原因，方便gdb调试。当所有任务处于Gwaiting状态时，也就表示当前程序进入了死锁状态，那么runtime回检测到这种情况，并输出所有Gwaiting任务的backtrace信息。\nGdead 当一个任务执行结束后，会调用runtime.goexit结束。将状态置为Gdead，并进入当前P的gFree列表。\n总结 goroutine的状态切换跟线程状态切换其实差不多，不过，因为gc的原因导致看上去复杂一点。但是如果去掉gc部分，其实goroutine 状态的切换跟 线程状态切换差不多。\n下一篇文章，我将会总结分析一下 P的状态切换。\n","date":"2025-01-06T10:35:19+08:00","permalink":"https://huizhou92.com/zh-cn/p/goroutine-%E7%9A%84%E7%8A%B6%E6%80%81-%E5%88%87%E6%8D%A2/","title":"goroutine 的状态 切换"},{"content":" htmx 是一种全新的前端开发工具，基于现有的 HTML、CSS 和 JavaScript 技术的一种补充，而不是完全取代它们。\n可以将 htmx 与其他技术和工具（如 Vue.js、React、Angular 等）结合使用,它的核心理念是“使用 HTML 作为应用程序的编程语言”，\n即通过在 HTML 标记中添加各种属性来实现动态行为，而无需编写大量的 JavaScript 代码。\nHtmx 的设计理念 利用已经熟悉的 HTML 和 CSS 知识，无需或很少需要编写 JavaScript 代码。 降低前端开发的复杂性，减少对复杂 JavaScript 框架的依赖。 使代码更易读易维护，通过声明式的标记直接在 HTML 中指定行为。 实现渐进增强，让 web 应用能够在不同程度的技术堆栈上运行，增强兼容性和可访问性。 htmx 通过提供一系列自定义的 HTML 属性，使得开发者能够简化 JavaScript 使用，仅通过 HTML 标签就可实现原本需要复杂脚本才能完成的动态交互功能。这样，开发者可以专注于内容和结构，而不是行为逻辑的实现细节，从而在开发现代 web 应用时更加快速和高效。\n安装使用 要安装并开始使用 htmx，你可以通过以下几种简单的方式将它集成到你的网页中。\n1 通过 CDN 引入 直接在你的 HTML 文件中添加以下 \u0026lt;script\u0026gt; 标签来加载 htmx。将这段代码放到 \u0026lt;head\u0026gt; 或者 \u0026lt;body\u0026gt; 标签的末尾。\n1 \u0026lt;script src=\u0026#34;https://unpkg.com/htmx.org\u0026#34;\u0026gt;\u0026lt;/script\u0026gt; 或者，你也可以使用其他 CDN 服务或指定特定版本的 htmx：\n1 \u0026lt;script src=\u0026#34;https://cdn.jsdelivr.net/npm/htmx.org@1.6.0\u0026#34;\u0026gt;\u0026lt;/script\u0026gt; 使用 CDN 是最简单和最快速的方式开始使用 htmx。\n2 使用 Npm 或 Yarn 安装 如果你的项目使用 Node.js 和 npm（或 yarn），你可以通过包管理器来安装 htmx。\n使用 npm： 1 npm install htmx.org --save 使用 yarn： 1 yarn add htmx.org 然后在你的 JavaScript 模块或入口文件中引入 htmx： 1 import \u0026#34;htmx.org\u0026#34;; 或者，你可以将它引入到你的一个特定的脚本文件中，并通过构建过程\n（例如 Webpack 或 Parcel）将其包含在你的最终打包文件中。\nGolang 如果您也是一个Gopher，那么我推荐您用temp包来使用HTMX,后面有一个简单的例子\n简单使用 htmx 提供了一组简单易用的 HTML 属性，用于实现各种动态行为，例如：\nhx-get：用于异步加载数据。 hx-post：用于提交表单数据。 hx-trigger：用于定义触发行为。 通过在 HTML 标记中添加这些属性，我们可以轻松地实现各种交互功能，而无需编写大量的 JavaScript 代码。例如，要在按钮点击时加载数据，我们可以这样写：\n1 \u0026lt;button hx-get=\u0026#34;/api/data\u0026#34; hx-target=\u0026#34;#result\u0026#34;\u0026gt;Load Data\u0026lt;/button\u0026gt;\u0026lt;div id=\u0026#34;result\u0026#34;\u0026gt;\u0026lt;/div\u0026gt; 上面的代码定义了一个按钮，当用户点击按钮时，htmx 将使用 AJAX 加载指定 URL 返回的数据，并将结果填充到指定的元素中\nhtmx 同样支持通过服务器响应来控制页面上元素的更新。\n你可以利用 hx-swap 属性来定义响应内容应该如何在 DOM 中被替换或插入，也可以使用扩展的 CSS 选择器语法来指定更新的目标元素。\n为了优化用户体验，htmx 也提供了请求指示器（loading 指示器），可以在 AJAX 请求发起时向用户显示一个可见的反馈，例如一个加载中的动画。\nhtmx 还有许多其它高级功能，如视图转换（View Transitions）、历史支持、事件和日志记录等。通过这些功能，开发者可以创建丰富且高效的用户界面，同时减少编写和维护 JavaScript 代码的工作量。\n更多例子(使用Go 语言示例) 完整代码: github.com/hxzhouh/go-htmx-example.git\n1. AJAX 加载内容 假设您有一个服务器端的 URL /get-content，它返回一些 HTML 内容。您可以使用 hx-get 属性来创建一个按钮，点击后会异步加载内容并将其插入到页面上的指定元素中。\n1 2 3 \u0026lt;h2\u0026gt;1. AJAX load\u0026lt;/h2\u0026gt; \u0026lt;button hx-get=\u0026#34;/get-content\u0026#34; hx-target=\u0026#34;#content\u0026#34;\u0026gt;click me\u0026lt;/button\u0026gt; \u0026lt;div id=\u0026#34;content\u0026#34;\u0026gt;\u0026lt;/div\u0026gt; 2. 表单提交 您可以使用 htmx 来异步提交表单。这意味着用户可以提交表单，页面不会刷新，而表单的响应将直接显示在页面上。\n1 2 3 4 5 6 7 8 9 10 \u0026lt;h2\u0026gt;2. from submit\u0026lt;/h2\u0026gt; \u0026lt;form hx-debug=\u0026#34;true\u0026#34; hx-post=\u0026#34;/submit-form\u0026#34; hx-target=\u0026#34;#form-result\u0026#34; hx-swap=\u0026#34;outerHTML\u0026#34;\u0026gt; \u0026lt;input type=\u0026#34;text\u0026#34; name=\u0026#34;name\u0026#34; placeholder=\u0026#34;inputName\u0026#34;\u0026gt; \u0026lt;input type=\u0026#34;submit\u0026#34; value=\u0026#34;summit\u0026#34;\u0026gt; \u0026lt;/form\u0026gt; \u0026lt;div id=\u0026#34;form-result\u0026#34;\u0026gt;\u0026lt;/div\u0026gt; 3. 实时搜索 使用 htmx 还可以非常容易地创建实时搜索表单，当用户在搜索框输入时，搜索结果可以不断刷新，下面是一个示例：\n1 2 3 4 5 6 7 8 9 \u0026lt;h2\u0026gt;3. search\u0026lt;/h2\u0026gt; \u0026lt;input name=\u0026#34;q\u0026#34; hx-get=\u0026#34;/search\u0026#34; hx-target=\u0026#34;#search-results\u0026#34; hx-trigger=\u0026#34;keyup changed delay:500ms\u0026#34; placeholder=\u0026#34;input search term\u0026#34;\u0026gt; \u0026lt;div id=\u0026#34;search-results\u0026#34;\u0026gt;\u0026lt;/div\u0026gt; 搜索框中键入的内容将被发送到 /search?q=\u0026lt;输入的值\u0026gt;，服务器需要根据查询参数 q 返回相应的搜索结果。\n4. 删除操作 使用 htmx，您可以很容易地实现在不刷新页面的情况下删除项目：\n1 2 3 4 5 \u0026lt;h2\u0026gt;4. delete\u0026lt;/h2\u0026gt; \u0026lt;div id=\u0026#34;item-123\u0026#34;\u0026gt; project 123 \u0026lt;button hx-delete=\u0026#34;/delete-item/123\u0026#34; hx-target=\u0026#34;#item-123\u0026#34; hx-swap=\u0026#34;outerHTML\u0026#34;\u0026gt;Delete \u0026lt;/button\u0026gt; \u0026lt;/div\u0026gt; 点击按钮时，将向服务器发送一个 DELETE 请求，以删除 ID 为 123 的项目。\n5. 加载更多内容 创建一个“加载更多”按钮，当点击时，可以加载下一页的内容。\n1 2 3 4 5 6 \u0026lt;h2\u0026gt;5. load more\u0026lt;/h2\u0026gt; \u0026lt;div id=\u0026#34;items\u0026#34;\u0026gt; \u0026lt;div\u0026gt;input 1\u0026lt;/div\u0026gt; \u0026lt;div\u0026gt;input 2\u0026lt;/div\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;button hx-get=\u0026#34;/get-more-items?page=2\u0026#34; hx-target=\u0026#34;#items\u0026#34; hx-swap=\u0026#34;afterend\u0026#34;\u0026gt;load more\u0026lt;/button\u0026gt; 在实际应用中，您需要动态更新 hx-get 属性中的 page 参数，以便加载正确的内容页面。\nhtmx 允许您通过 HTML 添加丰富的交互性，而不是依赖 JavaScript。这些例子只是展示了 htmx 功能的一部分。您可以通过查看 htmx 的官方文档来了解更多高级功能和用法。\n命令标签列表 htmx 是通过一组自定义的 HTML 属性来工作的，它们通常以 hx- 前缀开头。这些属性可以添加到标准的 HTML 标签上，以提供各种动态行为。以下是一些常用的 htmx 属性（命令和标签）：\n核心属性 hx-get: 发起一个 AJAX GET 请求。 hx-post: 发起一个 AJAX POST 请求。 hx-put: 发起一个 AJAX PUT 请求。 hx-delete: 发起一个 AJAX DELETE 请求。 hx-patch: 发起一个 AJAX PATCH 请求。 hx-trigger: 定义触发 AJAX 请求的事件，如 click, keyup, 等。 hx-target: 指定哪个元素会被请求的响应替换或更新。 hx-swap: 定义如何将响应内容插入到目标元素中，比如 innerHTML, outerHTML, beforebegin, afterend 等。 增强属性 hx-params: 控制包含哪些参数在请求中，如 none, *, vals, 等。 hx-include: 明确指定哪些元素的值应该包括在请求参数中。 hx-indicator: 指定一个或多个元素，在 AJAX 请求进行时显示为加载指示器。 hx-push-url: 控制是否将 AJAX 请求的 URL 推送到浏览器的历史记录中。 hx-prompt: 在发起请求前提示用户输入消息。 hx-confirm: 在执行操作前要求用户确认。 响应处理 hx-select: 从 AJAX 响应中选择一部分内容进行更新，而不是整个响应。 hx-headers: 允许设置自定义请求头。 事件属性 hx-on: 指定特定的事件及其处理，如 hx-on=\u0026quot;click: doSomething\u0026quot;。 WebSockets hx-ws: 定义与 WebSocket 连接相关的行为。 工具属性 hx-boost: 自动增强页面上的链接和表单，使它们通过 AJAX 异步工作。 hx-history-elt: 指定一个元素，其内容变化将触发浏览器历史记录的更新。 我的看法 针对这一技术大家也有很多不同的见解,\n有说说，这是回到了15年前，前后端融合在一起不利于维护。 也有人说 \u0026ldquo;在xml里手写语法树\u0026rdquo;,\u0026ldquo;它落伍了，不适合现代大型软件工程。\nHTMX的官网首页写到 \u0026ldquo;High power tools for HTML\u0026rdquo;。一项技术的成功还是的看未来大多数人对他的认可程度。 我目前对于HTMX的看法是 这样的:\nHTMX的核心思想是利用HTML语言获取数据，异步表单提交等交互场景，不需要使用js知识以及一些框架,也不需要学习前端构建工程那一套。\n它的前端代码都是由后端返回的，合适熟悉后端工程师做简单的交互界面，如果需要做复杂的页面，HTMX目前不支持或者支持有限，HTMX有很多高阶特性，掌握起来也不是特别容易\nHTMX可以让开发者不需要学习JS，但是也需要学习HTMX，学习曲线并没有降低。\n参考连接 本文长期连接 如果您觉得我的博客对你有帮助，请通过 RSS订阅我。 或者在X上关注我。 如果您有Medium账号，能给我个关注嘛？我的文章第一时间都会发布在Medium。 ","date":"2025-01-01T16:01:07+08:00","image":"https://images.hxzhouh.com/blog-images/2025/01/e6c9c9915295ea19685f460d4e7e13e5.png","permalink":"https://huizhou92.com/zh-cn/p/htmx-%E5%88%9D%E4%BD%93%E9%AA%8C/","title":"HTMX 初体验"},{"content":"在Go语言中，测试并发代码一直是一个具有挑战性的任务。尤其是测试一些需要跟时间相关的case的时候，传统的测试方法通常依赖于真实的系统时钟和同步机制，这会导致测试变得缓慢且容易出现不确定性。\n假设我们需要测试go-cache 的过期删除功能，我们可能会写出这种代码\ngo-cache是一个非常流行的 Go 缓存库，支持过期时间（TTL）和定期清理过期的缓存项。它适用于缓存数据，能够自动删除过期的条目。\nlist1: TestGoCacheEntryExpires\n1 2 3 4 5 6 7 8 9 10 11 func TestGoCacheEntryExpires(t *testing.T) { c := cache.New(5*time.Second, 10*time.Second) c.Set(\u0026#34;foo\u0026#34;, \u0026#34;bar\u0026#34;, cache.DefaultExpiration) v, found := c.Get(\u0026#34;foo\u0026#34;) assert.True(t, found) assert.Equal(t, \u0026#34;bar\u0026#34;, v) time.Sleep(5 * time.Second) v, found = c.Get(\u0026#34;foo\u0026#34;) assert.False(t, found) assert.Nil(t, v) } 运行这个case 需要等待5s，让 cache过期。\n1 2 3 ➜ synctest git:(main) ✗ time go test go-cacha_test.go ok command-line-arguments 5.012s go test go-cacha_test.go 0.38s user 1.27s system 27% cpu 6.049 total 在 Golang 1.24 之后，如何使用testing/synctest 解决这个问题呢？首先看看基于 testing/synctest 如何写这个test case 把。\nList 2: TestGoCacheEntryExpiresWithSynctest\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 func TestGoCacheEntryExpiresWithSynctest(t *testing.T) { c := cache.New(2*time.Second, 5*time.Second) synctest.Run(func() { c.Set(\u0026#34;foo\u0026#34;, \u0026#34;bar\u0026#34;, cache.DefaultExpiration) // Get an entry from the cache. if got, exist := c.Get(\u0026#34;foo\u0026#34;); !exist \u0026amp;\u0026amp; got != \u0026#34;bar\u0026#34; { t.Errorf(\u0026#34;c.Get(k) = %v, want %v\u0026#34;, got, \u0026#34;bar\u0026#34;) } // Verify that we get the same entry when accessing it before the expiry. time.Sleep(1 * time.Second) if got, exist := c.Get(\u0026#34;foo\u0026#34;); !exist \u0026amp;\u0026amp; got != \u0026#34;bar\u0026#34; { t.Errorf(\u0026#34;c.Get(k) = %v, want %v\u0026#34;, got,\u0026#34;bar\u0026#34;) } // Wait for the entry to expire and verify that we now get a new one. time.Sleep(3 * time.Second) if got, exist := c.Get(\u0026#34;foo\u0026#34;); exist { t.Errorf(\u0026#34;c.Get(k) = %v, want %v\u0026#34;, got, nil) } }) } 运行时间：\n1 2 3 4 ➜ synctest git:(main) ✗ time GOEXPERIMENT=synctest gotip test -run TestGoCacheEntryExpiresWithSynctest PASS ok blog-example/go/go1.24/synctest 0.009s GOEXPERIMENT=synctest gotip test -run TestGoCacheEntryExpiresWithSynctest 0.36s user 1.23s system 171% cpu 0.933 total 仅仅耗时 0.009s\ntesting/synctest 揭秘 testing/synctest主要目的是为了简化并发代码的测试。它的核心思想是通过使用虚拟时钟和goroutine组(也称为bubble)来控制并发代码的执行，从而使测试既快速又可靠。它仅仅只有两个接口。\n1 2 func Run(f func()) { synctest.Run(f) } func Wait() { synctest.Wait() } Run函数在一个新的goroutine中执行f函数，并创建一个独立的bubble，确保所有相关的goroutine都在虚拟时钟的控制下执行。\nWait 用来同步 bubble 中goroutine‘s 的状态。调用该函数调用后，主goroutine将阻塞，直到bubble中的其他goroutine都处于durably blocked 状态。\ndurably blocked 是 bubble 中goroutine 的一个特有的状态，有几种方式可以使 goroutine 进入 durably blocked 状态。\n在bubble内向channel发送或接收数据 select语句中，每个case都是bubble内的channel A send or receive on a channel from within the bubble A select statement where every case is a channel within the bubble sync.Cond.Wait time.Sleep\n但是如果goroutine 是因为 系统调用或外部事件而阻塞， 它就不是 durably blocked 状态，synctest.Wait 也不会因为它而阻塞。 每个bubble都有一个虚拟时钟，从2000-01-01 00:00:00 UTC 开始. 这个虚拟时钟不会根据代码的执行时间前进，只有在所有goroutine都处于空闲状态时才会向前推进。在TestGoCacheEntryExpiresWithSynctest 中调用time.Sleep 的时候， goroutine 只有一个并且处于空闲状态，时间会快速前进，而不必等待真实时间过去，所以测试运行速度很快。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 func TestSynctest(t *testing.T) { synctest.Run(func() { before := time.Now() fmt.Println(\u0026#34;before\u0026#34;, before) f1:=func() { count := 0 for i := 0; i \u0026lt; 10e9; i++ { // time consuming, It\u0026#39;s about 3s in my machine count++ } } go f1() synctest.Wait() //wait f1 after := time.Now() // time is not affected by the running time of f1 fmt.Println(\u0026#34;after\u0026#34;, after) }) } 运行结果为：\n1 2 3 4 5 6 ➜ synctest git:(main) ✗ time GOEXPERIMENT=synctest gotip test -run TestSynctest before 2000-01-01 08:00:00 +0800 CST m=+946164282.733407335 after 2000-01-01 08:00:00 +0800 CST m=+946164282.733407335 PASS ok blog-example/go/go1.24/synctest 3.131s GOEXPERIMENT=synctest gotip test -run TestSynctest 3.45s user 1.25s system 133% cpu 3.533 total 在 gosrc 中已经已经有蛮多使用 synctest 优化case 的例子。\n参考资料：\nhttps://github.com/golang/go/blob/05d8984781f7cf2f0f39b53699a558b6a1965c6c/src/testing/synctest/synctest.go#L41\n","date":"2024-12-19T19:22:52+08:00","image":"https://images.hxzhouh.com/blog-images/2024/12/260aeb6207be4b765d34328515c144dc.png","permalink":"https://huizhou92.com/zh-cn/p/go-1.24-%E6%96%B0%E7%9A%84%E5%AE%98%E6%96%B9%E5%BA%93-synctest/","title":"Go 1.24: 新的官方库 synctest"},{"content":"原文链接：\u0026ldquo;Security Is Our Top Priority\u0026rdquo; is BS\n几年前，我被邀请去做一个关于软件安全的会议演讲。其实，我并没有真正被邀请，而是我的公司购买了一个包含演讲席位的赞助包，我回复了一封内部邮件，自愿参与了这个活动 🤣 无论如何，在准备我的演讲过程中，我意识到了几个关于安全的重要观点，这些观点自此一直萦绕在我的心头：\n安全是无止境的。你总是可以投入更多努力来提高安全性。质量和安全、员工满意度等也是如此。 安全的需求与便捷的用户体验需求相冲突。增强一个方面往往会损害另一个方面。 现在，有些组织宣称“安全是我们的首要任务”。真的吗？你想要将一个没有上限的事情作为你的首要任务？我的意思是，安全是一件好事，但这听起来是不是有点太简单了？实际上，像这样的空洞营销声明可能会让我有点生气。在这篇文章中，我将帮助你理解如何解读这样的声明，以及在现实生活中如何处理安全问题。我将涵盖：\n一个哲学性的介绍 “安全是我们的首要任务”实际上意味着什么？ 你应该在多大程度上重视安全？ 公司应该怎么说替代这句话？ 安全性与用户体验平衡的哲学思考 安全的无限性以及它与用户体验（UX）之间的平衡让我想起了某件事。我不得不停下来思考了一会儿，然后我想起来了。大约在我19或20岁的时候，我发现了GK Chesterton。我非常喜欢他，因为他让我意识到实际上有非常了不起的基督教思想家，而在我那种多少算是福音派的背景中，这样的人并不多。不幸的是，尽管有Chesterton的影响，但与20岁时的我希望的相反，我个人的信仰并没有坚持下去。不过，我还是从他的著作中学到了很多至今仍感激的东西。这里有一段与我们讨论的话题相关的引用：\n“现代社会并不邪恶；在某些方面，现代社会太过美好了。它充满了狂野而被浪费的美德。当一个宗教体系被粉碎（正如基督教在宗教改革中被粉碎那样），被释放的不仅仅是恶习。恶习确实被释放了，它们四处游荡并造成破坏。但美德也被释放了；美德游荡得更加疯狂，美德造成的破坏更加可怕。现代社会充满了旧基督教美德的疯狂。美德之所以疯狂，是因为它们彼此孤立，独自游荡。因此，有些科学家只关心真理；而他们的真理是无情的。因此，有些人文主义者只关心怜悯；而他们的怜悯（很遗憾地说）往往是不真实的。”——GK Chesterton，《正统》，1908年\nChesterton的意思是，好的事物（美德）如果被过分追求或者脱离了其他好的事物，就可能变成坏事。这听起来似乎是显而易见的，确实如此。但是一旦你掌握了这个模式，就会发现它一直在发生。在这篇博文中，我们谈论的是那些忽视了UX的安全狂热者，但在我们的政治世界中也是如此。有些人将多样性、公平性和包容性（DEI）推行到极致，以至于将白人男性妖魔化。有些人将家庭价值观推崇到极致，让其他人感到格格不入。家庭价值观和包容性都是好东西，但如果它们被孤立对待，就可能走向极端，并在群体之间造成分裂。\n因此，我们需要在所有美好的事物之间找到一个健康的平衡，不让任何一个走向极端而忽视其他。这并不容易！如果你是一个安全极端主义者，即使你还是被黑客攻击了，至少可以说你已经竭尽全力来提高安全性。另一方面，如果你在安全性和UX之间取得了平衡，并为了更好的UX而做出了一些降低安全性的决定，然后遭到了黑客攻击。你如何为自己辩护？说“现实是复杂的，我们在这种情况下决定优先考虑UX”并不是一个听起来很好的回答。捍卫非极端立场需要勇气，因为极端主义者总是有更有力的口号。\n“安全是我们的首要任务”实际上意味着什么？ 安全真的是无限的吗？我认为是的。实际上，银行最安全的运营方式可能是关闭他们的在线业务，购买一个大保险库，并在门外部署一支小型军队。即便如此，安全检查的强度和军队的规模也可以无限增加。然而，大多数人还是更愿意通过银行应用程序的面部识别来转账，并认为这种安全程度已经足够好。\n公司真的会这么说吗？是的。比如微软的“将安全置于一切之上”，AWS的“在AWS，云安全是最高优先级”，Meta的“保护您的数据是我们的最高优先级”，还有很多其他例子。\n这听起来不错，但在实践中，这是否意味着只要有人提出以牺牲UX、消费者价格等为代价来提高安全性的想法，你就会实施？因为这似乎是它的意思。当然，答案是否定的，所以我对这些声明并不太认真，尽管我理解这给客户带来了一种温暖而模糊的感觉。我更希望组织能够坦诚和清晰，但我只能梦想在一个这样的世界里。\n实际上，这些公司所表达的可能是：\n“我们有一个平衡的优先级框架，我们对问题进行分类并给予每个问题加权得分。我们给UX问题分配20%，安全25%，技术债务10%，新功能20%，等等。正如你所见，风险是首要优先级，因为25%高于20%。”\n或者他们可能意味着：\n“安全（达到我们行业中标准水平的安全性）是我们的首要任务。一旦我们实施了足够的安全措施，我们就会专注于其他问题。”\n如果你有完全诚实的安全声明的例子，比如“我们关心安全，因为我们需要你信任我们，因此它是我们的首要任务之一”，我会非常感兴趣。请在评论中分享！\n安全性应该做到什么程度？ 当我在2018年做那次演讲时，我还不清楚到底应该在何处划线。自那以后，我开始使用ISO 14971和ISO 27001这样的风险框架进行工作，现在我已经有了一些工具来帮助我处理这个问题。\n一切始于一个评分机制：弄清楚我们需要保护的是什么，存在哪些风险，以及这些风险发生的可能性和严重程度如何。你将可能性和严重性相乘，为每个风险得出一个风险分数，然后将这些分数映射到低、中、高三个等级。\n如果风险分数是低的，你可以安全地接受这个风险。 如果是中等，你应该考虑风险控制，除非有正当理由不这么做。 如果是高风险，你必须实施风险控制。 然后，一旦风险控制措施到位，验证它们是否真正减轻了风险，剩余风险是否现在变低或不存在。这样你就完成了。\n听起来简单，但低、中、高的界限我们应该怎么划分呢？我总是把一些决策者聚在一起，给他们提供可能出错的情况的例子，然后请他们提出一个评分系统。接着询问他们愿意接受哪些类型的风险，同时考虑到如果应用了风险控制，产品或流程会是什么样子。\n这个简单的评分系统包括风险矩阵、风险偏好/风险接受政策和风险清单。这是一个简单的工具，可以帮助你做出决策。\n我们应该怎么说？ 几十年来，全球都在以成熟的方式处理安全、质量和安全问题。让我们推广那些实际这么做的公司，而不是说这是他们的首要任务。这是一个没有意义的声明。\n在我理想的世界里，公司会说：“我们维护着最先进的安全体系，因为没有客户的信任，我们作为公司就没有存在的权利。因此，这是我们工作中最重要的事情之一，我们投入了大量的精力。”这可能对大多数人来说听起来没有那么好，但这样说的公司肯定会给我留下深刻的印象。\n原文连接：\u0026ldquo;Security Is Our Top Priority\u0026rdquo; is BS\n本文长期连接 如果您觉得我的博客对你有帮助，请通过 RSS订阅我。 或者在X上关注我。 如果您有Medium账号，能给我个关注嘛？我的文章第一时间都会发布在Medium。 ","date":"2024-12-19T11:07:26+08:00","image":"https://images.unsplash.com/photo-1614064849549-ba6c7b819a49?crop=entropy\u0026cs=tinysrgb\u0026fit=max\u0026fm=jpg\u0026ixid=M3wzNjAwOTd8MHwxfHNlYXJjaHw1NHx8c2VjdXJpdHl8ZW58MHwwfHx8MTczNDU3ODA0NXww\u0026ixlib=rb-4.0.3\u0026q=80\u0026w=400","permalink":"https://huizhou92.com/zh-cn/p/%E8%AF%91%E5%AE%89%E5%85%A8%E6%98%AF%E6%88%91%E4%BB%AC%E7%9A%84%E9%A6%96%E8%A6%81%E4%BB%BB%E5%8A%A1-%E8%BF%99%E6%98%AF%E4%B8%80%E5%8F%A5%E5%BA%9F%E8%AF%9D/","title":"【译】“安全是我们的首要任务”--这是一句废话"},{"content":"以前，我写过一篇文章介绍runtime.SetFinalizer 这个函数，用于在对象被清理的时候调用，但是这个函数有一些问题，导致它的使用频率比较低。\n在 Go 中使用 SetFinalizer 方法时，必须确保传递给它的对象引用指向分配内存的起始位置（即分配内存块的第一个字节）。这要求程序员理解“分配”（allocation）的概念，而这个概念通常在 Go 语言的抽象层级中并未明确暴露。 对象只能定义一个SetFinalizer。 带有SetFinalizer的对象如果涉及到任何引用循环，将无法被释放，SetFinalizer也不会运行。 带有SetFinalizer的对象至少需要两个 GC 循环才能被释放。\nhttps://github.com/golang/go/issues/67535 对于第一条，我们可以用一个例子说明\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 package main import ( \u0026#34;fmt\u0026#34; \u0026#34;runtime\u0026#34; ) type MyStruct struct { Field int } func main() { obj := \u0026amp;MyStruct{Field: 42} runtime.SetFinalizer(obj, func(m *MyStruct) { fmt.Println(\u0026#34;Finalizer called for:\u0026#34;, m) }) // 错误示例：传递字段引用而非对象本身 // runtime.SetFinalizer(\u0026amp;obj.Field, func(m *int) { // fmt.Println(\u0026#34;Finalizer called for:\u0026#34;, *m) // }) } 基于上面的原因，在Golang 1.24 中添加了一个新的函数runtime.AddCleanUp 来替换 runtime.SetFinalizer 。\n注意： runtime.AddCleanup 和 runtime.SetFinalizer 都不保证 清理函数一定会被执行。\nAddCleanup的设计目标是解决runtime.SetFinalizer的诸多问题，特别是避免对象复活，从而允许对象的及时清理，并支持对象的循环清理。\nAddCleanup函数的原型如下：\n1 func AddCleanup[T, S any](ptr *T, cleanup func(S), arg S) Cleanup 基于此，可以写一个RAII(Resource Acquisition Is Initialization)的 Demo 。在go weak 的文章中，我们实现了一个固定长度的cache，改一下代码，添加一个newElemWeak 方法，当最旧的elem 被逐出的时候，会自动调用delete 将key 从cache 中删除。不需要我们手动管理。\n1 2 3 4 5 6 7 func (c *WeakCache) newElemWeak(elem *list.Element) weak.Pointer[list.Element] { elemWeak := weak.Make(elem) runtime.AddCleanup(elem, func(name string) { delete(c.cache, name) }, elem.Value.(*CacheItem).key) return elemWeak } 需要注意的几个问题 AddCleanup对ptr的约束很少，支持为同一个指针附加多个清理函数。不过，如果ptr可以从cleanup或arg中可达，ptr将永远不会被回收(memory leak)，清理函数也永远不会运行，目前来看这种情况也不会panic。 或许以后会用 GODEBUG=gccheckmark=1 这种模式来检测？\n比如\nhttps://gist.github.com/hxzhouh/5bb1d55259dcb4dab87b37beaef9bea2\n1 2 3 4 5 6 7 8 9 10 11 12 13 func NewFileResource(filename string) (*os.File, error) { file, err := os.OpenFile(filename, os.O_RDWR|os.O_CREATE, 0666) if err != nil { return nil, err } runtime.AddCleanup(file, func(f *os.File) { fmt.Println(\u0026#34;close f\u0026#34;) _ = f.Close() }, file) return file, nil } fmt.Println(\u0026quot;close f\u0026quot;) 不会被打印，file 也不会被关闭。\nTry It\n当给一个ptr绑定多个cleanup 的时候，因为cleanup 是在一个独立的goroutine 中运行，所以它的运行顺序可能是不固定的。\n特别是，如果几个对象相互指向并且同时变成 unreachable，它们的清理函数都可以运行，并且可以以任何顺序运行。即使对象形成一个循环也是如此（runtime.SetFinalizer 在这种情况下会产生内存泄露）。\n例如\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 func main() { x := MyStruct{Name: \u0026#34;X\u0026#34;} y := MyStruct{Name: \u0026#34;Y\u0026#34;} x.Other = \u0026amp;y y.Other = \u0026amp;x //runtime.SetFinalizer(\u0026amp;x, func(x *MyStruct) { //\tfmt.Printf(\u0026#34;Finalizer for %s is called\\n\u0026#34;, x.Name) //}) //runtime.SetFinalizer(\u0026amp;y, func(y *MyStruct) { //\tfmt.Printf(\u0026#34;Finalizer for %s is called\\n\u0026#34;, y.Name) //}) xName := x.Name runtime.AddCleanup(\u0026amp;x, func(name string) { fmt.Println(\u0026#34;Cleanup for\u0026#34;, x) }, xName) yName := y.Name runtime.AddCleanup(\u0026amp;y, func(name string) { fmt.Println(\u0026#34;Cleanup for\u0026#34;, x) }, yName) time.Sleep(time.Millisecond) runtime.GC() time.Sleep(time.Millisecond) runtime.GC() } https://gist.github.com/hxzhouh/ca402c723faa78726baba7e56bff573a\n1 2 3 ➜ AddCleanUp git:(main) ✗ gotip run main.go Cleanup for Y Cleanup for X SetFinalizer 的会阻止 GC，但是 AddCleanup 能够正常执行\n参考资料 https://github.com/golang/go/issues/67535 ","date":"2024-12-17T09:56:00+08:00","image":"https://images.hxzhouh.com/blog-images/2024/12/53b24938b44977786f01d0db8768c34e.png","permalink":"https://huizhou92.com/zh-cn/p/golang-1.24-runtime.addcleanup-%E6%94%B9%E8%BF%9B-runtime.setfinalizer-%E7%9A%84%E4%B8%80%E4%BA%9B%E9%97%AE%E9%A2%98/","title":"Golang 1.24: runtime.AddCleanup 改进 runtime.SetFinalizer 的一些问题"},{"content":"Weak 是什么？ Golang 在1.24 中带来了一个新的std-lib weak。 可以为*T 创建一个安全的引用，但是不会阻止 *T 被GC 回收。\nPackage weak provides ways to safely reference memory weakly, that is, without preventing its reclamation.\n跟 OS.ROOT 一样， weak 也是一个在其他语言中存在很久的功能，比如：\nJava 的 WeakReference 和 SoftReference 是经典实现，主要用于缓存和对象池。它们能够在 JVM 检测到内存不足时自动回收。 Python 提供了 weakref 模块，允许创建弱引用对象，常用于防止循环引用问题或缓存。 c++ 在 std::shared_ptr 中引入了 std::weak_ptr，用于解决共享指针的循环依赖问题。 Rust 提供 Rc 和 Arc 的弱引用版本 Weak，也用于避免循环引用并提升内存管理的灵活性。 weak 的定义很简单，一个Make 方法还有一个Value 方法。\n通过weak.Make 创建一个weak.Pointer ,如果 T 没有被回收的话，我们可以通过weak.Pointer.Value 获取T的地址。 否则就会返回 nil，很简单。\n我们可以通过一个简单的例子来实践一下 weak。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 func main() { originalObject := \u0026#34;Hello, World!\u0026#34; runtime.AddCleanup(\u0026amp;originalObject, func(s int64) { fmt.Println(\u0026#34;originalObject clean at: \u0026#34;, s) }, time.Now().Unix()) weakPtr := weak.Make(\u0026amp;originalObject) fmt.Println(fmt.Sprintf(\u0026#34;originalObject:addr %x\u0026#34;, \u0026amp;originalObject)) fmt.Println(fmt.Sprintf(\u0026#34;weakPtr addr:%x,size:%d\u0026#34;, weakPtr, unsafe.Sizeof(weakPtr))) runtime.GC() time.Sleep(1 * time.Millisecond) value := weakPtr.Value() if value != nil \u0026amp;\u0026amp; strings.Contains(*value, originalObject) { fmt.Println(\u0026#34;First GC :value: \u0026#34;, *value) } else { fmt.Println(\u0026#34;first gc. Weak reference value is nil\u0026#34;) } runtime.GC() time.Sleep(1 * time.Millisecond) value = weakPtr.Value() if value != nil { fmt.Println(\u0026#34;Second GC\u0026#34;, *value) } else { fmt.Println(\u0026#34;Second GC: Weak reference value is nil\u0026#34;) } } https://gist.github.com/hxzhouh/abd6be9ed8860e506643031bb2d446ce\n运行结果\n1 2 3 4 5 6 7 8 ➜ weak git:(main) ✗ gotip version go version devel go1.24-18b5435 Sun Dec 15 21:41:28 2024 -0800 darwin/arm64 ➜ weak git:(main) ✗ gotip run main.go originalObject:addr 14000010050 weakPtr addr:{1400000e0d0},size:8 First GC :value: Hello, World! originalObject clean at: 1734340907 Second GC: Weak reference value is nil 在上面的代码中，我们创建了一个 string 变量 originalObject ,然后使用weak.Make 创建了一个 weak.Pointer weakPtr\n在第一次GC 的时候，因为originalObject 在后面还有使用，所以 weakPtr.Value 返回了 originalObject 的地址。 在第二次GC 的时候，originalObject 没有被使用，它被GC回收了， 所以 weakPtr.Value 返回了nil runtime.AddCleanup 也是go 1.24 新增的功能，它的功能类似 runtime.SetFinalizer,也是在 对象呗垃圾回收的时候用于执行一段代码。我后面可能会详细介绍它\n通过上面的例子，我们可以知道 weak.Make 通过创建一个中间地址(weak.Printer)将真实地址隐藏起来。 weak.Printer 不会影响 真实地址的垃圾回收，如果真实地址被垃圾回收了，weak.Printer.Value 将会返回nil。由于不知道真实地址什么时候会被回收，所以需要仔细检查weak.Printer.Value 的返回值。 Weak 有什么作用 Canonicalization Maps 相信您还记得在go 1.23 中添加的 unique 它可以将多个相同的字符串用一个指针（8个字节）来表示，达到节约内存的目的 , weak 也能实现类似的效果.(实际上 go 1.24 中unique 已经使用 weak 重构了)\n实现一个固定大小的缓存 下面是一个使用weak+ list.List 实现 固定大小缓存的例子\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 type WeakCache struct { cache map[string]weak.Pointer[list.Element] // Use weak references to store values mu sync.Mutex storage Storage } // Storage is a fixed-length cache based on doubly linked tables and weaktype Storage struct { capacity int // Maximum size of the cache list *list.List } // Set func (c *WeakCache) Set(key string, value any) { // If the element already exists, update the value and move it to the head of the chain table if elem, exists := c.cache[key]; exists { if elemValue := elem.Value(); elemValue != nil { elemValue.Value = \u0026amp;CacheItem{key: key, value: value} c.storage.list.MoveToFront(elemValue) elemWeak := weak.Make(elemValue) c.cache[key] = elemWeak return } else { c.removeElement(key) } } // remove the oldest unused element if capacity is full if c.storage.list.Len() \u0026gt;= c.storage.capacity { c.evict() } // Add new element elem := c.storage.list.PushFront(\u0026amp;CacheItem{key: key, value: value}) elemWeak := weak.Make(elem) c.cache[key] = elemWeak } 完整的代码请参考： https://gist.github.com/hxzhouh/1945d4a1e5a6567f084628d60b63f125\n我们可以创建一个固定大小的list ，然后使用一个Map记录key在list 中的位置，value 是一个指向 list.Element 的weak.Pointer. 如果 key 存在于list 上，那么 Map[key].Value 会返回 list 的地址。 再给cache 添加数据的时候，会先判断list 的大小，如果已经list已经满了的话，就把队尾的数据淘汰。Map[key].Value返回nil。\n这样，我们就能构建一个高效+固定大小的cache系统。 weak + 无锁队列 可以构建出更加高效的数据结构。\n就我个人而言，weak 在特定场合下还是挺有用处的。使用起来也很简单，我会在项目中积极使用weak\n更多关于 weak 的资料\nhttps://tip.golang.org/doc/go1.24#weak https://github.com/golang/go/issues/67552 ","date":"2024-12-14T19:40:46+08:00","image":"https://images.hxzhouh.com/blog-images/2024/12/edbf334955e117265be0194bba455ee3.png","permalink":"https://huizhou92.com/zh-cn/p/go1.24-%E6%96%B0%E7%9A%84%E6%A0%87%E5%87%86%E5%BA%93-weak/","title":"go1.24: 新的标准库 weak"},{"content":"\nBacklink | |Photo by Kaleidico on Unsplash Golang 1.24 已经进入冻结期了，目前很多特性我们在Go 1.24 Release Notes 能够看到，接下来一段时间我会学习Golang1.24将会添加的新功能以及修改点。如果您也想学习Go最新的进展，请关注我，\n这篇文章，我们将学习一下os.Root这个新增的Standard library。\nProposal 目录遍历漏洞是一类常见的漏洞，攻击者会诱骗程序打开其不希望的文件。这些攻击通常采用提供相对路径名的形式，例如\u0026quot;../../../etc/passwd\u0026quot; ，这会导致在预期位置之外进行访问。 CVE-2024-3400是最近的一个真实的目录遍历示例，导致远程代码执行漏洞被主动利用。\n在其他语言以及操作系统中，已经都有类似的实现, 比如:\nPython 的 chroot：通过 os.chroot() 将根目录限制为特定目录。 Linux 的文件系统命名空间：通过 mount 和 chroot 限制进程的视图。\n我们可以写一个demo 测试一下。\n首先构造一个 “机密”文件 1 echo \u0026#39;password123\u0026#39; \u0026gt;\u0026gt; /tmp/password 然后写一个Golang函数， 原义是打开当前目录的文件\n1 2 3 4 5 6 7 8 9 10 11 12 func main() { fileName := os.Args[1] //readFile localFilePath := \u0026#34;.\u0026#34; filePath := fmt.Sprintf(\u0026#34;%s/%s\u0026#34;, localFilePath, fileName) content, err := os.ReadFile(filePath) if err != nil { fmt.Printf(\u0026#34;Error reading file %s: %s\\n\u0026#34;, fileName, err) return } fmt.Printf(\u0026#34;File %s opened successfully. file content %s\\n\u0026#34;, fileName, content) } 但是因为传入了不可靠的参数，代码能够访问到 权限范围之外的地方。\n1 2 3 4 5 6 ➜ os_root git:(main) ✗ pwd /Users/hxzhouh/workspace/github/me/blog-example/go/go1.24/os_root ➜ os_root git:(main) ✗ ./main ../../../../../../../../../tmp/password ./../../../../../../../../../tmp/password File ../../../../../../../../../tmp/password opened successfully. file content password123 在 Go1.24 中，新增了 os.Root 的类型，其提供了在特定目录中执行文件系统操作的能力。整个体系是围绕着这个新类型进行的。 对应的核心函数是 os.OpenRoot，函数打开一个目录并返回一个 os.Root。\nos.Root 上的方法仅允许在目录内操作，不允许指向目录外部位置的路径，包括遵循目录外符号链接的路径。（防御住了前面提案背景提到的攻击范围）\n我们用Go1.24 的方式修改代码\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 func main() { fileName := os.Args[1] root, err := os.OpenRoot(\u0026#34;.\u0026#34;) if err != nil { panic(err) } file, err := root.Open(fileName) if err != nil { fmt.Println(fmt.Sprintf(\u0026#34;Error opening file %s: %s\\n\u0026#34;, fileName, err.Error())) return } content := make([]byte, 1024) c, err := file.Read(content) if err != nil { panic(err) } content = content[:c] fmt.Printf(\u0026#34;File %s opened successfully. file content %s\\n\u0026#34;, fileName, content) } 再次运行\n1 2 3 4 5 ➜ os_root git:(main) ✗ gotip version go version devel go1.24-fafd447 Wed Dec 11 15:57:34 2024 -0800 darwin/arm64 ➜ os_root git:(main) ✗ gotip build -o go1.24 main.go ➜ os_root git:(main) ✗ ./go1.24 ../../../../../../../../../tmp/password Error opening file ../../../../../../../../../tmp/password: openat ../../../../../../../../../tmp/password: path escapes from parent 如果文件夹脱离了parent 层级，就会报错。\n更多的APi接口请参考官方文档 。1.24正式发布后，估计很多第三方库都会第一时间适配把，毕竟其他语言基本上都有这种功能了。\n","date":"2024-12-10T19:23:31+08:00","permalink":"https://huizhou92.com/zh-cn/p/go1.24-%E6%96%B0%E7%9A%84%E6%A0%87%E5%87%86%E5%BA%93-os.root/","title":"go1.24: 新的标准库 os.Root"},{"content":"bigcache是一个高性能的内存缓存库，专为需要高并发访问和低延迟响应的应用场景设计。本文将深入探讨 BigCache 的性能优化手段，包括分片机制、高效哈希算法、读写锁的使用等，并引用相关源码进行详细说明。\n分段加锁 从使用者的角度来看cache就像一个大的hashtable,可以存储k/v 格式的数据。 那么，是不是可以使用一个map[string][]byte + sync.RWMutex 实现满足需求的cache呢？\n如果性能要求不高，的确可以这么做。\nsync.RWMutex虽然对读写进行了优化，但是对于并发的读，最终还是把写变成了串行，一旦写的并发量大的时候，即使写不同的key, 对应的goroutine也会block，只允许一个写执行，这是一个瓶颈，并且不可控。\nbigcache 参考了 java ConcurrentMap 的实现方式，将一个大hashtable 分成多个小的 shard，每个分片一把锁，很多大并发场景下为了减小并发的压力都会采用这种方法，比如MongoDB的sharding等。Golang也有一个第三方的 ConcurrentMap 实现 concurrent-map。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 // https://github.com/allegro/bigcache/blob/a2f05d7cbfdc7000a8b7e1c40f27d3f239c204df/bigcache.go#L58 type BigCache struct { shards []*cacheShard shardMask uint64 config Config } func newBigCache(ctx context.Context, config Config, clock clock) (*BigCache, error) { ...... cache := \u0026amp;BigCache{ shards: make([]*cacheShard, config.Shards), lifeWindow: lifeWindowSeconds, clock: clock, hash: config.Hasher, config: config, shardMask: uint64(config.Shards - 1), close: make(chan struct{}), } ...... for i := 0; i \u0026lt; config.Shards; i++ { cache.shards[i] = initNewShard(config, onRemove, clock) } ...... return cache, nil } 对于每一个缓存对象，根据它的key计算它的哈希值: hash(key) % N。 理想情况下N个 goroutine 每次请求正好平均落在各自的shard上，这样就不会有锁竞争了。即使有多个goroutine同时请求，如果hash比较平均的话，单个shard的压力也会比较小。可以降低延迟，因为等待获取锁的时间变小了。 N的选择 既然分片可以很好的降低锁的竞争，那么N是不是越大越好呢？当然不是，如果N非常大，比如每个缓存对象一个锁，那么会带来很多额外的不必要的开销。可以选择一个不太大的值，在性能和花销上寻找一个平衡。\n另外, N是 2的幂， 比如16、32、64。这样设计的好处就是计算余数可以使用位运算快速计算。\n1 2 3 4 // https://github.com/allegro/bigcache/blob/a2f05d7cbfdc7000a8b7e1c40f27d3f239c204df/bigcache.go#L253 func (c *BigCache) getShard(hashedKey uint64) (shard *cacheShard) { return c.shards[hashedKey\u0026amp;c.shardMask] } 因为对于 2 的幂N，对于任意的x, 下面的公式成立:\nx mod N = (x \u0026amp; (N − 1))\n所以只需要使用一次按位 AND (\u0026amp;) 就可以求得它的余数。\n选择合适的 Hash 算法 计算机科学家已经发明了很多的Hash算法，gopher也实现了很多Hash算法。一个优秀的Hash算法有以下特点\n哈希值应该比较随机 (质量) 哈希速度比较快 (速度) 尽量不产生额外的内存分配, 避免对垃圾回收产生压力 (耗费资源少) bigcache 提供了一个默认的 Hash算法的实现，采用 fnv64a 算法。这个算法的好处是采用位运算的方式在栈上进行运算，避免在堆上分配。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 type fnv64a struct{} const ( offset64 = 14695981039346656037 prime64 = 1099511628211 ) func (f fnv64a) Sum64(key string) uint64 { var hash uint64 = offset64 for i := 0; i \u0026lt; len(key); i++ { hash ^= uint64(key[i]) hash *= prime64 } return hash } 内存优化 对于 Go 语言中的 map, 垃圾回收器在 mark和scan阶段检查 map 中的每一个元素, 如果缓存中包含数百万的缓存对象，垃圾回收器对这些对象无意义的检查导致不必要的时间开销。\n作者做了测试。他们测试了简单的 HTTP/JSON 序列化 (不会访问 cache)。 在 cache 为空的时候 1 万的 QPS 的耗时大约 10 毫秒。当 cache 填满的时候， P99 的请求都会超过 1 秒。监控显示堆中包含 4 千万的对象， GC 过程中的 mark 和 scan 也需要 4 秒。\n那是因为如果hashtable中的元素包含指针，那么GC在mark会扫描每个包含指针的元素，如果不包含指针，在mark阶段就会跳过这些元素。\n我们可以用一个简单的例子测试一下。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 var pointMap map[int]*int var noPointMap map[int]int func BenchmarkPointMap(b *testing.B) { pointMap = make(map[int]*int) for i := 0; i \u0026lt; 10e6; i++ { pointMap[i] = \u0026amp;i } b.ResetTimer() for i := 0; i \u0026lt; b.N; i++ { delete(pointMap, i) pointMap[i] = \u0026amp;i } } func BenchmarkNoPointMap(b *testing.B) { noPointMap = make(map[int]int) for i := 0; i \u0026lt; 10e6; i++ { noPointMap[i] = i } b.ResetTimer() for i := 0; i \u0026lt; b.N; i++ { delete(noPointMap, i) noPointMap[i] = i } } 测试结果如下\n1 2 3 4 5 6 7 ➜ gc git:(main) ✗ GOMAXPROCS=1 go test --bench=. goos: darwin goarch: arm64 pkg: blog-example/go/gc cpu: Apple M1 Pro BenchmarkPointMap 5273188 209.4 ns/op BenchmarkNoPointMap 7037848 178.5 ns/op 然后分别运行两个测试，分析 gc\n1 2 go test -bench=BenchmarkPointMap -trace trace_point.out go test -bench=BenchmarkNoPointMap -trace trace_no_point.out NoPointMap 的 Wall Duration 只有PointMap 的2% 。虽然PointMap 的并发量很小，并且单个的 goroutine也没有竞争，但是由于元素的数量很多，垃圾回收在mark/scan阶段需要花费上百毫秒进行标记和遍历。\nbigcache 是如何解决这个问题的？禁止你的用户在 bigcache 上存储带有指针的数据。\n开个玩笑，如果真的这么做，你的用户会抛弃你。有几种办法可以解决这个问题。\n参考 offheap，使用定制化的Malloc() 和 Free() 来手动管理内存，而绕过runtime 垃圾回收，但是这样会比较容易导致内存泄露。 第二种方式是使用 freecache。freecache 通过减少指针的数量以零 GC 开销实现 map。它将键和值保存在ringbuffer中，并使用索引查找对象。 bigcache 实现的方式是使用哈希值作为map[int]int的 key。 把缓存对象序列化后放到一个预先分配的大的字节数组中，然后将它在数组中的 offset 作为map[int]int的 value。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 //https://github.com/allegro/bigcache/blob/a2f05d7cbfdc7000a8b7e1c40f27d3f239c204df/shard.go#L18 type cacheShard struct { hashmap map[uint64]uint32 entries queue.BytesQueue lock sync.RWMutex entryBuffer []byte onRemove onRemoveCallback isVerbose bool statsEnabled bool logger Logger clock clock lifeWindow uint64 hashmapStats map[uint64]uint32 stats Stats } func (s *cacheShard) set(key string, hashedKey uint64, entry []byte) error { currentTimestamp := uint64(s.clock.Epoch()) s.lock.Lock() if previousIndex := s.hashmap[hashedKey]; previousIndex != 0 { // 检查是否存在相同哈希键的旧条目 if previousEntry, err := s.entries.Get(int(previousIndex)); err == nil { resetHashFromEntry(previousEntry) // 重置旧条目的哈希 delete(s.hashmap, hashedKey) // 从哈希表中删除旧条目 } } if !s.cleanEnabled { // 如果清理功能未启用 if oldestEntry, err := s.entries.Peek(); err == nil { s.onEvict(oldestEntry, currentTimestamp, s.removeOldestEntry) // 处理最旧的条目 } } w := wrapEntry(currentTimestamp, hashedKey, key, entry, \u0026amp;s.entryBuffer) for { if index, err := s.entries.Push(w); err == nil { // 尝试将新条目推入队列 s.hashmap[hashedKey] = uint64(index) // 更新哈希表 s.lock.Unlock() return nil } if s.removeOldestEntry(NoSpace) != nil { // 如果空间不足，删除最旧的条目 s.lock.Unlock() return errors.New(\u0026#34;entry is bigger than max shard size\u0026#34;) // 返回错误 } } } func (s *cacheShard) getValidWrapEntry(key string, hashedKey uint64) ([]byte, error) { wrappedEntry, err := s.getWrappedEntry(hashedKey) if err != nil { return nil, err } if !compareKeyFromEntry(wrappedEntry, key) { s.collision() if s.isVerbose { s.logger.Printf(\u0026#34;Collision detected. Both %q and %q have the same hash %x\u0026#34;, key, readKeyFromEntry(wrappedEntry), hashedKey) } return nil, ErrEntryNotFound } s.hitWithoutLock(hashedKey) return wrappedEntry, nil } queue.BytesQueue是一个字节数组，按需分配。当加入一个[]byte时，它会把数据 copy 到尾部。\nbigcache 在删除缓存元素的时候， 只是把它从的索引从map[uint64]uint32中删除了，并把它在queue.BytesQueue队列中的数据置为0。删除操作会在 queue.BytesQueue中造成很多的 “空洞”，而且这些 \u0026ldquo;虫洞\u0026rdquo; 不会被整理，也不会被移除。因为它的底层是使用一个字节数组实现的，\u0026ldquo;空洞\u0026rdquo; 的移除是一个耗时的操作，会导致锁的持有时间过长。bigcache 只能等待清理机制把这些 \u0026ldquo;空洞\u0026rdquo; 删除掉。\n其他一些细节： bigcache 中的缓存对象没有刷新过期时间的功能，所有的缓存最终都会过期。 所有缓存的生命周期都是由config.LifeWindow 配置，不能针对单独的key设置。 ","date":"2024-12-04T21:42:56+08:00","image":"https://images.hxzhouh.com/blog-images/2024/12/d1288ea91074f2a22a8ac4fec04d8b90.png","permalink":"https://huizhou92.com/zh-cn/p/%E6%B7%B1%E5%85%A5%E6%8E%A2%E8%AE%A8-bigcache-%E7%9A%84%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96%E6%89%8B%E6%AE%B5/","title":"深入探讨 BigCache 的性能优化手段"},{"content":"Ben Dicken (@BenjDicken) 做了一项测试，执行双层循环， 1 万 * 10 万= 10 亿次循环，看看哪种编程语言快。为此还制作了一个动图来直观展示。\n一般来说，这种项目，最精彩的是issue。\n热心的开发者贡献了各种语言的版本，比如Zig、Julia、Perl、Elixir、Fortan、C#、Lua等\n同时，还在讨论应该怎样优化代码\n比如 @dolanor 提了一个PR # optimize go loops with goroutine 认为Golang的长处是在并发编程，单线程下它的效率肯定比不上C、Rust，应该用goroutine来优化。\n@Brandon-T 在 # Benchmark Issues 讨论了现有基准测试存在的问题及改进方向，核心观点为测试不应包含程序启动、打印等无关时间，应聚焦代码执行本身。\n不知不觉我几乎把整个issue全部看完了。\n这个项目让我想到了年初的1BRC。在枯燥的编码生活中，这是一个很好的消遣。同时能够学习一些性能优化的技巧，参与到与世界各地的人的讨论中来。\n我希望这样的活动能够多一点。\n本文长期链接 如果您觉得我的博客对你有帮助，请通过 RSS订阅我。 或者在X上关注我。 如果您有Medium账号，能给我个关注嘛？我的文章第一时间都会发布在Medium。 ","date":"2024-12-04T19:20:16+08:00","image":"https://images.hxzhouh.com/blog-images/2024/11/6d3e4010fa1e42b2686048757189eab8.png","permalink":"https://huizhou92.com/zh-cn/p/%E9%82%A3%E4%B8%AA%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80%E6%89%8D%E6%98%AF%E6%9C%80%E5%BF%AB%E7%9A%84/","title":"那个编程语言才是最快的？"},{"content":"\u0026ldquo;因为TCP端口号是16位无符号整数，最大65535，所以一台服务器最多支持65536个TCP socket连接.\u0026rdquo; 这是一个非常经典的误解! 即使是有多年网络编程经验的人,也会持有这个错误结论。\n其中0-1023 端口是系统保留的端口，并不能被普通应用程序所使用，这里暂时不考虑这个情况.而是以65535 代替。\n要戳破这个错误结论，可以从理论和实践两方面来。\n理论 *unix 系统通过一个四元组来唯一标识一条TCP连接. 这个四元组的结构是{local_ip, local_port, remote_ip, remote_port}。所以，对于IPv4, 系统理论上最多可以管理2^(32+16+32+16),也就是2的96次方个连接。\nIPv4 可以理解成一个 32位正数\n因为对于同一台服务器来说，一般只有一个 local_ip，那么同一台服务器可以管理 2^(16+32+16) 个连接。 一个服务(进程, 如 Nginx 进程)一般只监听一个 local_port，那么同一台服务就可以管理 2^(32+16) 个连接。 如果从一台远端机器(所谓的 client)来连接这台服务器上的一个服务，那么 local_ip，local_port，remote_ip 这3个变量是固定的，那么就只能建立 2^16=65536 个连接了。这就是经典的误解的来源！ 如果不仅仅考虑TCP，则是一个五元组，加上协议号(TCP，UDP或者其它)。所以一个服务器最多能支持多少个TCP连接，它的限制不在于四元组，而是其他参数。\n文件描述符 我们知道在Linux中一切都是文件（socket也是文件），最大能打开的文件数量，决定了能够同时建立TCP连接的数量，那么一台服务器最大能打开多少个文件呢？\n查看系统支持的最大打开文件描述符数， 1 2 [root@test1 ~]# cat /proc/sys/fs/file-max 1616352 单个进程能打开的最大文件描述符数量 1 2 [root@test1 ~]# ulimit -n 1024 这两个值都是可以改变的，一般在进行压力测试的时候，会手动调整这个值。\nip_local_port_range 如果某个客户端向同一个TCP端点(ip:port)发起主动连接，那么每一条连接都必须使用不同的本地TCP端点，如果客户端只有一个IP则是使用不同的本地端口，该端口的范围在*nix系统上的一个例子是32768到61000左右，可以通过如下命令查看：\n1 2 [root@test1 ~]# cat /proc/sys/net/ipv4/ip_local_port_range 32768\t60999 也就是说，一个客户端连接同一个服务器的同一个ip:port(比如进行压力测试)，最多可以发起30000个左右的连接。不过，对于client端，操作系统会自动根据不同的远端 ip:port，决定是否重用本地端口。\n内存\u0026amp;CPU 一个ESTABLISH状态的socket大约消耗3.3KB内存，如果没有数据业务的话CPU占用很低。所以从内存角度来看，一台服务器能支持的最大TCP 连接数量也是有上线的，远远到不了4元组的上限。\n总结 一台服务器最大能支持多少条 TCP 连接的上限是确定的，那就是2^96 个，但是它的下限，需要根据很多情况来判断，比如内存、CPU、文件描述符等。没有具体答案。\n","date":"2024-12-02T15:50:14+08:00","image":"https://images.hxzhouh.com/blog-images/2024/12/5a04e98368531b4e0208f40a907399f0.png","permalink":"https://huizhou92.com/zh-cn/p/linux%E4%B8%80%E5%8F%B0%E6%9C%8D%E5%8A%A1%E5%99%A8%E6%9C%80%E5%A4%A7%E8%83%BD%E6%94%AF%E6%8C%81%E5%A4%9A%E5%B0%91%E6%9D%A1-tcp-%E8%BF%9E%E6%8E%A5/","title":"linux：一台服务器最大能支持多少条 TCP 连接"},{"content":"最近想要系统的学习一下基础设施方面的知识，所以准备搭建一个学习环境，我没有多余的机器使用，只有一个MacBook Pro 2021 ，所以选择在笔记本上使用 Docker 搭建一套环境，目前看来第一步还是顺利的。\n安装 GitLab Mac 的M1芯片使用的是ARM架构，所以我们去寻找 ARM架构的镜像， 我是用的是yrzr/gitlab-ce-arm64v8:latest\n首先需要创建 gitlab-ce 的三个工作目录 etc、 log、 opt ，不然会报错 。\n将volumes里面的配置修改成你的工作目录就可以了。这里暴露了两个端口9922、9980 因为是在本地使用，所以就没开放https的443 端口，后面也不准备使用https。\ndocker-compose.yaml\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 version: \u0026#34;3.8\u0026#34; services: gitlab-ce: image: yrzr/gitlab-ce-arm64v8:latest container_name: gitlab-ce privileged: true restart: always ports: - \u0026#34;9922:22\u0026#34; - \u0026#34;9980:9980\u0026#34; volumes: - /Users/hxzhouh/tools/gitlab/etc:/etc/gitlab:z - /Users/hxzhouh/tools/gitlab/log:/var/log/gitlab:z - /Users/hxzhouh/tools/gitlab/opt:/var/opt/gitlab:z deploy: resources: limits: memory: 4096M tty: true stdin_open: true 这里需要注意的是，我们对外暴露的端口是9980，因为我们后面会配置 gitlab 的http 端口运行在9980 而不是 默认的80 ，这样做，是为了避免这个问题：\nhttps://stackoverflow.com/questions/66961517/gitlab-http-clone-url-is-wrong-port-8022-missing\n等待docker 被拉起来，然后进入gitlab-ce 里面修改 配置 /etc/gitlab/gitlab.rb\n1 2 docker exec -it gitlab-ce /bin/bash vi /etc/gitlab/gitlab.rb 在最后添加三行，保存退出。\n1 2 3 external_url \u0026#39;http://127.0.0.1:9980\u0026#39; gitlab_rails[\u0026#39;gitlab_ssh_host\u0026#39;] = \u0026#39;127.0.0.1\u0026#39; gitlab_rails[\u0026#39;gitlab_shell_ssh_port\u0026#39;] = 9922 然后修改默认密码\n1 2 3 4 gitlab-rails console -e production user = User.where(id: 1).first user.password = \u0026#39;AIl+mVN(:bk\\#5%c\u0026#39; user.save! 最后在执行reload 操作，然后重启\n1 2 gitlab-ctl reconfigure gitlab-ctl restart 稍等片刻。\n然后 浏览器输入127.0.0.1:9980 就可以打开gitlab-ce了，默认的root 账号密码就是我们刚刚修改的密码。\n添加ssh 跟使用GitHub一样，我们先创建一个ssh 密钥对， 然后将公钥添加到 GitLab里面。在本地 ~/.ssh/config 里面添加配置\n1 2 3 4 5 6 Host 127.0.0.1 HostName 127.0.0.1 Port 9922 IdentityFile ~/.ssh/ssh PreferredAuthentications publickey User root 测试一下\n1 2 ➜ .ssh ssh -T git@127.0.0.1 Welcome to GitLab, @root! ssh 是没有问题的。\n尝试新建一个项目\n创建成功，在本地将代码拉下来。\n1 git clone ssh://git@127.0.0.1:9922/root/hello-world.git ssh 推送也是没有问题的\n1 2 3 ➜ hello-world git:(main) git push origin --force To ssh://127.0.0.1:9922/root/hello-world.git b4dd724..e45f213 main -\u0026gt; main Gitlab Runners 配置 在setting -\u0026gt; CI/CD -\u0026gt; Runners 点击 \u0026hellip;,然后 根据 ‘Show runner installation and registration instructions’ 文档 安装 runners\n我这里输入的命令是：\n1 2 3 4 5 sudo curl --output /usr/local/bin/gitlab-runner https://gitlab-runner-downloads.s3.amazonaws.com/latest/binaries/gitlab-runner-darwin-arm64 sudo chmod +x /usr/local/bin/gitlab-runner gitlab-runner install gitlab-runner start gitlab-runner register --url http://127.0.0.1:9980 --registration-token GR13489416KQ-jitR3JhfMgr8f-9G 有几个关键点需要注意\nEnter tags for the runner (comma-separated): GitLab是用 tag来管理runner 的，最好是一个runner做一件事情，用tag 标记，写.gitlab.ci.yml 的时候需要指定tags Enter an executor executor 有很多种，我这里为了演示，选择了shell 更多关于GitLab Runner 的 的介绍可以参考官网的文章，这里就不做展开。\n安装好了就可以在 http://127.0.0.1:9980/admin/runners 看到效果了\n最后，在 刚才创建的工程中，添加一个 .gitlab-ci.yml 测试一下。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 stages: - build build_job: stage: build tags: - golang-local-shell script: - go build -o myapp only: - main - tags artifacts: paths: - myapp 将代码推送到gitlab，很快就能编译完了 http://127.0.0.1:9980/root/hello-world/-/pipelines\n然后在 http://127.0.0.1:9980/root/hello-world/-/artifacts 可以找到 构建的产物。\n至此，在本地搭建GitLab环境已经弄好，下一篇文章，在折腾在本地搭建k8s 集群，然后从GitLab自动打包成docker镜像推送到 k8s 集群，完成一个CI/CD的完整流水线。\n","date":"2024-11-16T14:58:29+08:00","image":"https://images.hxzhouh.com/blog-images/2024/11/0d1e85b332916907aaf183fc74feb3d7.png","permalink":"https://huizhou92.com/zh-cn/p/01jcsw86hvvsfs4j9rtjshk97z/","title":"如何在MacBook上搭建GitLab"},{"content":"对于无锁编程来讲，无锁只是一个表象，编程者设法组织 data+processing，重点在于如何消除 dataracing。而消除 dataracing 而言，传统的并发编程逻辑是采用关键区、排他性锁、读写锁等方式来保护 data 不会因为 processing 而导致错误读或错误写，那么对于无锁编程来说，则是通过消除 data 的共享性，或者消除并发操作 data 等方式来解决问题。\n所以最典型的无锁编程技法包含两个技巧：\nstructure bumper loop\n其他的方法都是相似思路的具体衍生。 这里的“其他的方法”，是指完全不使用锁定或 CAS 的算法设计方案。本文中讨论的是如何设计数据结构及其处理器（算法）来防止加锁，甚至于连 CAS 也去除。\n至于在共享的data上强行消除竞争读写问题的其他无锁方案，例如RingBuffer之类的工具类库，则是完全依赖于具体的 data 实体并在具体的 CPU 上进行设计，基本上是一种很受限的方法，不具备高层次抽象层面的通用性。尽管其具体的设计思路有迹可循，但却不是最佳的选择：一个优秀的 RingBuffer，它的致命之处就在于在单核心的CPU上，或者单颗 vCPU 的 vHost 上可能是无法降级工作的，或者即使能工作也是低效的或者高消费的。所以本文讨论的是更通用的，在任何高级语言（无论其线程、协程支持度如何）于任何 Targets 上都可以通行的无锁编程技法。\nStructure copy Structure copy是一种经典的无锁编程技巧。它的核心思想在于将易变数据交给一个 structure 管理，通常可能起名为 Entry，然后在这个 structure 上展开数据处理过程。如此，由于数据处理过程只会操作其所关联到的 structure，因此这一组数据本身就是非共享的，也就不需要考虑 dataracing 的潜在可能性的。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 type Worker struct { closed int32 // avoid duplicated release rsrc in Close() entries []*Entry } type Entry struct { Count int Data []any } func (w *Worker) New(data ...any) *Entry { e:=\u0026amp;Entry{Data:data} w.entries = append(w.entries, e) return e } func (e *Entry) Run() { // processing e.data } 假设初始化数据 data []any 被提供给 Worker，基于此产生一个 Entry，然后通过 Entry.Run 来处理初始化数据，产生结果，那么上面的示例代码就避免了数据包（Count，Data）的共享问题，因为这个数据包是排他性独立的。\n有时候我们的数据包很难拆解，此时可以以衍生技法来实现拆解。具体的思路是设法进行分治。即数据包可以按照推进程度重新设计为 step1，step2，等等，每一步骤中的小数据包的计算结果依次提交给下一步骤。又或者数据包可以拆解为若干个小计项目，最后将多个小计结果合并计算（Map-Reduce?）。\n无论采取哪种拆解思路，总的思路不变，即单个 processing 所操作的 data 是排他性独立的一个副本，从而从根本上去除共享加锁解锁的需求。\n问题 问题在于太多的小块内存（Entry struct）可能是不好的。一方面它可能带来额外的内存消耗（如果正在处理一个巨大的链表、数组之类，你不太可能总是制造它们的副本），另一方面，太多频繁的小块内存的分发和析构也会产生难以接受的开销。有时候，强制这样的小块内存在栈上分配（如果语言或者编译器支持）是解决后一问题的良药。不过更多的情况下、或许这的确就是不可行的。\n当然，带有 GC 的语言这方面的压力会小一点。 其次，使用一个sync.Pool也可以减轻小内存频繁分配的压力。\n应用 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 type Logger struct { handler Handler // for structured logging } type Handler interface { Handle(context.Context, Record) error } func (l *Logger) Debug(msg string, args ...any) { l.log(context.Background(), LevelDebug, msg, args...) } func (l *Logger) log(ctx context.Context, level Level, msg string, args ...any) { 。。。。 r := NewRecord(time.Now(), level, msg, pc) 。。。。 _ = l.Handler().Handle(ctx, r) } 在 slog 中，每条日志都会被包装成一个NewRecord ，避免了数据竞争。\nEntry 模式可以说是到处都有在用，用途也不一定限于为了无锁。然而凡是运用到该模式的地方，自动获得了无锁的收益，这其实是很划算的。\nBumper Loop Bumper Loop是一种设计模式\nBumper Loop 最经典的例子是Redis, Redis 使用多线程网络模型，但是在事务处理上使用单线程。\n它的核心思想是将并行事件强行序列化，然后再一一分发给具体处理程序。于是对于这些具体处理程序来讲，共享数据总是排他性的：因为所有处理程序在同一时间下只会运行一个。如果具体处理程序总是飞快地完成，没有阻塞的忧虑，那么Bumper Loop模式将会是一个非常好的消费模式。\n1 2 3 4 5 6 7 8 func (w *Worker) runLoop() { for { switch{ case ev:=\u0026lt;-fileWatcherCh: onFileChanged(ev) } } } 对于低频事件的分发和简化并在此同时去除加锁需求、提升性能来说，循环泵模式是一时之选。在诸如 TCP/IP 服务器的 incoming data 处理上通常Bumper Loop 是最佳选择：\n对新进连接请求采取 Entry 模式制作一个独立的处理器 connectionProcessor，该处理器中以循环泵模式接受输入数据，识别输入数据的模式为规约命令，然后分发给具体的规约命令处理器。\n问题 Bumper Loop 的问题在于，一个阻塞会破坏整个循环，一个过慢的处理会带来不可知的下一事件的处理延迟，高频率的事件会在分发点上阻塞、堆积，甚至是丢失。尽管 Bumper Loop 似乎很明显地有串行化的效率劣势，但它仍被广泛地用于 TCP/IP server/client 编程中。\nStructure Copy 与 Bumper Loop 结合 Bumper Loop 的问题之一是不太适合高频事件场景，一般来说事件频率在80ms以上时才比较好用。这种尺度的隐喻是说单次事件处理平均耗时应该小于 80ms。\n在不那么严格的场景中（例如非金融高频交易），有时候可以在耗时的事件处理器中启动一个 gorountine 去异步地慢慢处理，而主体的 bumpper loop 则继续去分发后继事件。这时候异步 go routine 又可以用到 Entry 模式，适当地复制少许状态以便解耦竞态条件。\n","date":"2024-10-19T12:03:18+08:00","permalink":"https://huizhou92.com/zh-cn/p/go-%E9%AB%98%E6%80%A7%E8%83%BD%E7%BC%96%E7%A8%8B-ep9-%E4%B8%A4%E4%B8%AA%E6%9C%89%E7%94%A8%E7%9A%84-golang-%E6%97%A0%E9%94%81%E7%BC%96%E7%A8%8B%E6%8A%80%E5%B7%A7/","title":"Go 高性能编程 EP9: 两个有用的 Golang 无锁编程技巧"},{"content":"2022年，字节跳动给Golang提了issue建议把map的底层实现改成SwissTable的。2023年，dolt写了一篇博客SwissMap: A smaller, faster Golang Hash Table 分享他们 设计了一个基于SwissTable 的 Map ,引起了广泛的关注。目前 Go 核心团队已经开始重新审视 swisstable 设计，在runtime中也添加了部分代码，趁着假期，刚好有时间深入了解一下原理，跟runtime map 相比有什么区别，以及为什么它可能会成为map的标准实现。\nThis article was first published in the Medium MPP plan. If you are a Medium user, please follow me on Medium. Thank you very much.\n本文不会完全解释hashtable或者swisstable的原理。您需要对hashtable 有一定的了解。\n哈希表提供了一个key到对应value的映射，通过一个hash函数把key转换成某个“位置“，从这个位置上可以直接拿到我们想要的value，\n传统 hashtable 哈希表提供了一个key到对应value的映射，通过一个hash函数把key转换成某个“位置“，从这个位置上可以直接拿到我们想要的value。不过，即使hash函数再完美，把无限的key映射到一个有限大小的内存空间内也还是不可避免得会产生冲突：两个不同的key会被映射到同一个位置。 为了解决这个问题，传统的hashtable有好几个解决方案，最常见的解决冲突的办法有“链表法”和“线性探测法”。\n链表法 链表法是最常见的，它的中心思想在于如果key映射到了相同的位置，那么就把这些key和value存在一张链表里。查找的时候先用hash函数计算得到位置，然后再从存放在该位置上的链表里一个个遍历找到key相等的条目。它的结构类似这样：\nfigure 1: 拉链法实现 hashtable\n链表法实现很简单，没那么多边界条件要考虑,插入数据和删除数据很快，插入用链表的头插法，删除只需要移动部分节点的next指针。此外，链表法能采取扩容之外的手段阻止查询性能退化，比如把过长链表转换成搜索树等。链表法的缺点是本身对缓存不够友好，冲突较多的时候缓存命中率较低从而影响性能。不同的slot之间数据在内存里的跨度较大，数据结构整体的空间局部性较差。\n线性探测法 线性探测是另一种常见的哈希表冲突解决方法。它解决冲突的方式于链表法不同，在遇到hash冲突的时候，它会从冲突的位置开始向后一个个查找，直到找到一个空位，或者没找到然后索引回到了冲突发生的位置，这时会进行扩容然后再重新执行上述插入流程。\nFigure 2 ：线性探测法添加数据 动画演示\n查找也是一样的，首先通过hash函数计算得到元素应该在的位置，然后从这个位置开始一个个比较key是否相等，遇到被删除的元素就跳过，遇到空的slot就停止搜索，这表示元素不在这个哈希表中。所以删除元素的时候，使用的是标记删除。\nFigure 3: 线性探测法查找数据演示\n线性探测法 的时间复杂度跟链表法差不多，它的优点是对缓存友好，现在可以用数组之类的紧密数据结构实现。同时，它的缺点也很明显：\n实现复杂，一个slot有元素、空、被删除这三种状态 hash冲突是连锁式的，一处冲突可能会连续影响多处，最终导致插入同样的数据，它扩容的次数会比链表法更多，最终可能会用掉更多的内存。 因为冲突会造成后续插入和删除的连锁反应，所以查找过程退化到O(n)的概率更大，而且没法像链表法那样把有大量冲突的地方转换成搜索树之类的结构。\n因为删除元素麻烦，加上冲突会有连锁影响，所以很多库实现的hashtable都是用的链表法。不过即使有这么多缺点，光缓存友好和内存利用率高在现代计算机上就是非常大的性能优势了，所以像golang和python都会使用线性探测法的近似变种来实现哈希表。 Go Hashmap 如何存储数据 我们首先来回忆一下 Go Map 是如何存储数据的。\nfigure 4: go map 示意图\n快速总结一下：\nGo map 底层通过哈希函数将 key 映射到多个 bucket中。每个 bucket 具有固定数量的键值对slot，用于存储 key 和对应的 value。 每个 bucket 能存储 8个键值对。当冲突发生时（即多个 key 被映射到同一个 bucket），这些 key 和 value 会在同一个 bucket 内存储。 map 通过哈希函数计算 key 的哈希值，并根据哈希值找到对应的 bucket。 如果某个 bucket 被填满（8 个slot已用完），会生成一个 overflow bucket，继续存储新的键值对。 查找时数据时，首先计算要查找的 key 的哈希值，然后确定该哈希值映射到的 bucket。Go 会检查每个slot，如果 bucket 中存在overflow bucket，会顺序检查overflow bucket中的 key。 SwissTable，一种高效的 hashtable 实现方式 SwissTable 是一种基于改进的线性探测法的哈希表实现，其核心思想是通过改进哈希表的结构和元数据存储，优化了性能和内存使用。SwissTable 采用了一种新的元数据控制机制，大幅减少了不必要的键比较操作，同时利用 SIMD 指令提升吞吐量。\n我们回顾了一下两种常见的哈希表实现，它们要么浪费内存且对缓存不友好；要么发生冲突后会更容易导致查找、插入、删除操作性能下降。这还是在有“完美哈希函数”的情况下，如果你用了个不那么好的哈希函数，那会导致key冲突的概率大大上升，性能问题会更加明显，最坏的情况下性能甚至会不如在数组里进行线性搜索。\n业界开始寻找一种既对缓存友好又不会让查找性能退化的太厉害的哈希表算法。大多数人的研究方向是开发更好的哈希函数，在让哈希函数不断接近“完美哈希函数”的品质的同时用各种手段优化计算性能；另外一些人在改进哈希表本身的结构力求在缓存友好、性能和内存用量上找到平衡。swisstable就属于后者。\nswisstable的时间复杂度和线性探测法的差不多，空间复杂度介于链表法和线性探测之间。 swisstable的实现有很多，我主要基于dolthub/swiss这个实现进行简要的介绍。\nSwissTable 的基本结构 虽然名字变了，实际上swisstable依然是hashtable，而且使用改进的线性探测法来解决hash冲突。 所以大家应该能想象到，swisstable的底层应该也是个类似数组的结构。有了这样大致的模糊印象就可以了，现在我们可以来看看swisstable的结构了:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 type Map[K comparable, V any] struct { ctrl []metadata groups []group[K, V] hash maphash.Hasher[K] resident uint32 //currently occupied slots in the hash map dead uint32 //A tombstone indicates a slot that was previously occupied but has been deleted limit uint32 // This field represents the maximum number of elements that can be added to the hash map before it needs to be resized. It is calculated based on the load factor and the number of groups. } // metadata is the h2 metadata array for a group. // find operations first probe the controls bytes // to filter candidates before matching keys type metadata [groupSize]int8 // group is a group of 16 key-value pairstype group[K comparable, V any] struct { keys [groupSize]K values [groupSize]V } 在swisstable 的实现中，ctrl 是一个 []metadata ，[]metadata 跟 []group[K, V] 数量对应 。每个group有8个slot\nhash会被分成两部分：57bits长度的为H1，用于确定从哪个groups开始探测，剩下的7bits叫做H2，刚好放在metadata中， 被用作是当前key的哈希特征值，用于后面的查找和过滤。\nswisstable比传统哈希表更快的秘诀就在于这些被叫做ctrl的metadata。控制信息主要是下面这几种：\nslot是否为空: 0b10000000 slot里的元素是否已经被删除: 0b11111110 slot里存的键值对的key的哈希特征（H2）0bh2\n对于空、删除这几种特殊状态，对应的值都是特意设置的，目的是为了能够在后面的匹配中使用SIMD指令，获得最高的性能。 查找、插入、删除都是基于这些ctrl的，它们非常小，可以尽量多的被放入CPU的高速缓存，同时又包含了足够的信息以满足哈希表的增删改查。而slot就只用来存数据，ctrl和slot一一对应，控制信息在ctrl里的索引就是对应的数据在slot里的索引，下面以添加数据为例，查找，删除 都差不多。\n添加数据 swisstable 添加数据的过程分成几个步骤。\n计算哈希值并分割为 h1 和 h2 , 根据 h1 确定开始探测的groups , 使用 metaMatchH2 检查当前组中的 metadata 是否有匹配的 h2。如果找到匹配的 h2，则进一步检查对应槽位中的键是否与目标键相同。如果相同，则更新值并返回。 如果没有找到匹配的键，使用 metaMatchEmpty 检查当前组中是否有空闲slot。如果有slot，则插入新的键值对，并更新 metadata 和 resident 计数。 如果当前组没有空闲槽位，进行线性探测，检查下一个groups。 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 func (m *Map[K, V]) Put(key K, value V) { if m.resident \u0026gt;= m.limit { m.rehash(m.nextSize()) } hi, lo := splitHash(m.hash.Hash(key)) g := probeStart(hi, len(m.groups)) for { // inlined find loop matches := metaMatchH2(\u0026amp;m.ctrl[g], lo) for matches != 0 { s := nextMatch(\u0026amp;matches) if key == m.groups[g].keys[s] { // update m.groups[g].keys[s] = key m.groups[g].values[s] = value return } } // |key| is not in group |g|, // stop probing if we see an empty slot matches = metaMatchEmpty(\u0026amp;m.ctrl[g]) if matches != 0 { // insert s := nextMatch(\u0026amp;matches) m.groups[g].keys[s] = key m.groups[g].values[s] = value m.ctrl[g][s] = int8(lo) m.resident++ return } g += 1 // linear probing if g \u0026gt;= uint32(len(m.groups)) { g = 0 } } } func metaMatchH2(m *metadata, h h2) bitset { // https://graphics.stanford.edu/~seander/bithacks.html##ValueInWord return hasZeroByte(castUint64(m) ^ (loBits * uint64(h))) } func nextMatch(b *bitset) uint32 { s := uint32(bits.TrailingZeros64(uint64(*b))) *b \u0026amp;= ^(1 \u0026lt;\u0026lt; s) // clear bit |s| return s \u0026gt;\u0026gt; 3 // div by 8 } 虽然，步骤很少，但是里面使用了比较复杂的位运算，按照正常的流程，需要把h2 跟所有的 对比，直到找到我们要的目标。swisstable 使用了一个很巧妙的方式来实现这个目标。\n首先将h2 * 0x0101010101010101 得到一个uint64，这样就能一次性对比 8个 ctrl 然后跟meta 做 xor 运行。 如果 h2 存在于 metadata 中。那么对应的bit 就是0b00000000 ， metaMatchH2 的作用，可以用 下面的单元测试理解， nextMatch 用于确定 key 在group中的的具体位置。 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 func TestMetaMatchH2(t *testing.T) { metaData := make([]metadata, 2) metaData[0] = [8]int8{0x7f, 0, 0, 0x7f, 0, 0, 0, 0x7f} // Imitate ctrl m := \u0026amp;metaData[0] h := 0x7f metaUint64 := castUint64(m) h2Pattern := loBits * uint64(h) xorResult := metaUint64 ^ h2Pattern fmt.Printf(\u0026#34;metaUint64: %b\\n\u0026#34;, xorResult) r := hasZeroByte(xorResult) fmt.Printf(\u0026#34;r: %b\\n\u0026#34;, r) for r != 0 { fmt.Println(nextMatch(\u0026amp;r)) } } ---- output // metaUint64: 00000000 11111110 11111110 11111110 0000000 01111111 01111111 00000000 // r: 10000000 00000000 00000000 00000000 10000000 00000000 00000000 10000000 // 0 // 3 // 7 SwissTable 的优势 看完SwissTable的实现，可以总结为下面几点：\n对hashtable的操作从slot转移到了ctrl上，ctrl更小更容易被填入CPU的高速缓存，因此比直接在slot上操作更快，即使需要多付出一次从ctrl得到索引后再去查找slot的代价。 记录哈希特征值，减少了无意义的key等值比较，这是线性探测法性能下降的主要元凶。 对slot的查找和操作是通过ctrl批量进行的，单位时间内吞吐量有显著提升。 标志位的值和整个数据结构的内存布局都为SIMD进行了优化，可以充分发挥性能优势。 对slot也有优化，比如对太大的数据会压缩存储以提高缓存命中率。\nswisstable 解决了空间局部性问题的基础上，还利用了现代CPU的特性批量操作元素，所以性能会有飞跃般的提升。 最后在我本地macbook m1 （不支持SIMD）上跑benchmark，结果如下，在大map场景下，swisstable 性能有比较明显的提升。\nFigure 5: swisstable 官方benchmark\n总结 目前go 官方还没有swisstable 的实现， 但是关于它的讨论一直再继续，目前社区也有几种实现。比如concurrent-swiss-map ，swiss 等。\n不过实现都不是特别完美，比如在小map 场景下swisstable 的性能甚至比不上 runtime_map 等。但是swisstable 表现出来的潜力已经在其他语言上的表现，说明它值得我们期待。\n参考文档 dolthub https://www.dolthub.com/blog/2023-03-28-swiss-map/ swisstable 原理 https://abseil.io/about/design/swisstables 首次提出swisstable的cppcon演讲：https://www.youtube.com/watch?v=ncHmEUmJZf4 针对swisstable算法的一些改进：https://www.youtube.com/watch?v=JZE3_0qvrMg 位运算原理: http://graphics.stanford.edu/~seander/bithacks.html##ValueInWord hash 函数对比： https://aras-p.info/blog/2016/08/09/More-Hash-Function-Tests/ 另外一篇位运算原理的文章 https://lemire.me/blog/2016/06/27/a-fast-alternative-to-the-modulo-reduction/ ","date":"2024-09-30T11:25:51+08:00","image":"https://images.hxzhouh.com/blog-images/2024/09/f08c74aea8485d51d461d18494df416e.png","permalink":"https://huizhou92.com/zh-cn/p/swisstable-%E4%BC%9A%E6%88%90%E4%B8%BA-golang-std-map%E5%98%9B/","title":" SwissTable 会成为 Golang std map嘛？"},{"content":"在软件架构中，限流是一种控制资源使用和保护系统安全的重要机制。它通过限制在一定时间内可以处理的请求数量，来防止系统过载，确保系统在高负载情况下仍能保持稳定运行。\n本文的目标是分析和实现几种常见的限流算法，以及分析他们优缺点。最后我们探讨一下真实业务代码中的一些限流设计。\nThis article was first published in the Medium MPP plan. If you are a Medium user, please follow me on Medium. Thank you very much.\n假设我们通过性能测试得出我们的系统最大的负载为10TPS。\n流量计数器模式 最简单的做法，我们做一个计时器，每秒最多允许10个请求通过，超过这个数量的流量就拒绝。\nCode1 ： windows limit run it\nhttps://gist.github.com/hxzhouh/51020e18622c2e38ebf21cd6a9dc5cc6\n但是这个做法是有问题的，假设我们2秒内收到了都收到了10TPS请求，但是是在 0.9s 与 1.1s 收到的，这样虽然每个周期的流量都不超过10 TPS请求的阈值，但是系统确实曾经在1s内发生了超过阈值的20TPS请求。\n流量计数器的缺陷根源在于它只是针对时间点进行离散的统计，为了弥补该缺陷，一种名为“滑动时间窗”的限流模式被设计出来，它可以实现平滑的基于时间片段统计。\n滑动窗口机制 滑动窗口算法(Sliding Window Algorithm)在计算机科学的很多领域中都有成功的应用，譬如TCP协议的阻塞控制(Congestion Control)使用到滑动窗口算法\n滑动窗口算法通过将时间分为多个小的时间段，每个时间段内维护一个独立的计数器。当一个请求到达时，它会被分配到当前时间所在的小时间段，并检查该时间段的计数器是否已达到限制。如果未达到，则允许请求并增加计数；如果已达到，则拒绝请求。随着时间的推移，旧的时间段会淡出窗口，新的时间段会加入。\ncode2: sliding_windows try it\nhttps://gist.github.com/hxzhouh/c5c79ea4b80ea5a026052471de07107f\n滑动窗口算法其实就是把流量计数器算法的时间窗口划分小一点，提供更细致的流量控制，并不能完全解决瞬时大流量。也很难在更细粒度上对流量曲线进行整形，起不到削峰填谷的作用。下面继续介绍两种适用于阻塞式限流的限流模式。\n漏桶算法 漏桶算法是通过一个固定容量的队列来模拟桶，以恒定速率从桶中取出请求进行处理，无论请求到达的频率如何，都保证请求以均匀的速度被处理，从而平滑流量并防止流量突增。\nCode3: leakBucket try it\nhttps://gist.github.com/hxzhouh/ba78993644ce58958127f64fc0976c55\n漏桶算法适用于需要强制执行固定速率处理的场景，如网络流量控制、API请求限制等。通过控制令牌的添加速率，漏桶算法能够有效地避免系统因瞬时流量高峰而过载。漏桶实现起来很容易，难点在于如何确定漏桶的两个参数：桶的大小和水的流出速率。如果桶设置得太大，那服务依然可能遭遇流量过大的冲击，不能完全发挥限流的作用；如果设置得太小，那很可能误杀掉一部分正常的请求。\n令牌桶算法 令牌桶算法跟漏桶算法想法，更像现实生活中的排队算法，系统以固定的速率放号，我们首先要取号，然后再进行业务处理。 假设我们要限制系统在X秒内最大请求次数不超过Y，那就每间隔X/Y时间往桶中放一个令牌，当有请求进来时，首先要从桶中取得一个准入的令牌，然后才能进入系统进行处理。如果获取不到令牌就返回请求失败。\nCode 4 ：token_limit try it https://gist.github.com/hxzhouh/0c172824334aeea5ef101bd682fef59e\n令牌桶算法适用于需要处理突发流量的场景，如网络通信、API调用等。通过控制令牌的填充速率和桶的容量，令牌桶算法能够有效地平衡流量，防止系统过载，同时 如果系统资源富裕的情况下，允许在短期内处理更多的请求。跟漏桶算法类似，令牌生成的速度，也是需要重点考虑的。\n实际业务中的限流算法 分布式限流算法 上面介绍的四个限流算法，状态都是存储在内存中的，我们可以理解为单机限流算法，微服务架构下，它们就最多只能应用于集群最入口处的网关上，对整个服务集群进行流量控制，无法细粒度地管理流量在内部微服务节点中的流转情况。如果我们需要实现一个服务的多个节点之间协同限流，那么我们需要将状态保存在集群中共享，下面是一个使用Redis 实现分布式 令牌桶算法的实现。实际上，我在业务中使用更多的是这种方式。\n优先级 服务器资源是宝贵的，再资源紧张的情况下，我们更加希望宝贵的资源用于服务我们的vip客户。因此，我们可以设计一种基于“货币化额度”的分布式限流方案。不同于传统令牌桶算法中的“准入/拒绝”二元判定方式，这里的“货币额度”是一种更灵活的限流方式。用户在访问集群中的服务时，每次都会消耗一定的额度，类似于消耗资源的“货币”，并且可以根据用户的等级分配不同的额度。VIP用户可能拥有更高的额度，普通用户则有一定的额度限制。当额度耗尽后，用户需要重新向“令牌桶”申请额度，才能继续访问。\ncode 5: quota try it\nhttps://gist.github.com/hxzhouh/dc06a2947f4d436bdce9743d65b6c9e6\n结论 本文介绍了几种常见的限流算法，包括流量计数器、滑动窗口、漏桶、令牌桶等，并分析了它们在不同场景下的应用效果。流量计数器算法简单易用，但无法应对瞬时高峰流量，滑动窗口算法在一定程度上弥补了这一缺陷。漏桶算法通过固定速率处理请求，适合需要平滑流量的场景，而令牌桶算法则能够灵活处理突发流量，并允许系统在短时间内接收更多请求。\n在实际业务中，尤其是微服务架构下，分布式限流是非常重要的。通过 Redis 等中间件的协同，分布式令牌桶算法能有效管理多个节点的流量。此外，基于优先级的“货币化额度”方案为限流设计提供了更多灵活性，有助于提升 VIP 客户体验。限流机制不仅能够保护系统免受过载，还能提升系统的整体稳定性与性能。\n参考文档 [1] 限流设计模式\n本文长期连接 如果您觉得我的博客对你有帮助，请通过 RSS订阅我。 或者在X上关注我。 如果您有Medium账号，能给我个关注嘛？我的文章第一时间都会发布在Medium。 ","date":"2024-09-25T09:34:59+08:00","image":"https://images.hxzhouh.com/blog-images/2024/09/f146e1aedafc425732135df81c5cd244.png","permalink":"https://huizhou92.com/zh-cn/p/%E5%B8%B8%E8%A7%81%E9%99%90%E9%80%9F%E7%AE%97%E6%B3%95%E7%9A%84%E5%88%86%E6%9E%90%E4%B8%8E%E5%AE%9E%E7%8E%B0/","title":"常见限速算法的分析与实现"},{"content":"背景 JSON是一种轻量级的数据交换格式，Go 语言的 encoding/json 包自诞生以来已有十年之久，它凭借其灵活的特性赢得了开发者的青睐。开发者可以通过结构体标签自定义字段的 JSON 表现形式，也可以让 Go 类型自定义其在 JSON 中的表现形式。然而，随着 Go 语言和 JSON 标准的发展，一些功能上的缺失和性能上的限制逐渐暴露出来。\n功能缺失：比如，不能指定 time.Time 类型的自定义格式化，不能在序列化时省略特定的 Go 值等。 API 缺陷：比如，没有简单的方法来正确地从 io.Reader 中反序列化 JSON。 性能限制：标准json包的性能表现并不尽如人意，特别是在处理大量数据时。 行为缺陷：比如，对 JSON 语法的错误处理不够严格，大小写不敏感的反序列化等。 就像math/v2一样的，Go 官方提出encoding/json/v2 来解决上面的那些问题，本文主要目标是分析enable/json中 关于空值的一些问题。以及它在 encoding/json/v2中是如何被解决的。本文不涉及 encoding/json/v2 中其他的修改\nThis article was first published in the Medium MPP plan. If you are a Medium user, please follow me on Medium. Thank you very much.\nOmitempty 在encoding/json包中，有这样关于omitempty的描述:\nThe \u0026ldquo;omitempty\u0026rdquo; option specifies that the field should be omitted from the encoding if the field has an empty value, defined as false, 0, a nil pointer, a nil interface value, and any empty array, slice, map, or string.\n但是，这种预定义的”空”值判断逻辑并不能满足所有实际场景的需求。我们来看一个例子：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 type Post struct { Id int64 `json:\u0026#34;id,omitempty\u0026#34;` CreateTime time.Time `json:\u0026#34;create_time,omitempty\u0026#34;` TagList []Tag `json:\u0026#34;tag_list,omitempty\u0026#34;` Name string `json:\u0026#34;name,omitempty\u0026#34;` Score float64 `json:\u0026#34;score,omitempty\u0026#34;` Category Category `json:\u0026#34;category,omitempty\u0026#34;` LikePost map[string]Post `json:\u0026#34;like,omitempty\u0026#34;` } type Tag struct { ID string `json:\u0026#34;id\u0026#34;` Name string `json:\u0026#34;name\u0026#34;` } type Category struct { ID float64 `json:\u0026#34;id\u0026#34;` Name string `json:\u0026#34;name\u0026#34;` } func main() { b, _ := json.Marshal(new(Post)) fmt.Println(string(b)) } 输出结果为：\n1 {\u0026#34;create_time\u0026#34;:\u0026#34;0001-01-01T00:00:00Z\u0026#34;,\u0026#34;category\u0026#34;:{\u0026#34;id\u0026#34;:0,\u0026#34;name\u0026#34;:\u0026#34;\u0026#34;}} 虽然Post 各个字段都添加了omitempty 。但是结果并不像我们预期一样。\nomitempty 不能处理空 struct ，比如 Post.Category omitempty 处理time.Time 的方式不是 我们理解的UTC =0，也就是1970-01-01 00:00:00 ,而是 0001-01-01T00:00:00Z 。 Omitzero标签 在 encoding/json/v2 中，会添加一个新的标签 omitzero，添加了两个功能，来解决上面的两个问题。（目前这个功能还在开发中，不过可以通过go-json-experiment/json提前体验新功能）\n更好的time.Time 处理。 支持自定义IsZero函数。\n比如下面下面的代码： 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 package main import ( \u0026#34;encoding/json\u0026#34; \u0026#34;fmt\u0026#34; v2_json \u0026#34;github.com/go-json-experiment/json\u0026#34; \u0026#34;math\u0026#34; \u0026#34;time\u0026#34;) type Post struct { Id int64 `json:\u0026#34;id,omitempty,omitzero\u0026#34;` CreateTime time.Time `json:\u0026#34;create_time,omitempty,omitzero\u0026#34;` TagList []Tag `json:\u0026#34;tag_list,omitempty\u0026#34;` Name string `json:\u0026#34;name,omitempty\u0026#34;` Score ScoreType `json:\u0026#34;score,omitempty,omitzero\u0026#34;` Category Category `json:\u0026#34;category,omitempty,omitzero\u0026#34;` LikePost map[string]Post `json:\u0026#34;like,omitempty\u0026#34;` } type ScoreType float64 func (s ScoreType) IsZero() bool { return s \u0026lt; math.MinInt64 } type Tag struct { ID string `json:\u0026#34;id\u0026#34;` Name string `json:\u0026#34;name\u0026#34;` } type Category struct { ID float64 `json:\u0026#34;id\u0026#34;` Name string `json:\u0026#34;name\u0026#34;` } func main() { v1String, _ := json.Marshal(new(Post)) fmt.Println(string(v1String)) v2String, _ := v2_json.Marshal(new(Post)) fmt.Println(string(v2String)) } 跟encoding/json 相比 encoding/json/v2 解决了上面提到的问题。\n1 2 {\u0026#34;create_time\u0026#34;:\u0026#34;0001-01-01T00:00:00Z\u0026#34;,\u0026#34;category\u0026#34;:{\u0026#34;id\u0026#34;:0,\u0026#34;name\u0026#34;:\u0026#34;\u0026#34;}} {\u0026#34;score\u0026#34;:0} 结论 通过引入omitzero标签，Go语言在解决JSON编码中”空”值处理的痛点上迈出了重要一步。这个方案不仅满足了开发者对更灵活的”空”值定义的需求，还保持了与现有系统的兼容性。目前该omitzero的落地时间尚未确定，最早也要等到Go 1.24版本。此外，encoding/xml等也会效仿json包，增加omitzero标签。\nencoding/json/v2 还包括 性能等其他方面的更新， 有兴趣的Gopher 可以 提前了解这些改动，本博客也会一直关注这个proposal\nGo语言开始走向成熟。\n","date":"2024-09-15T10:05:57+08:00","image":"https://images.hxzhouh.com/blog-images/2024/09/5cfcc61c5e45994e3e35ceb82bfa6bc8.png","permalink":"https://huizhou92.com/zh-cn/p/go-%E6%8F%90%E6%A1%88-json-v2-%E6%9D%A5%E4%BA%86/","title":"Go 提案: JSON v2 来了"},{"content":"在[上一篇](013 两个有用的 Golang 无锁编程技巧.zh-cn)文章中，我们讨论了两个无锁编程思想。总结就是：通过精心的设计消除数据共享或者消除并发访问同一个数据。尽管我们一直想追求完全的无锁编程，但事实是这基本不可能。一般来说，我们讨论look-free，是因为想要避免加锁，那么使用CAS是一种不错的选择。如果CAS 都不能够满足要求，那么我们可以尽量将Mutex 的粒度缩小，或者使用RWmutex 替换Mutex等。\nlock-free的优势：\n减少线程阻塞和等待时间 避免线程的优先级反转 提高并发性能 消除竞态条件（race condition）、死锁、饿死等潜在问题 代码更加清晰易懂\n本文我们将使用Go实践一下几种lock-free编程的方案。 Channel Share Memory By Communicating 是Go语言官方推荐的共享内存方案：\n不要通过共享内存进行通信；相反，通过通信来共享内存。\nchannel实现 lock-free 的 原因是\nchannel 将数据所有全交出去了 channel 内部使用了锁\n在官方博客的例子中 1 2 3 4 5 6 7 8 9 type Resource string func Poller(in, out chan *Resource) { for r := range in { // poll the URL // send the processed Resource to out out \u0026lt;- r } } 数据通过 in，out 两个channel 流转，不存在同一个时间有多个goroutine 同时操作一份数据，所以这就是lock-free。\nCAS 现在几乎所有的 CPU 指令都支持 CAS 的原子操作，\nCAS (compare and swap) 是原子操作的一种，用于在多线程中实现原子数据交换，避免多线程同时改写某一共享数据时，由于执行顺序不确定性以及中断的不可预知性产生的数据不一致问题。我们可以直接用 CAS 来实现 lock free的数据结构。\n如果我们要实现一个stack 数据结构，最常用的方案就是使用slice+ RWmutex ,保证并发安全， 同时，我们也可以使用CAS来实现 这个数据结构，完整的 代码如下：\n通过简单的benchmark 测试， lock-free 版本的 stack 要比 slice+ RWmutex 快大约20%，如果是在并发场景下，lock-free 的性能表现可能还会更好。\n1 2 3 4 5 6 7 8 9 10 11 12 13 func BenchmarkConcurrentPushLockFree(b *testing.B) { stack := NewStackByLockFree() for i := 0; i \u0026lt; b.N; i++ { stack.Push(i) } } func BenchmarkConcurrentPushSlice(b *testing.B) { stack := NewStackBySlice() for i := 0; i \u0026lt; b.N; i++ { stack.Push(i) } } 1 2 3 4 ➜ lock-free git:(main) ✗ go test --bench=. BenchmarkConcurrentPushLockFree-10 22657522 49.66 ns/op BenchmarkConcurrentPushSlice-10 29135671 59.04 ns/op Struct Copy 从本质上讲Struct Copy 是一种空间换时间的策略。如下面的代码所示：\nSingleBuffer 是一个共享资源，外部代码每次使用它的时候需要加锁， 但是如果用一个BufferWrapper 将它包裹起来，让每个goroutine 持有一个单独的BufferWrapper，那么是不是不用去考虑dataracing了？ （使用sync.pool是为了减少内存分配）\n性能测试\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 func BenchmarkSingleBuffer_print(b *testing.B) { for i := 0; i \u0026lt; b.N; i++ { run_buff_bench(singleBuff) } } func BenchmarkBufferWrapper_print(b *testing.B) { bufferWrapper := NewBufferWrapper() for i := 0; i \u0026lt; b.N; i++ { run_buff_bench(bufferWrapper) } } func run_buff_bench(buff printId) { wg := sync.WaitGroup{} f := func(id int) { defer wg.Done() for j := 0; j \u0026lt; 10000; j++ { buff.print(id) } } for j := 0; j \u0026lt; 100; j++ { wg.Add(1) go f(j) } wg.Wait() } 1 2 BenchmarkSingleBuffer_print-10 4 261640427 ns/op BenchmarkBufferWrapper_print-10 67 18320110 ns/op fastjson 的 Parser 也是如此做的， 我们在很多性能优化场景下都能见到这种操作。\n总结 本篇文章中，我们探讨了三种实现 lock-free 编程的方法，并通过实际的代码和性能测试验证了它们的有效性。尽管完全实现无锁编程是一个艰难的目标，但通过合理的设计和技术选型，可以显著减少锁的使用，提高系统的并发性能。在实际开发中，应该根据具体场景选择合适的方案，比如在性能敏感的场景下，可以优先考虑 CAS 和 Struct Copy；在数据流转清晰、操作简单的场景中，Channel 是一种非常自然的选择。\n","date":"2024-09-09T09:46:47+08:00","permalink":"https://huizhou92.com/zh-cn/p/go-%E9%AB%98%E6%80%A7%E8%83%BD%E7%BC%96%E7%A8%8Bep11-lock-free-%E5%AE%9E%E8%B7%B5.zh-cn/","title":"go 高性能编程EP11 lock-free 实践.zh-cn"},{"content":"最近发现 Golang 标准库竟然自带了 varint 的实现，代码位置在 encoding/binary/varint.go，这个跟protobuf里面的varint实现基本是一致的。刚好借助 golang 标准库的 varint 源码，我们来系统地学习和梳理下 varint。\n熟悉 protobuf 的人肯定对 varint 不陌生，protobuf 里面除了带 fix (如 fixed32、fixed64) 之外的整数类型, 都是 varint 编码。\nvarint 的出现主要是为了解决两个问题：\n空间效率：以 uint64 类型为例，可以表示的最大值为 18446744073709551615。然而在实际业务场景中，我们通常处理的整数值远小于 uint64 的最大值。假设在我们的业务中，需要处理的整数值仅为 1，但在网络传输过程中，我们却需要使用 8 个字节来表示这个值。这就导致了大量的空间浪费，因为大部分字节并没有实际存储有效的信息。varint 编码通过使用可变长度的字节序列来表示整数，使得小的整数可以用更少的字节表示，提高空间效率。 兼容性：varint 使得我们可以在不改变编码 / 解码逻辑的情况下，处理不同大小的整数。这意味着我们可以在不破坏向后兼容性的情况下，将一个字段从较小的整数类型（如 uint32）升级到较大的整数类型（如 uint64） 本文将通过分析 Golang 标准库自带的 varint 源码实现，介绍 varint 的设计原理以及Golang标准库是如何解决 varint 在编码负数时遇到的问题。\nThis article was first published in the Medium MPP plan. If you are a Medium user, please follow me on Medium. Thank you very much.\nVarint 的设计原理 varint 的设计原理非常简单：\n7bit 为一组：将整数的二进制表示分为 7 个 bit 位一组。从低位到高位，每 7 个 bit 位作为一个单元。 最高位表示 “继续” 标志。在每个 7 位的单元前面添加一个标志位，形成一个 8 位的字节。如果后面还有更多的字节，这个标志位就设置为 1，否则设置为 0。\n例如：对于一个整数 uint64(300)，它的二进制表示是 100101100。我们可以将它分为两组，即 10 和 0101100。然后在每组前面添加标志位，得到两个字节 00000010 和 10101100，这两个字节就是 300 的 varint 编码。相比于用 uint64 的 4 字节表示，少了 75% 的存储空间。 1 2 3 4 5 6 7 8 9 func main() { v := uint64(300) bytes := make([]byte, 0) bytes = binary.AppendUvarint(bytes, v) fmt.Println(len(bytes)) for i := len(bytes); i \u0026gt; 0; i-- { fmt.Printf(\u0026#34;%08b \u0026#34;, bytes[i-1]) } } 无符号整数的 Varint 在 Golang 标准库中有两套 varint 的函数: 分别用于无符号整数的 PutUvarint和 Uvarint，以及用于有符号整数的 Varint 和 PutVarint\n我们先看下无符号整数的 varint 实现，代码如下：\nlist1: go src PutUvarint\n1 2 3 4 5 6 7 8 9 10 func PutUvarint(buf []byte, x uint64) int { i := 0 for x \u0026gt;= 0x80 { buf[i] = byte(x) | 0x80 x \u0026gt;\u0026gt;= 7 i++ } buf[i] = byte(x) return i + 1 } 代码里有个非常重要的常量：0x80，对应于二进制编码就是 1000 0000。这个常量对接下来的逻辑非常重要：\nx \u0026gt;= 0x80。这意味着 x 的二进制表示形式至少有 8 位，我们刚才讲到 7 个 bit 位为一组，那 x 就需要被拆分了。 byte(x) | 0x80。将 x 的最低 8 位与 1000 0000 进行按位或操作，然后将结果存储在 buf[i] 中。这样 既可以将最高位设置为 1，同时也提取出了 x 的最低 7 位。 x \u0026gt;\u0026gt;= 7. 将 x 右移 7 位，处理下一个分组。 buf[i] = byte(x)。当 for 循环结束时，即意味着 x 的二进制表示形式最高位必然是 0。此时就不用做额外的补零操作了。 Uvarint 是 PutUvarint 的逆过程。\n需要注意的是，varint 将整数划分为 7 位一组。这意味着，对于大整数 varint 将会出现负向优化。例如对于 uint64 的最大值来说，本来只需要 8 个 byte 来表示，但在 varint 中却需要 10 个字节来表示了。（64/7 ≈ 10）\n负数的编码：zigzag 编码 看似 varint 编码已经完美无缺了，但以上忽略了一点：负数的存在。\n我们知道，在计算机中数字是用补码来表示的，而负数的补码则是将其绝对值按位取反再加 1。这就意味着一个很小的负数，它的二进制形式对应于一个非常大的整数。\n例如：对于一个 32 位的整数 -5 来说，其绝对值 5 的二进制形式是 101。 但 -5 的二进制形式却是 11111111111111111111111111111011，如果使用 varint 对其编码, 需要 5 个字节才能表示。\nGolang标准库引入了 zigzag 编码来解决这个问题，zigzag 的原理非常简单：\n对于正数 n，会将其映射为 2n。例如整数 2，经过 zigzag 编码之后变成了 4。 对于负数 -n 来说，会将其映射为 2n-1。例如负数 -3，经过 zigzag 编码之后变成了 5。 这样负数和正数在数值上完全不会冲突，正整数和负整数交错排列，这也是为什么叫做 zigzag 编码 (锯齿形编码）的原因。\n同时，负数被转换成正数之后，二进制编码也精简了许多。\n例如： 对 int32(-5) 进行 zigzag 编码后，变成了 9，对应于二进制为 00000000000000000000000000001001，使用 1 个字节即可表示 varint。\n我们看下 Golang 标准库的实现，代码如下：\n1 2 3 4 5 6 7 func PutVarint(buf []byte, x int64) int { ux := uint64(x) \u0026lt;\u0026lt; 1 if x \u0026lt; 0 { ux = ^ux } return PutUvarint(buf, ux) } 从代码可以看出，对于有符号整数的varint实现，golang标准库这里分成了两步：\n先对整数进行 zigzag 编码进行转换 对转换之后的数值再进行 varint 编码\n对于负数，多了一步 ux = ^ux ，这就有些难以理解了，为什么这么转换之后就等于2n - 1了？ 我们可以大概推导下整个过程，假设我们有个整数 -n：\n对原数值先左移，再进行取反。其实可以看做：对原数值先取反，再左移，然后+1。 即 2*(~(-n))+1 我们知道负数的补码=绝对值按位取反+1，那如何根据补码再推导出绝对值？这里有个公式是：|A| = ~A+1 我们将这个公式带到第一步的式子里面： 2*(n-1) + 1 = 2n - 1。这就完美对应上了负数的 ZigZag 编码 (数学多么美妙)。 在 Golang 标准库里面，调用 PutUvarint 时只会使用 varint 编码，调用 PutVarint 会先进行 zigzag 编码，再进行 varint 编码。\n而在 protobuf 中，如果类型是 int32、int64、uint32、uint64，只会使用 varint 编码。使用 sint32、sint64 将先进行 zigzag 编码，再进行 varint 编码\nVarint 不适用的情况 虽然 varint 编码设计非常精妙，但并不适用于所有的场景：\n大整数：对于非常大的整数，varint 编码可能会比固定长度的编码更消耗空间。例如当所有的整数值域大于 2^63，那使用 varint 会用到 10 字节。相比于传统的八字节整数，反而多用了 25% 的空间 需要快速随机访问的数据：由于 varint 是变长编码，所以我们无法直接通过索引来访问特定的整数，必须从头开始解码，直到找到我们需要的整数。这使得 varint 编码不适合用于需要快速随机访问的数据。 需要频繁进行数学运算的数据：由于 varint 编码的数据需要先解码才能进行数学运算，所以如果一个应用需要频繁地对数据进行数学运算，那么使用 varint 编码可能会导致性能下降。 安全敏感的应用：varint 编码的数据可能会暴露出一些关于原始整数的信息，例如它的大小。在某些安全敏感的应用中，这可能是不可接受的。 ","date":"2024-09-06T15:33:15+08:00","permalink":"https://huizhou92.com/zh-cn/p/%E8%A7%A3%E6%9E%90go-varint-%E7%9A%84%E4%BD%BF%E7%94%A8%E4%B8%8E%E5%AE%9E%E7%8E%B0%E5%8E%9F%E7%90%86/","title":"解析Go: varint 的使用与实现原理"},{"content":"注意这是一篇旧文章，Golang可能会取消runtime.SetFinalizer，使用runtime.AddCleanup 替代。它解决了 runtime.SetFinalizer 一些痛点。具体内容可以参考我这篇文章\n如果我们希望在一个对象被gc之前，做一些资源释放的工作，我们可以使用 runtime.SetFinalizer。就像函数返回之前执行defer释放资源一样。比如下面的代码:\nThis article was first published in the Medium MPP plan. If you are a Medium user, please follow me on Medium. Thank you very much.\nList1: example By runtime.SetFinalizer\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 type MyStruct struct { Name string Other *MyStruct } func main() { x := MyStruct{Name: \u0026#34;X\u0026#34;} runtime.SetFinalizer(\u0026amp;x, func(x *MyStruct) { fmt.Printf(\u0026#34;Finalizer for %s is called\\n\u0026#34;, x.Name) }) runtime.GC() time.Sleep(1 * time.Second) runtime.GC() } 官方文档中对SetFinalizer的一些解释，主要含义是对象可以关联一个SetFinalizer函数， 当GC检测到unreachable对象有关联的SetFinalizer函数时，会执行关联的SetFinalizer函数， 同时取消关联。 这样当下一次GC的时候，对象重新处于unreachable状态并且没有SetFinalizer关联， 就会被回收。\n仔细看文档，还有几个需要注意的点：\n即使程序正常结束或者发生错误， 但是在对象被 gc 选中并被回收之前，SetFinalizer 都不会执行， 所以不要在SetFinalizer中执行将内存中的内容flush到磁盘这种操作。 SetFinalizer 最大的问题是延长了对象生命周期。在第一次回收时执行 Finalizer 函数，且目标对象重新变成可达状态，直到第二次才真正 “销毁”。这对于有大量对象分配的高并发算法，可能会造成很大麻烦 指针构成的 \u0026ldquo;循环引⽤\u0026rdquo; 加上 runtime.SetFinalizer 会导致内存泄露。 list 2： runtime.SetFinalizer memory leak\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 // MyStruct 是一个简单的结构体，包含一个指针字段。 type MyStruct struct { Name string Other *MyStruct } func main() { x := MyStruct{Name: \u0026#34;X\u0026#34;} y := MyStruct{Name: \u0026#34;Y\u0026#34;} x.Other = \u0026amp;y y.Other = \u0026amp;x runtime.SetFinalizer(\u0026amp;x, func(x *MyStruct) { fmt.Printf(\u0026#34;Finalizer for %s is called\\n\u0026#34;, x.Name) }) time.Sleep(time.Second) runtime.GC() time.Sleep(time.Second) runtime.GC() } x 永远不会被释放。正确的做法应该是， 在不需要使用 对象的时候，显式移除 Finalizer runtime.SetFinalizer(\u0026amp;x, nil)\n实际应用 在业务代码中很少使用runtime.SetFinalizer （我没使用过）但是再Go源码中 有比较多的使用， 比如\nnet/http\n1 2 3 4 5 6 7 8 9 10 11 12 13 func (fd *netFD) setAddr(laddr, raddr Addr) { fd.laddr = laddr fd.raddr = raddr runtime.SetFinalizer(fd, (*netFD).Close) } func (fd *netFD) Close() error { if fd.fakeNetFD != nil { return fd.fakeNetFD.Close() } runtime.SetFinalizer(fd, nil) return fd.pfd.Close() } go-cache库提供了SetFinalizer的一种用法。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 func New(defaultExpiration, cleanupInterval time.Duration) *Cache { items := make(map[string]Item) return newCacheWithJanitor(defaultExpiration, cleanupInterval, items) } func newCacheWithJanitor(de time.Duration, ci time.Duration, m map[string]Item) *Cache { c := newCache(de, m) C := \u0026amp;Cache{c} if ci \u0026gt; 0 { runJanitor(c, ci) runtime.SetFinalizer(C, stopJanitor) } return C } func runJanitor(c *cache, ci time.Duration) { j := \u0026amp;janitor{ Interval: ci, stop: make(chan bool), } c.janitor = j go j.Run(c) } func stopJanitor(c *Cache) { c.janitor.stop \u0026lt;- true } func (j *janitor) Run(c *cache) { ticker := time.NewTicker(j.Interval) for { select { case \u0026lt;-ticker.C: c.DeleteExpired() case \u0026lt;-j.stop: ticker.Stop() return } } } newCacheWithJanitor在ci参数大于0时，将开启后台协程，通过ticker定期清理过期缓存。一旦从stop chan中读到值，则异步协程退出。\nstopJanitor为指向Cache的指针C定义了finalizer函数stopJanitor。一旦我们在业务代码中不再有指向Cache的引用时，c将会进行GC流程，首先执行stopJanitor函数，其作用是为内部的stop channel写入值，从而通知上一步的异步清理协程，使其退出。这样就实现了业务代码无感知的异步协程回收，是一种优雅的退出方式。\n本文长期链接 如果您觉得我的博客对你有帮助，请通过 RSS订阅我。 或者在X上关注我。 如果您有Medium账号，能给我个关注嘛？我的文章第一时间都会发布在Medium。 ","date":"2024-09-04T19:33:11+08:00","image":"https://images.hxzhouh.com/blog-images/2024/09/44dc3c5b905dd33169c691b6ec42b4cf.png","permalink":"https://huizhou92.com/zh-cn/p/go-runtimesetfinalizer/","title":"Go:  runtime.SetFinalizer 详解"},{"content":"不管使用什么语言，内存泄露是经常遇到的一类问题，然而使用Go语言编写内存泄露的代码却不容易，本文将列举几个可能出现内存泄露的场景，从反例中学习如何避免内存泄露。\nThis article was first published in the Medium MPP plan. If you are a Medium user, please follow me on Medium. Thank you very much.\n资源泄露 不关闭打开的文件 当你不再需要一个打开的文件,正常你需要调用它的Close方法,如果你不调用Close，就有可能文件描述符达到最大限制，无法在打开新的文件或者连接,程序会报too many open files的错误。比如下面的例子：\nCode 1: 文件没关闭导致 耗尽文件描述符。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 func main() { files := make([]*os.File, 0) for i := 0; ; i++ { file, err := os.OpenFile(\u0026#34;test.log\u0026#34;, os.O_CREATE|os.O_APPEND|os.O_WRONLY, 0644) if err != nil { fmt.Printf(\u0026#34;Error at file %d: %v\\n\u0026#34;, i, err) break } else { _, _ = file.Write([]byte(\u0026#34;Hello, World!\u0026#34;)) files = append(files, file) } } } ---- ➜ memory_leak git:(main) ✗ go run close_file.go Error at file 61437: open test.log: too many open files 在我的Mac 电脑上一个进程能打开的文件句柄数量最大是61440，也可以手动设置这个数值。go 程序会默认打开 stderr，stdout，stdin 三个文件句柄，一个进程最多能够打开61437 文件，多了就会报错。\nhttp.Response.Body.Close() Go 语言有一个 比较“知名”的bug，相信您一定看到过：如果我们忘记关闭 http 请求的body 的话，会导致内存泄露，比如下面的代码。\nhttps://gist.github.com/hxzhouh/1e63ef82a1088ac378384e30651b20c9\ncode 2： http body 没有关闭导致内存泄露。\n1 2 3 4 5 6 7 8 9 10 11 12 13 func makeRequest() { client := \u0026amp;http.Client{} req, err := http.NewRequest(http.MethodGet, \u0026#34;http://localhost:8081\u0026#34;, nil) res, err := client.Do(req) if err != nil { fmt.Println(err) } _, err = ioutil.ReadAll(res.Body) // defer res.Body.Close() if err != nil { fmt.Println(err) } } 关于这个问题您可以参考下面的文章了解更多信息，后面如果有时间的话，我们从头梳理一下 net/http\nis resp.Body.Close() necessary if we don\u0026rsquo;t read anything from the body? https://manishrjain.com/must-close-golang-http-response 字符串/slice 导致内存泄露 虽然 Go spec 并没有说明一个字符串表达式的结果（子）字符串和原来字符串是否共享一个内存块 但编译器确实让它们共享一个内存块，而且很多标准库包的函数原型设计也默认了这一点。这是一个好的设计，它不仅节省内存，而且还减少了CPU消耗。 但是有时候它会造成暂时性的内存泄露。\nCode 3: 字符串导致内存泄露。\nhttps://gist.github.com/hxzhouh/e09587195e2d7aa2d5f6676777c6cb16\n![[Pasted image 20240925174837.png]]\n为防止createStringWithLengthOnHeap 临时性内存泄露，我们可以使用strings.Clone()\nCode 4 ： 使用strings.Clone() 避免临时内存泄露。\n1 2 3 4 5 6 func Demo1() { for i := 0; i \u0026lt; 10; i++ { s := createStringWithLengthOnHeap(1 \u0026lt;\u0026lt; 20) //1M packageStr1 = append(packageStr1, strings.Clone(s[:50])) } } 这样就不会导致临时性内存泄露了。\nGoroutine Leak Goroutine Handler 绝大部分内存泄露的原因是因为goroutine泄露，比如下面的例子，很快将会内存耗尽 而导致OOM\nCode 5: goroutine handler\n1 2 3 4 5 6 for { go func() { time.Sleep(1 * time.Hour) }() } } Channel channel 的使用错误也很容易导致 goroutine 泄露，\n对于无缓冲的channel，必须要等到生产者和消费者全部就绪后，才能往channel写数据，否则将会阻塞。下面的例子因为Example 提前退出导致协程泄露。\nCode 6: 不合理使用无缓冲channel 导致goroutine泄露\n1 2 3 4 5 6 7 8 9 10 11 12 13 func Example() { a := 1 c := make(chan error) go func() { c \u0026lt;- err return }() // Example 在这里退出，导致协程泄露。 if a \u0026gt; 0 { return } err := \u0026lt;-c } 只需要改成有缓冲的channel 就能解决这个问题 c:= make(chan error,1)\n还有一个典型的例子就是channel range 误用。\nCode 7: 不合理使用range 导致goroutine泄露\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 func main() { wg := \u0026amp;sync.WaitGroup{} c := make(chan any, 1) items := []int{1, 2, 3, 4, 5} for _, i := range items { wg.Add(1) go func() { c \u0026lt;- i }() } go func() { for data := range c { fmt.Println(data) wg.Done() } fmt.Println(\u0026#34;close\u0026#34;) }() wg.Wait() time.Sleep(1 * time.Second) } channel 可以使用 range 迭代 .但是一旦读取不到内容，range 就会等待 channel 的写入，而 range 如果正好在 goroutine 内部，这个 goroutine 就会被阻塞，造成泄露。正确的做法是: 在wg.Wait() 后面 close channel.\nruntime.SetFinalizer误用 如果两个对象都设置了 runtime.SetFinalizer 并且他们之间存在 \u0026ldquo;循环引⽤\u0026rdquo; ，那么这两个对象将会泄露，即时他们不再使用，GC 也不会回收他们。\n关于 runtime.SetFinalizer 的更多内容，可以参考我的另外一篇文章\ntime.Ticker 这是go 1.23 版本之前的问题了， 如果我们不调用ticker.Stop().go 1.23 已经不会造成泄露了 https://go.dev/doc/go1.23#timer-changes\nDefer 我们一般习惯在defer 中释放资源 defer 函数本身不会导致内存泄露。但是它的两个机制可能会导致内存临时性泄露。\n执行时间，defer 总是在函数结束的运行。如果您的函数运行时间过长，或者永远不会结束，那么您在defer 中释放的资源可能，很久都不会被释放，或者永远都不被释放。 defer 本身也需要占用内存，每个 defer 都会在内存中添加一个调用点。如果您在循环中使用defer，有可能会导致临时性的内存泄露。\nCode 8: defer 导致 内存临时泄露 1 2 3 4 5 6 7 8 9 10 11 func ReadFile(files []string) { for _, file := range files { f, err := os.Open(file) if err != nil { fmt.Println(err) return } // do something defer f.Close() } } 比如上面的代码，不仅仅可能会导致 defer 临时内存泄露，还可能会导致too many open files\n不要痴迷于使用defer 除非你觉得代码你的代码可能会panic ，否则及时关闭文件是一个更好的选择。\n总结 本文列举了几种可能会导致go 内存泄露的行为，同时 Goroutine 内存泄漏是 Go 语言最容易发生的内存泄漏情况，它通常伴随着错误地使用 goroutine 和 channel等。而 channel 的特殊用法如 select 和 range 又让 channel 阻塞变得更加隐蔽不易发现，进而增加排查内存泄漏的难度。\n遇到内存泄露问题，我们可以通过 pprof 帮助我们快速的定位问题，希望我们每个人都能写出健壮的代码。\n参考资料 https://go101.org/article/memory-leaking.html\n","date":"2024-09-04T14:39:36+08:00","permalink":"https://huizhou92.com/zh-cn/p/%E5%A6%82%E4%BD%95%E5%86%99%E5%87%BA%E5%86%85%E5%AD%98%E6%B3%84%E9%9C%B2%E7%9A%84%E7%A8%8B%E5%BA%8F/","title":"如何写出内存泄露的程序？"},{"content":" tmux 是一个终端多路复用器：它允许从单个屏幕创建、访问和控制多个终端。 tmux 可能会与屏幕分离并继续在后台运行，然后重新连接。\n第一次看到tmux 的介绍的时候，我其实没什么感觉,觉得没什么.后面用terminal多了，遇到了一些问题，尝试解决，然后我重新认真学习tmux。它改变了我电脑的习惯。\n本文将会花十分钟介绍，tmux 的基本使用场景\n什么是 Terminal Session 回忆一下，你日常工作时候使用terminal 的场景，打开一个 Iterm2 窗口，然后使用ssh 连接一台远程机器，然后进入特定目录，开始工作，完成工作后，关闭Iterm2 窗口。上面这些步骤，就是一个 terminal session 它的生命周期是跟 terminal 的生命周期绑定在一起的，关闭窗口后session就结束，然后下次我们要工作的时候，就重复上面的步骤。\n有什么办法，可以将session跟terminal 开来，下次再操作的时候，就不需要重复上面的步骤？ tmux可以帮助我们实现这个功能。\nThis article was first published in the Medium MPP plan. If you are a Medium user, please follow me on Medium. Thank you very much.\n我们看看再 tmux 下如何实现上面这个功能把。\n在这个演示中，我首先用tmux new -s test 创建了一个tmux session ，然后登录我的一台开发机器，然后再将session 剥离，回到Iterm2 终端，最后我又使用 tmux attach-session 回到原来的开发机器，跟刚才退出去的时候一模一样。 这就是 tmux 基础的应用了，剥离session，并且保持session 状态。\nTL;DR tmux 可以帮助我们实现：\n它允许在单个窗口中，同时访问多个会话。这对于同时运行多个命令行程序很有用。 它可以让新窗口\u0026quot;接入\u0026quot;已经存在的会话。 它允许每个会话有多个连接窗口，因此可以多人实时共享会话。 它还支持窗口任意的垂直和水平拆分。 Tmux 基本用法 安装 Tmux 在Mac上，可以使用brew 来安装 tmux\n1 brew install tmux 其他环境请参考:Installing tmux\n启动tmux 与退出 Tmux 安装完成后， 在 terminal中输入 tmux 就可以启动一个 tmux session 。输入exit 就会退出 tmux session ，返回到原来的 terminal 页面。\n前缀键 跟其他软件不一样的是: tmux 中所有的快捷键都需要和前缀快捷键 ⌃b 来组合使用（注：⌃ 为 Mac 的 control 键),这样其实挺好的，减少了与其他软件冲突的概率。可以通过 ⌃b+? 来查询所有的快捷键。一般把tmux 的快捷键分成三类:窗口管理、窗格管理、以及session 管理。\nSession 管理 如果运行了多次 tmux 命令则会开启多个 tmux 会话（session）。在 tmux 会话中，使用前缀快捷键 ⌃b 配合以下快捷键可操作会话：\n⌃b + $ 重命名当前会话 ⌃b + s 选择会话列表 ⌃b + d detach 当前会话，运行后将会退出 tmux 进程，返回至 terminal 主页面。\n在 terminal 中，可以这样操作 session tmux new -s foo # 新建名称为 foo 的会话 tmux ls # 列出所有 tmux 会话 tmux a # 恢复至上一次的会话 tmux a -t foo # 恢复名称为 foo 的会话，会话默认名称为数字 tmux kill-session -t foo # 删除名称为 foo 的会话 tmux kill-server # 删除所有的会话\n配合 alias 会得到更好的体验，比如我自己的配置 1 2 3 4 5 alias tnew=\u0026#39;tmux new -s\u0026#39; # 新建一个会话 alias tls=\u0026#39;tmux ls\u0026#39; alias td=\u0026#39;tmux detach\u0026#39; # 分离 会话，会保存分离之前的状态 alias ta=\u0026#39;tmux attach -t\u0026#39; # 连接会话 alias tkss=\u0026#39;tmux kill-session -t\u0026#39; 窗格管理 Tmux 可以将窗口分成多个窗格（pane），每个窗格运行不同的命令。以下命令都是在 Tmux 窗口中执行。\n⌃b + % 左右平分出两个窗格 ⌃b + \u0026quot; 上下平分出两个窗格 ⌃b + x 关闭当前窗格 ⌃b + { 当前窗格前移 ⌃b + } 当前窗格后移 ⌃b + ; 选择上次使用的窗格 ⌃b + o 选择下一个窗格，也可以使用上下左右方向键来选择 ⌃b + space 切换窗格布局，tmux 内置了五种窗格布局，也可以通过 ⌥1 至 ⌥5来切换 ⌃b + z 最大化当前窗格，再次执行可恢复原来大小 ⌃b + q 显示所有窗格的序号，在序号出现期间按下对应的数字，即可跳转至对应的窗格 窗口管理 tmux 还有窗口（window） 的概念，当窗格变得拥挤的时候，我们可以再开一个窗口，下面是窗口一些常用的快捷键。\n⌃b + c 新建窗口，此时当前窗口会切换至新窗口，不影响原有窗口的状态 ⌃b + p 切换至上一窗口 ⌃b + n 切换至下一窗口 ⌃b + w 窗口列表选择，注意 macOS 下使用 ⌃p 和 ⌃n 进行上下选择 ⌃b + \u0026amp; 关闭当前窗口 ⌃b + , 重命名窗口，可以使用中文，重命名后能在 tmux 状态栏更快速的识别窗口 id ⌃b + 0 切换至 0 号窗口，使用其他数字 id 切换至对应窗口。 ⌃b + f 根据窗口名搜索选择窗口，可模糊匹配。 总结 这篇文章只是总结了一下tmux 的基本使用以及快捷键，还有很多应用场景没有涉及。比如跟vim 配合如何更加高效的在 vim中写代码。希望看过这篇文章的朋友，能够上手体验一下tmux， 使用tmux 生产力。\n","date":"2024-08-15T18:56:30+08:00","image":"https://images.hxzhouh.com/blog-images/2024/08/d46c392343d2c463c4744cc2259b42a7.png","permalink":"https://huizhou92.com/zh-cn/p/mac-tmux-%E6%9C%80%E4%BD%B3%E5%AE%9E%E8%B7%B5/","title":"Mac: tmux 最佳实践"},{"content":"RPC是远程过程调用的简称，是分布式系统中不同节点间流行的通信方式。是互联网时代的基石技术，Go语言的标准库也提供了一个简单的RPC实现，Go语言的RPC包的路径为net/rpc，本篇文章的目的是利用net/rpc 实现一个简单的RPC 接口，帮助我们拨开RPC 的迷雾。\n对 net/rpc 而言，一个函数需要能够被远程调用，需要满足如下五个条件：\nthe method’s type is exported. the method is exported. the method has two arguments, both exported (or builtin) types. the method’s second argument is a pointer. the method has return type error. 也就是说，必须满足。\n1 func (t *T) MethodName(argType T1, replyType *T2) error 简单的RPC请求 基于这五点要求，我们可以构建一个简单的RPC接口\n1 2 3 4 5 6 type HelloService struct{} func (p *HelloService) Hello(request string, reply *string) error { log.Println(\u0026#34;HelloService Hello\u0026#34;) *reply = \u0026#34;hello:\u0026#34; + request return nil } 然后就可以将HelloService类型的对象注册为一个RPC服务。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 func main() { _ = rpc.RegisterName(\u0026#34;HelloService\u0026#34;, new(HelloService)) listener, err := net.Listen(\u0026#34;tcp\u0026#34;, \u0026#34;:1234\u0026#34;) if err != nil { log.Fatal(\u0026#34;ListenTCP error:\u0026#34;, err) } for { conn, err := listener.Accept() if err != nil { log.Fatal(\u0026#34;Accept error:\u0026#34;, err) } go rpc.ServeConn(conn) } } 客户端的实现如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 func main() { conn, err := net.Dial(\u0026#34;tcp\u0026#34;, \u0026#34;:1234\u0026#34;) if err != nil { log.Fatal(\u0026#34;net.Dial:\u0026#34;, err) } client := rpc.NewClient(conn) var reply string err = client.Call(\u0026#34;HelloService.Hello\u0026#34;, \u0026#34;hello\u0026#34;, \u0026amp;reply) if err != nil { log.Fatal(err) } fmt.Println(reply) } 首先是通过rpc.Dial Dail a RPC服务，然后再通过client.Call()调用具体的RPC方法。第一个参数是用点号链接的RPC服务名字和方法名字，第二个参数是入参，第三个为返回值，是一个指针。\n由这个例子可以看出RPC的使用其实非常简单。\n在 Server 与Client 的代码中，我们都需要去记忆 RPC 服务的名字HelloService 以及，接口名字Hello。这在开发过程中，很容易出错，我们可以稍微封装一下。将公共的部分抽出来，完整的代码如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 // server.go const ServerName = \u0026#34;HelloService\u0026#34; type HelloServiceInterface = interface { Hello(request string, reply *string) error } func RegisterHelloService(srv HelloServiceInterface) error { return rpc.RegisterName(ServerName, srv) } type HelloService struct{} func (p *HelloService) Hello(request string, reply *string) error { log.Println(\u0026#34;HelloService Hello\u0026#34;) *reply = \u0026#34;hello:\u0026#34; + request return nil } func main() { _ = RegisterHelloService(new(HelloService)) listener, err := net.Listen(\u0026#34;tcp\u0026#34;, \u0026#34;:1234\u0026#34;) if err != nil { log.Fatal(\u0026#34;ListenTCP error:\u0026#34;, err) } for { conn, err := listener.Accept() if err != nil { log.Fatal(\u0026#34;Accept error:\u0026#34;, err) } go rpc.ServeConn(conn) } } 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 // client.go type HelloServiceClient struct { *rpc.Client } var _ HelloServiceInterface = (*HelloServiceClient)(nil) const ServerName = \u0026#34;HelloService\u0026#34; func DialHelloService(network, address string) (*HelloServiceClient, error) { conn, err := net.Dial(network, address) client := rpc.NewClient(conn) if err != nil { return nil, err } return \u0026amp;HelloServiceClient{Client: client}, nil } func (p *HelloServiceClient) Hello(request string, reply *string) error { return p.Client.Call(ServerName+\u0026#34;.Hello\u0026#34;, request, reply) } func main() { client, err := DialHelloService(\u0026#34;tcp\u0026#34;, \u0026#34;localhost:1234\u0026#34;) if err != nil { log.Fatal(\u0026#34;net.Dial:\u0026#34;, err) } var reply string err = client.Hello(\u0026#34;hello\u0026#34;, \u0026amp;reply) if err != nil { log.Fatal(err) } fmt.Println(reply) } 是不是已经有点眼熟了？\ncodec 标准库的RPC默认采用Go语言特有的Gob编码，但是我们很容易在上面实现其他编码，比如Protobuf，JSON 等。标准库中已经支持了jsonrpc编码，我们只需要稍微改动一下服务端与客户端代码，就能实现JSON编码\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 // server.go func main() { _ = rpc.RegisterName(\u0026#34;HelloService\u0026#34;, new(HelloService)) listener, err := net.Listen(\u0026#34;tcp\u0026#34;, \u0026#34;:1234\u0026#34;) if err != nil { log.Fatal(\u0026#34;ListenTCP error:\u0026#34;, err) } for { conn, err := listener.Accept() if err != nil { log.Fatal(\u0026#34;Accept error:\u0026#34;, err) } go rpc.ServeCodec(jsonrpc.NewServerCodec(conn)) //go rpc.ServeConn(conn) } } //client.go func DialHelloService(network, address string) (*HelloServiceClient, error) { conn, err := net.Dial(network, address) //client := rpc.NewClient(conn) client := rpc.NewClientWithCodec(jsonrpc.NewClientCodec(conn)) if err != nil { return nil, err } return \u0026amp;HelloServiceClient{Client: client}, nil } 请求的JSON数据对象在内部对应两个结构体：客户端是clientRequest，服务器端是 serverRequest 。clientRequest和serverRequest结构体的内容基本是一致的：\n1 2 3 4 5 6 7 8 9 10 type clientRequest struct { Method string `json:\u0026#34;method\u0026#34;` Params [1]any `json:\u0026#34;params\u0026#34;` Id uint64 `json:\u0026#34;id\u0026#34;` } type serverRequest struct { Method string `json:\u0026#34;method\u0026#34;` Params *json.RawMessage `json:\u0026#34;params\u0026#34;` Id *json.RawMessage `json:\u0026#34;id\u0026#34;` } 其中，Method 表示服务名字，它是 serviceName +Method 组成。 params部分的第一个元素为参数，id是由调用方维护的唯一的调用编号。用于在并发场场景下区分请求。\n我们可以用nc 来模拟服务端，然后运行客户端代码，看看使用json编码的客户端会给服务端发送什么信息，\n1 nc -l 1234 nc 收到的数据为：\n1 {\u0026#34;method\u0026#34;:\u0026#34;HelloService.Hello\u0026#34;,\u0026#34;params\u0026#34;:[\u0026#34;hello\u0026#34;],\u0026#34;id\u0026#34;:0} 跟 serverRequest 一致。\n我们也可以运行 服务端代码，然后使用 nc 发送请求。\n1 2 3 echo -e \u0026#39;{\u0026#34;method\u0026#34;:\u0026#34;HelloService.Hello\u0026#34;,\u0026#34;params\u0026#34;:[\u0026#34;Hello\u0026#34;],\u0026#34;Id\u0026#34;:1}\u0026#39; | nc localhost 1234 --- {\u0026#34;id\u0026#34;:1,\u0026#34;result\u0026#34;:\u0026#34;hello:Hello\u0026#34;,\u0026#34;error\u0026#34;:null} 总结 本文介绍了 Go 标准库中的rpc，它使用非常简单，性能异常强大。很多rpc的第三方库都是对rpc的封装。文章很简单，等于是给RPC研究系列开了一个头。下一篇文章，我们会将protobuf 跟RPC结合起来，最终，我们会实现一个自己的RPC框架。\n","date":"2024-08-13T18:24:42+08:00","image":"https://images.hxzhouh.com/blog-images/2024/08/d4dddb722300af56ecbb03cefdf1aec1.png","permalink":"https://huizhou92.com/zh-cn/p/%E8%AE%A4%E8%AF%86rpc/","title":"认识RPC"},{"content":"在上一篇文章中，我用net/rpc 包实现了一个简单的 RPC接口，并且尝试了net/rpc自带的Gob编码以及JSON编码，学习了Golang RPC 的一些基本知识。本篇文章，我会将net/rpc 跟 protobuf结合起来，然后在了解一下如何使用Protobuf + 插件 生成 gRPC 的代码。 最后会尝试创建一个自己的protobuf插件来帮助我们生成代码，开始吧。\nThis article was first published in the Medium MPP plan. If you are a Medium user, please follow me on Medium. Thank you very much.\n我们在工作过程中一定使用过gRPC + protobuf ,但是它们两个并不是绑定关系，gRPC可以使用JSON编码，protobuf也可以在其他语言中实现。\nProtocol Buffers 是谷歌推出的编码标准，它在传输效率和编解码性能上都要优于 JSON。但其代价则是需要依赖中间描述语言（IDL）来定义数据和服务的结构（ *.proto 文件），并且需要一整套的工具链（protoc 及其插件）来生成对应的序列化和反序列化代码。\n除了谷歌官方提供的工具和插件（比如生成 go 代码的 protoc-gen-go）外，我们还可以开发或定制自己的插件，根据业务需要按照 proto 文件的定义生成代码或者文档。由 IDL 生成代码或者文档是元编程的一种形式，可以极大的解放程序员的生产力。\n一个使用protobuf 的例子 首先我们写一个proto 文件 hello-service.proto，定义一个message “String“\n1 2 3 4 5 6 7 syntax = \u0026#34;proto3\u0026#34;; package api; option go_package=\u0026#34;api\u0026#34;; message String { string value = 1; } 然后使用protoc 工具生成message String 的 Go代码\n1 protoc --go_out=./api proto/hello.proto 生成的代码 里面有一个 String struct\n1 2 3 4 5 6 type String struct { Value string `protobuf:\u0026#34;bytes,1,opt,name=value,proto3\u0026#34; json:\u0026#34;value,omitempty\u0026#34;` XXX_NoUnkeyedLiteral struct{} `json:\u0026#34;-\u0026#34;` XXX_unrecognized []byte `json:\u0026#34;-\u0026#34;` XXX_sizecache int32 `json:\u0026#34;-\u0026#34;` } 我们可以直接使用它，修改一下函数的参数。\n1 2 3 type HelloServiceInterface = interface { Hello(request api.String, reply *api.String) error } 其实使用起来跟以前没什么区别。甚至还不如直接使用string方便。\n那么我们为什么要使用Protobuf?\n正如前面所说的，用Protobuf定义与语言无关的RPC服务接口以及message，然后使用protoc工具生成不同语言的代码，才是它真正的价值所在。\nprotoc 的插件系统 protobuf是一个与编程语言无关的协议。它通过protoc跟各种不同的插件来将protobuf文件编译成不同的编程语言，我们以Golang+gRPC 为例子。\n1 protoc --go_out=plugins=grpc. hello-service.proto 这里有一个 --go_out 参数。因为我们调用的插件是protoc-gen-go，所以参数名字叫 go_out；如果名字叫 XXX，那参数名字就叫 XXX_out。\nprotoc 在运行的时候首先会解析 proto 文件的所有内容，生成一组 Protocol Buffers 编码的描述数据，首先会判断protoc 内部是否包含go插件, 然后会尝试在$PATH 里面寻找protoc-gen-go，找不到会报错，然后运行protoc-gen-go 命令，并且通过 stdin 将描述数据发送给插件命令。插件生成好文件内容后再向 stdout 输入 Protocol Buffers 编码的数据来告诉 protoc 生成具体的文件。\nplugins=grpc 是 为了调用protoc-gen-go 自带的一个插件，如果不使用它，那么只会生成 Go 语言 的message信息，使用这个插件才会生成grpc 相关的代码。\n自定义一个 protoc 插件 如果在protobuf 中添加Hello 接口的定时，我们是不是可以自定义一个 protoc 插件，直接生成代码？\n1 2 3 4 5 6 7 8 9 syntax = \u0026#34;proto3\u0026#34;; package api; option go_package=\u0026#34;./api\u0026#34;; service HelloService { rpc Hello (String) returns (String) {} } message String { string value = 1; } 目标 这篇文章，我的目标是创建一个插件，然后用来生成RPC 的服务端与客户端代码，生成的代码大致是这样的。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 // HelloService_rpc.pb.go type HelloServiceInterface interface { Hello(String, *String) error } func RegisterHelloService( srv *rpc.Server, x HelloServiceInterface, ) error { if err := srv.RegisterName(\u0026#34;HelloService\u0026#34;, x); err != nil { return err } return nil } type HelloServiceClient struct { *rpc.Client } var _ HelloServiceInterface = (*HelloServiceClient)(nil) func DialHelloService(network, address string) ( *HelloServiceClient, error, ) { c, err := rpc.Dial(network, address) if err != nil { return nil, err } return \u0026amp;HelloServiceClient{Client: c}, nil } func (p *HelloServiceClient) Hello( in String, out *String, ) error { return p.Client.Call(\u0026#34;HelloService.Hello\u0026#34;, in, out) } 这样我们的业务代码就能改成下面这个样子。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 // service func main() { listener, err := net.Listen(\u0026#34;tcp\u0026#34;, \u0026#34;:1234\u0026#34;) if err != nil { log.Fatal(\u0026#34;ListenTCP error:\u0026#34;, err) } _ = api.RegisterHelloService(rpc.DefaultServer, new(HelloService)) for { conn, err := listener.Accept() if err != nil { log.Fatal(\u0026#34;Accept error:\u0026#34;, err) } go rpc.ServeConn(conn) } } type HelloService struct{} func (p *HelloService) Hello(request api.String, reply *api.String) error { log.Println(\u0026#34;HelloService.proto Hello\u0026#34;) *reply = api.String{Value: \u0026#34;Hello:\u0026#34; + request.Value} return nil } // client.go func main() { client, err := api.DialHelloService(\u0026#34;tcp\u0026#34;, \u0026#34;localhost:1234\u0026#34;) if err != nil { log.Fatal(\u0026#34;net.Dial:\u0026#34;, err) } reply := \u0026amp;api.String{} err = client.Hello(api.String{Value: \u0026#34;Hello\u0026#34;}, reply) if err != nil { log.Fatal(err) } log.Println(reply) } 基于生成的代码，我们的工作量已经小了很多，并且出错的几率已经很小了。一个不错的开始。\n根据上面的api代码，我们可以抽出来一个模板文件：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 const tmplService = ` package {{.PackageName}} import ( \u0026#34;net/rpc\u0026#34;) {{$root := .}} type {{.ServiceName}}Interface interface { {{- range $_, $m := .MethodList}} {{$m.MethodName}}({{$m.InputTypeName}}, *{{$m.OutputTypeName}}) error {{- end}}} func Register{{.ServiceName}}( srv *rpc.Server, x {{.ServiceName}}Interface,) error { if err := srv.RegisterName(\u0026#34;{{.ServiceName}}\u0026#34;, x); err != nil { return err } return nil} type {{.ServiceName}}Client struct { *rpc.Client} var _ {{.ServiceName}}Interface = (*{{.ServiceName}}Client)(nil) func Dial{{.ServiceName}}(network, address string) ( *{{.ServiceName}}Client, error,) { c, err := rpc.Dial(network, address) if err != nil { return nil, err } return \u0026amp;{{.ServiceName}}Client{Client: c}, nil} {{range $_, $m := .MethodList}} func (p *{{$root.ServiceName}}Client) {{$m.MethodName}}( in {{$m.InputTypeName}}, out *{{$m.OutputTypeName}},) error { return p.Client.Call(\u0026#34;{{$root.ServiceName}}.{{$m.MethodName}}\u0026#34;, in, out)} {{end}} ` 整个模板很清晰，里面有一些占位符，比如 MethodName，ServiceName 等，我们后面会介绍。\n如何开发 一个插件？ 谷歌发布了 Go 语言 API1，其中引入了一个新包 google.golang.org/protobuf/compiler/protogen ，极大的降低了plugins 开发难度：\n首先我们创建一个go 语言工程，比如protoc-gen-go-spprpc 然后我们需要定义一个protogen.Options，然后调用它的Run方法，并传入一个 func(*protogen.Plugin) error回调。主流程代码到此就结束了。 我们还可以设置protogen.Options的ParamFunc参数，这样 protogen 会自动为我们解析命令行传入的参数。诸如从标准输入读取并解码 protobuf 信息，将输入信息编码成 protobuf 写入 stdout 等操作全部由 protogen 包办了。我们要做的就是与 protogen.Plugin 交互实现代码生成逻辑。 每个服务最重要的是服务的名字，然后每个服务有一组方法。而对于服务定义的方法，最重要的是方法的名字，还有输入参数和输出参数类型的名字。我们首先定义一个ServiceData，用于描述服务的元信息：\n1 2 3 4 5 6 7 8 9 10 11 12 // ServiceData 结构体定义 type ServiceData struct { PackageName string ServiceName string MethodList []Method } // Method 结构体定义 type Method struct { MethodName string InputTypeName string OutputTypeName string } 然后就是主逻辑，以及代码生成逻辑，最后调用tmpl生成代码。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 func main() { protogen.Options{}.Run(func(gen *protogen.Plugin) error { for _, file := range gen.Files { if !file.Generate { continue } generateFile(gen, file) } return nil }) } // generateFile 函数定义 func generateFile(gen *protogen.Plugin, file *protogen.File) { filename := file.GeneratedFilenamePrefix + \u0026#34;_rpc.pb.go\u0026#34; g := gen.NewGeneratedFile(filename, file.GoImportPath) tmpl, err := template.New(\u0026#34;service\u0026#34;).Parse(tmplService) if err != nil { log.Fatalf(\u0026#34;Error parsing template: %v\u0026#34;, err) } packageName := string(file.GoPackageName) // 遍历每个服务生成代码 for _, service := range file.Services { serviceData := ServiceData{ ServiceName: service.GoName, PackageName: packageName, } for _, method := range service.Methods { inputType := method.Input.GoIdent.GoName outputType := method.Output.GoIdent.GoName serviceData.MethodList = append(serviceData.MethodList, Method{ MethodName: method.GoName, InputTypeName: inputType, OutputTypeName: outputType, }) } // 执行模板渲染 err = tmpl.Execute(g, serviceData) if err != nil { log.Fatalf(\u0026#34;Error executing template: %v\u0026#34;, err) } } } 调试插件 最后我们将编译后的 二进制执行文件protoc-gen-go-spprpc，放在$PATH 里面， 然后运行protoc 就能生成我们想要的代码了。\n1 protoc --go_out=.. --go-spprpc_out=.. HelloService.proto 因为protoc-gen-go-spprpc 必须依赖 protoc 才能运行，所以调试起来比较麻烦。我们可以使用\nfmt.Fprintf(os.Stderr, \u0026quot;Fprintln: %v\\n\u0026quot;, err) 打印错误日志的方式调试。\n总结 以上就是本文的全部内容了。我们首先使用protobuf 实现了一个rpc call，然后创建了一个protobuf 插件来帮助我们生成代码。为我们打开了一扇学习protobuf + RPC 的大门，也是我们通往彻底理解gRPC的路。希望大家都能掌握这个技术。\n参考文档 https://taoshu.in/go/create-protoc-plugin.html https://chai2010.cn/advanced-go-programming-book/ch4-rpc/ch4-02-pb-intro.html ","date":"2024-08-13T16:10:53+08:00","permalink":"https://huizhou92.com/zh-cn/p/rpc%E5%AE%9E%E8%B7%B5-ep2-protobuf%E4%B8%8E-%E5%AE%83%E7%9A%84%E6%8F%92%E4%BB%B6%E7%B3%BB%E7%BB%9F/","title":"RPC实践 EP2: Protobuf与 它的插件系统。"},{"content":"从Go 编译器的角度来看，内存会被分配到两个地方: stack 和 heap。对于业务开发人员来说，这两种方式，没什么区别，通常开发者并不需要关心内存分配在栈上，还是堆上，因为这都是编译器自动完成的。但是从性能的角度出发，在栈上分配内存和在堆上分配内存，性能差异是非常大的。在函数中申请一个对象，如果分配在栈中，函数执行结束时自动回收。如果分配在堆中，则是由GC算法在某个时间点进行垃圾回收，其中的原理比较复杂。总之，分配堆内存比栈内存需要更多的开销，这种将内存分配到堆的现象就是内存逃逸。我们在写代码的时候，应当尽量避免堆内存分配。\n为什么会有内存逃逸？ 原因其实很简单，编译器无法确定变量的生存周期，或者栈空间放不下那么大的内存。Go 编译器怎么知道某个变量需要分配在栈上，还是堆上呢？编译器决定内存分配位置的方式，就称之为逃逸分析(escape analysis)。逃逸分析由编译器完成，作用于编译阶段。可以用 -gcflags=-m 来观察变量是否逃逸。\n内存逃逸对性能的影响 可以做一个很简单的benchmark测试, BenchmarkInt 是一个指针数组，\u0026amp;j 会产生内存逃逸， BenchmarkInt2 则不会产生 内存逃逸。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 func BenchmarkInt(b *testing.B) { for i := 0; i \u0026lt; b.N; i++ { a := make([]*int, 100) for j := 0; j \u0026lt; 100; j++ { a[j] = \u0026amp;j } } } func BenchmarkInt2(b *testing.B) { for i := 0; i \u0026lt; b.N; i++ { a := make([]int, 100) for j := 0; j \u0026lt; 100; j++ { a[j] = j } } } 运行结果是：\nBenchmarkInt2 的比BenchmarkInt 快30倍，并且没有一次内存分配，BenchmarkInt 则有101次内存分配。 从这个测试我们就知道为什么有必要进行内存逃逸分析了。\n内存逃逸的典型场景 变量逃逸 \u0026amp; 指针逃逸 当一个变量的生命周期超出函数范围时，编译器会将其分配到堆上，我们叫这种现象为内存变量逃逸，或者指针逃逸。\n1 2 3 4 5 6 7 8 9 10 11 12 13 package main import \u0026#34;fmt\u0026#34; func main() { s := makeString() fmt.Println(s) } func makeString() *string { str := \u0026#34;Hello, World!\u0026#34; return \u0026amp;str } 栈溢出 操作系统对内核线程使用的栈空间是有大小限制的，在64位操作系统上面，这个大小通常是8 MB。可以使用 ulimit -a 命令查看计算机允许的最大的栈内存大小。Go runtime 在 goroutine 需要的时候动态地分配栈空间，goroutine 的初始栈大小为 2 KB。当 goroutine 被调度时，会绑定内核线程执行，栈空间大小也不会超过操作系统的限制。对于go 的编译器来说，超过一定大小的局部变量将逃逸到堆上，一般是64KB。比如这段代码尝试创建一个占用 8193 字节的数组： 8192 * 8 / 1024 = 64k\n1 2 3 4 5 6 func main() { a := make([]int64, 8176) b := make([]int64, 8192) c := make([]int64, 8193) println(a, b, c) } 当数组大于 8192 的时候就逃逸到了堆上。\n不确定大小的变量 1 2 3 4 5 6 7 func main() { a := generate(3) println(a) } func generate(n int) []int { return make([]int, n) } generate 的参数是在运行时传入的，所以编译器不能确定他的大小， 逃逸到堆上，\ninterface{} 动态类型逃逸 在Go语言中，空接口即 interface{} 可以表示任意的类型，如果函数参数为 interface{}，编译期间很难确定其参数的具体类型，也会发生逃逸。\n比如：\n1 2 3 4 func main() { v := \u0026#34;Hello,World\u0026#34; fmt.Printf(\u0026#34;addr of v in bar = %p\\n\u0026#34;, \u0026amp;v) } 运行结果是：\n因为 fmt.Println 的参数是一个any（也就是interface{}) 所以v会发生逃逸\n闭包 Closure 比如下面的例子\n1 2 3 4 5 6 7 8 9 10 11 12 13 func Increase() func() int { n := 0 return func() int { n++ return n } } func main() { in := Increase() fmt.Println(in()) // 1 fmt.Println(in()) // 2 } Increase() 返回值是一个闭包函数，该闭包函数访问了外部变量 n，那变量 n 将会一直存在，直到 in 被销毁。很显然，变量 n 占用的内存不能随着函数 Increase() 的退出而回收，因此将会逃逸到堆上。\n手动强制避免逃逸 在 interface{} 动态类型逃逸 的例子中， 我们就是打印了一个\u0026quot;Hello,World\u0026quot;，但是还是产生了内存逃逸，我们可以确定的一点是：v 不需要逃逸，但若使用fmt.Printf，我们无法阻拦a的逃逸。那是否有一种方法可以干扰逃逸分析，使逃逸分析认为需要在堆上分配的内存对象而我们确定认为不需要逃逸的对象避免逃逸呢？在Go runtime代码中，我们发现了一个函数：\n1 2 3 4 5 // $GOROOT/src/runtime/stubs.go func noescape(p unsafe.Pointer) unsafe.Pointer { x := uintptr(p) return unsafe.Pointer(x ^ 0) } 在Go标准库和rruntime实现中，该函数得到大量使用。该函数的实现逻辑使得我们传入的指针值与其返回的指针值是一样的。该函数只是通过uintptr做了一次转换，而这次转换将指针转换成了数值，这“切断”了逃逸分析的数据流跟踪，导致传入的指针避免逃逸。\n我们改一下上面的例子\n1 2 3 4 5 6 7 8 9 10 11 func noescape(p unsafe.Pointer) unsafe.Pointer { x := uintptr(p) return unsafe.Pointer(x ^ 0) } func main() { v := \u0026#34;Hello,World\u0026#34; v2 := \u0026#34;Hello,World1\u0026#34; fmt.Printf(\u0026#34;addr of v in bar = %p \\n\u0026#34;, (*int)(noescape(unsafe.Pointer(\u0026amp;v)))) fmt.Printf(\u0026#34;addr of v in bar = %p\\n\u0026#34;, \u0026amp;v2) } 运行结果如图所示，v 没有发生内存逃逸，v2有内存逃逸。\n总结 在一般的开发过程中，我们一般很少会涉及内存逃逸分析，根据经验来看，优化一个锁得到的性能提升，比你做十次内存逃逸分析结果还要好。在平时的开发过程中，我们只需要明白一件事就好：\n传值会拷贝整个对象，而传指针只会拷贝指针地址，指向的对象是同一个。传指针可以减少值的拷贝，但是会导致内存分配逃逸到堆中，增加垃圾回收(GC)的负担。在对象频繁创建和删除的场景下，传递指针导致的 GC 开销可能会严重影响性能。\n一般情况下，对于需要修改原对象值，或占用内存比较大的结构体，选择传指针。对于只读的占用内存较小的结构体，直接传值能够获得更好的性能。 参考资料 https://dave.cheney.net/2014/06/07/five-things-that-make-go-fast http://www.wingtecher.com/themes/WingTecherResearch/assets/papers/ICSE20.pdf https://tonybai.com/2021/05/24/understand-go-escape-analysis-by-example/ https://docs.google.com/document/d/1CxgUBPlx9iJzkz9JWkb6tIpTe5q32QDmz8l0BouG0Cw/preview# https://dave.cheney.net/2018/01/08/gos-hidden-pragmas http://www.wingtecher.com/themes/WingTecherResearch/assets/papers/ICSE20.pdf ","date":"2024-08-08T11:28:58+08:00","image":"https://images.hxzhouh.com/blog-images/2024/08/317a5c9d3df72bec002eb7c0bd64c06d.png","permalink":"https://huizhou92.com/zh-cn/p/go-%E9%AB%98%E6%80%A7%E8%83%BD%E7%BC%96%E7%A8%8B-ep9-%E9%80%83%E9%80%B8%E5%88%86%E6%9E%90/","title":"Go 高性能编程 EP9: 逃逸分析"},{"content":"\nBacklink | |Photo by Ambitious Studio* | Rick Barrett on Unsplash 原文链接：https://www.dolthub.com/blog/2023-03-28-swiss-map/\n这篇文章介绍SwissMap，这是一个基于 SwissTable 的新 Golang HashTable，比 Golang 内置的Map更快，更节约内存。我们将介绍这个新软件包的动机、设计和实现。并为您提供一些尝试它的理由。\n在 DoltHub，我们热爱 Golang，并已将其用于构建 DoltDB，这是第一个也是唯一一个可以进行分支、差异和合并的 SQL 数据库。通过构建 Dolt 的经验，我们在语言上获得了一些专业知识。我们发现了很多我们喜欢的功能，也遇到了一些比较尖锐的问题。Go 语言的一个重要的特点是简洁性。它暴露最小的接口，将复杂性藏在Runtime中（简洁不等于简单）。Golang 内置的 map 是其的一个很好的例子：内置在runtime 中，使用专门的接口进行读写。对于大多数用例，map 表现出色，但其不透明的实现使其很难扩展。在没有替代方案的情况下，我们决定自行编写HashTable。\n动机 HashTable在 Dolt的代码库中被广泛使用，但在处理数据持久性和检索的底层堆栈中尤为重要。Dolt 中负责数据持久性的抽象被称为 ChunkStore。 ChunkStore许多的实现，但它们共享一组普通的语义：使用 [20]byte 内容可寻址哈希来存储和获取名为“chunks”的可变长度字节缓冲区。Dolt 的表索引存储在Prolly Trees中，这是一种由这些可变大小块组成的基于树的数据结构。Prolly 树中的较高节点通过它们的哈希引用子节点。为了反解这个哈希地址，ChunkStore 必须使用“块索引”将哈希地址映射到磁盘上的物理位置。相比之下，传统的 B 树索引使用固定大小的数据页，父节点直接通过它们在索引文件中的物理位置引用子节点。\nDolt 中的大型 Prolly Tree 索引可以达到 4 至 5 个层级。遍历每个级别需要使用块索引来解析父节点和子节点之间的引用。为了与传统的 B 树索引竞争，块索引必须具有非常低的延迟。这个块索引的原始设计是一组静态的、排序的数组。查询索引涉及对每个数组进行二进制搜索，直到找到所需的地址为止。这种设计的好处在于它的紧凑性。块地址本身是 20 个字节，并且伴随着一个 uint64 文件偏移和一个 uint32 块长度。这种查找信息比传统的 B-Tree 索引存储的 8 字节文件偏移明显更臃肿。将查找结果存储在静态数组中最大限度地减小了块索引的内存占用。其缺点是查询索引的渐近复杂度为 m log(n)，其中 m 是数组的数量，n 是它们的平均大小。\n在设计我们的新 ChunkStore 实现 Chunk Journal 时，我们决定用HashTable替换基于数组的块索引。基于HashTable的索引将支持常数时间的哈希地址查找，从而减少 ChunkStore 的延迟。这种折衷方案是HashTable使用更多内存。实际上，使用多少内存取决于您使用的HashTable类型。我们的第一个实现使用了 Golang 的内置HashTable map，其\u0026quot;最大负载因子\u0026quot;为 6.5/8。这意味着在最佳情况下，map 使用的内存比基于数组的块索引多 23%。然而，平均情况要糟糕得多。那么，如何在不超出内存预算的情况下实现常数时间的块查找呢？这就是 SwissMap 的作用。\nSwissTable 设计 SwissMap 基于 Google 的开源 C++库 Abseil 中的\u0026quot;SwissTable\u0026quot;HashTable家族。这些HashTable被设计为 C++标准库中 std::unordered_map 的更快速、更小型的替代品。与 std::unordered_map 相比，它们具有更密集、更友好的缓存内存布局，并利用 SSE 指令加速键值查找。该设计被证明非常有效，目前已被其他语言采用。Rust 的 SwissTable 移植版 Hashbrown 已经被纳入 Rust 标准库，在 Rust 1.36 中推出。甚至在 Golang 社区内，正在进行采纳 SwissTable 设计作为运行时映射实现的努力。SwissTable 设计非常适用于我们的分块索引用例：速度快，并支持更高的最大负载因子 14/16。\n内置地图和 SwissMap 之间的主要设计差异在于它们的哈希方案。内置地图使用了一种“开放哈希”方案，其中具有冲突哈希的键值对被收集到单个“桶”中。要在地图中查找一个值，首先基于键的哈希选择一个桶，然后遍历桶中的每个键值对，直到找到匹配的键。\n![[Pasted image 20240807102716.png]]\n内置地图中的关键优化是使用“额外散列位”，这允许在遍历存储桶的插槽时快速进行相等性检查。在直接将查询键与候选键进行比较之前，查找算法首先比较每个键的 8 位散列（与存储桶散列独立）以查看是否可能存在正匹配。这种快速预检具有 1/256 的误报率，并且极大加速了通过散列表存储桶进行搜索。要了解有关 Golang 内置地图的更多设计细节，请查看 Keith Randall 在 2016 年 GopherCon 大会上的演讲“地图实现内部”。\nSwissTable 使用一种名为“closed-hashing”的不同散列方案。与将元素收集到桶中不同，散列表中的每个键-值对被分配其自己的“槽位”。此槽位的位置由探测算法决定，其起始点由键的哈希决定。最简单的例子是线性探测搜索，它从槽位 hash(key) mod size 开始，并在找到所需键或到达空槽位时停止。这种探测方法用于查找现有键和为新键找到插入位置。与内置的 Golang map 类似，SwissTable 使用“短哈希”来加速探测期间的相等性检查。但与内置的 map 不同，它的哈希元数据与键-值数据分开存储。\n![[Pasted image 20240807095909.png]]\nSwissTable 的分段内存布局是其性能的关键驱动因素。在表中探测序列只访问元数据数组，直到找到短哈希匹配为止。这种访问模式在探测过程中最大化了缓存局部性。一旦找到元数据匹配，相应的键几乎总是匹配的。拥有专用的元数据数组意味着我们可以使用 SSE 指令并行比较 16 个短哈希！使用 SSE 指令不仅更快，还是 SwissTable 支持最大负载因子 14/16 的原因。观察表明，“负面”探测（搜索表中不存在的键）仅在遇到空槽时终止。表中空槽越少，平均探测序列找到它们所需的时间就越长。为了保持HashTable的 O（1）访问时间，平均探测序列的长度必须受到一个小的恒定因子的限制。有效使用 SSE 指令允许我们将平均探测序列的长度除以 16。经验测量表明，即使在最大负载时，平均探测序列执行的 16 路比较也不到两次！ 如果您对了解 SwissTable 设计（更多）感兴趣，请查看 Matt Kulukundis 在 2017 年 CppCon 大会上的演讲，“逐步设计一个快速、高效、友好缓存的HashTable”。\n将 SwissTable 移植到 Golang 有了设计方案，就是该动手实施了。第一步是编写 find() 算法。正如马特·库卢昆迪斯在他的讲座中指出的那样，find() 是 SwissTable 中所有核心方法的基础：Get()、Has()、Put() 和 Delete() 的实现都从“查找”特定槽开始。您可以在此处阅读实际实现，但为简单起见，我们将查看伪代码版本。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 func (m Map) find(key) (slot int, ok bool) { h1, h2 := hashOf(key) // high and low hash bits s := modulus(h1, len(m.keys)/16) // pick probe start for { // SSE probe for \u0026#34;short hash\u0026#34; matches matches := matchH2(m.metadata[s:s+16], h2) for _, idx := range matches { if m.keys[idx] == key { return idx, true // found |key| } } // SSE probe for empty slots matches = matchEmpty(m.metadata[s:s+16]) for _, idx := range matches { return idx, false // found empty slot } s += 16 } } 搜索循环持续进行，直到达到两种退出条件之一。 对于调用 Get()、Has() 和 Delete() 的成功调用，当短哈希和键值都与查询键匹配时，会在第一个返回时终止。 对于 Put() 调用和未成功搜索的情况，会在找到空槽位时在第二个返回时终止。 在元数据数组中，空槽位由特殊的短哈希值编码。 matchEmpty 方法为此值执行 16 路 SSE 探测。\nGolang 对 SSE 指令的支持以及对 SIMD 指令的支持都很有限。为了利用这些基本函数，SwissMap 使用优秀的 Avo 软件包生成具有相关 SSE 指令的汇编函数。您可以在这里找到代码生成方法。\n块索引用例需要将哈希键映射到块查找数据的特定HashTable。但是，我们希望 SwissMap 是一个通用数据结构，可以在任何性能敏感的上下文中重复使用。使用泛型，我们可以定义一个HashTable，它和内置地图一样灵活\n1 2 3 4 5 6 package swiss type Map[K comparable, V any] struct { hash maphash.Hasher[K] ... } SwissMap 的哈希函数是 maphash，这是另一个 DoltHub 包，它使用 Golang 的运行时哈希程序，可以对任何可比较的数据类型进行哈希处理。在支持的平台上，运行时哈希程序将使用 AES 指令高效生成强哈希值。利用像 SSE 和 AES 这样的硬件优化使 SwissMap 能够将查找延迟最小化，甚至在处理更大的密钥集时胜过 Golang 的内置映射函数：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 goos: darwin goarch: amd64 pkg: github.com/dolthub/swiss cpu: Intel(R) Core(TM) i7-9750H CPU @ 2.60GHz BenchmarkStringMaps num_keys=16 num_keys=16 runtime_map-12 112244895\t10.71 ns/op num_keys=16 swiss.Map-12 65813416\t16.50 ns/op num_keys=128 num_keys=128 runtime_map-12 94492519\t12.48 ns/op num_keys=128 swiss.Map-12 62943102\t16.09 ns/op num_keys=1024 num_keys=1024 runtime_map-12 63513327\t18.92 ns/op num_keys=1024 swiss.Map-12 70340458\t19.13 ns/op num_keys=8192 num_keys=8192 runtime_map-12 45350466\t24.77 ns/op num_keys=8192 swiss.Map-12 58187996\t21.29 ns/op num_keys=131072 num_keys=131072 runtime_map-12 35635282\t40.24 ns/op num_keys=131072 swiss.Map-12 36062179\t30.71 ns/op PASS 最后，让我们来看看 SwissMap 的内存消耗。我们构建 SwissMap 的最初动机是为了使我们的块索引在最小化额外内存消耗的同时获得常数时间查找性能。SwissMap 支持比内置地图更高的最大负载因子（87.5% 对比 81.25%），但仅凭这一点并不能讲述整个故事。使用 Golang 的 pprof 分析器，我们可以测量每个地图的实际负载因子，针对一系列键集大小。测量代码可以在这里找到。\n![[Pasted image 20240807100333.png]]\n在上面的图表中，我们可以看到瑞士地图（SwissMap）和内置地图之间内存消耗模式明显不同。为了比较，我们还包括了存储相同数据集的数组的内存消耗。内置地图的内存消耗遵循阶梯函数，因为它始终由两的幂次数个存储桶构建而成。这种情况的原因来自于经典的位运算优化模式。\n任何HashTable查找（开放或闭合哈希）都必须基于查询键的哈希选择探测序列的起始位置。将哈希值映射到桶或插槽是通过余数除法完成的。事实证明，余数除法操作符％在 CPU 周期中是相当昂贵的，但如果除数是 2 的幂，则可以用最低 n 位的超快速位掩码替换％操作。因此，许多HashTable被限制在 2 的幂大小。通常这会产生可忽略的内存开销，但在分配包含数百万元素的HashTable时，影响会很大！如上图所示，Golang 的内置映射平均使用的内存比 SwissTable 多 63％！\n为了避免余数除法的速度缓慢以及二次幂大小造成的内存膨胀，我们的 SwissMap 实现采用了一种不同的模映射，最初由 Daniel Lemire 提出。这个想法看似简单：\n1 2 3 func fastModN(x, n uint32) uint32 { return uint32((uint64(x) * uint64(n)) \u0026gt;\u0026gt; 32) } 这种方法比经典的位掩码技术多出的操作很少，微基准测试只需四分之一纳秒。使用这种模数方法意味着我们受限于 uint32 的范围，但由于这个整数可以索引 16 个元素的存储桶，SwissMap 可以容纳高达 2 ^ 36 个元素。对于大多数用例来说，这已经足够了，并且可以节省内存，非常值得！\n尝试一下 SwissMap 希望这是一次关于HashTable设计和高性能 Golang 的深入了解。SwissMap 已经证明是我们分块索引问题的有效解决方案，但我们希望它也能成为其他性能敏感用例的通用包。虽然它并不适合每种情况，但我们认为在关注大型HashTable的内存利用率时，它是有用的。如果您对 SwissMap 有任何反馈，请随时在存储库中创建一个问题。或者，如果您想直接与我们交流，请加入我们的 Discord！\n本文长期连接 如果您觉得我的博客对你有帮助，请通过 RSS订阅我。 或者在X上关注我。 如果您有Medium账号，能给我个关注嘛？我的文章第一时间都会发布在Medium。 ","date":"2024-08-07T09:41:37+08:00","permalink":"https://huizhou92.com/zh-cn/p/%E8%AF%91swissmap%E4%B8%80%E4%B8%AA%E6%9B%B4%E5%B0%8F%E6%9B%B4%E5%BF%AB%E7%9A%84-golang-hashmap/","title":"【译】SwissMap：一个更小、更快的 Golang HashMap"},{"content":"我们在用golang 写程序的时候，一般不会去过分关注内存，因为golang 运行时能够很好的帮我们完成GC 工作，但是如果遇到了需要性能优化的场景，我们能够了解一些GC 的知识，以及如何优化GC，会有很大的收益。 这篇文章，我们通过一个解析XML文件的服务来学习一下。如何通过go trace 来优化GC，提高代码的性能。\n感谢 Arden Lions 优秀的演讲Evaluating Performance In Go。这篇文章可以理解成演讲的 blog 版本。\n如果您对 go trace 不太熟悉，可以先看一下@Vincent的文章Go: Discovery of the Trace Package\n所有的例子都在我的MacBook Pro M1 上运行，它有十个核心。\n我们的目标是实现一个从多个RSS XML文件处理程序，从title寻找包含go关键字的的item，这里，我使用我的博客的RSS XML文件作为示例，解析这个文件100次，模拟压力。\n完整的代码：https://github.com/hxzhouh/blog-example/tree/main/go/go_trace%20\nSingle list1: 使用单协程统计key\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 func freq(docs []string) int { var count int for _, doc := range docs { f, err := os.OpenFile(doc, os.O_RDONLY, 0) if err != nil { return 0 } data, err := io.ReadAll(f) if err != nil { return 0 } var d document if err := xml.Unmarshal(data, \u0026amp;d); err != nil { log.Printf(\u0026#34;Decoding Document [Ns] : ERROR :%+v\u0026#34;, err) return 0 } for _, item := range d.Channel.Items { if strings.Contains(strings.ToLower(item.Title), \u0026#34;go\u0026#34;) { count++ } } } return count } func main() { trace.Start(os.Stdout) defer trace.Stop() files := make([]string, 0) for i := 0; i \u0026lt; 100; i++ { files = append(files, \u0026#34;index.xml\u0026#34;) } count := freq(files) log.Println(fmt.Sprintf(\u0026#34;find key word go %d count\u0026#34;, count)) } 代码很简单，我们使用一个for循环就完成任务了。然后运行\n1 2 3 4 5 6 ➜ go_trace git:(main) ✗ go build ➜ go_trace git:(main) ✗ time ./go_trace 2 \u0026gt; trace_single.out -- result -- 2024/08/02 16:17:06 find key word go 2400 count ./go_trace 2 \u0026gt; trace_single.out 1.99s user 0.05s system 102% cpu 1.996 total 然后我们使用 go trace 查看 trace_single.out\nRunTime :2031ms, STW: 57ms, GC Occurrences :252ms ,GC STW AVE: 0.227ms\nGC 时间 占用总运行时间为: 57 / 2031 ≈ 0.02\n使用最大的内存为11.28M左右\nFigure 1: single: run time\nFigure 2: single: GC\nFigure 3: single: max heap\n我们现在只使用了一个核心，资源利用率太低，如果我们想加速这个程序，最好是使用并发，这也是go最擅长的部分。\nConcurrent List 2: 使用 FinOut 方式统计 key。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 func concurrent(docs []string) int { var count int32 g := runtime.GOMAXPROCS(0) wg := sync.WaitGroup{} wg.Add(g) ch := make(chan string, 100) go func() { for _, v := range docs { ch \u0026lt;- v } close(ch) }() for i := 0; i \u0026lt; g; i++ { go func() { var iFound int32 defer func() { atomic.AddInt32(\u0026amp;count, iFound) wg.Done() }() for doc := range ch { f, err := os.OpenFile(doc, os.O_RDONLY, 0) if err != nil { return } data, err := io.ReadAll(f) if err != nil { return } var d document if err = xml.Unmarshal(data, \u0026amp;d); err != nil { log.Printf(\u0026#34;Decoding Document [Ns] : ERROR :%+v\u0026#34;, err) return } for _, item := range d.Channel.Items { if strings.Contains(strings.ToLower(item.Title), \u0026#34;go\u0026#34;) { iFound++ } } } }() } wg.Wait() return int(count) } 使用同样的方式运行\n1 2 3 4 5 go build time ./go_trace 2 \u0026gt; trace_pool.out --- 2024/08/02 19:27:13 find key word go 2400 count ./go_trace 2 \u0026gt; trace_pool.out 2.83s user 0.13s system 673% cpu 0.439 total RunTime :425ms, STW: 154ms, GC Occurrences :39 ,GC STW AVE: 3.9ms\nGC 时间 占用总运行时间为: 154 /425 ≈ 0.36\n最大的内存消耗为91.60MB\nFigure 4: concurrent, GC count\nFigure 5: concurrent, Max heap\nconcurrent 比single 大约快了5倍，在go trace 的结果中，我们可以看到 concurrent 版本中GC占了36%的运行时间。有没有办法能优化这个时间呢？幸运的是在go 1.19 版本中我们有两个参数可以来控制GC。\nGOGC \u0026amp; GOMEMLIMIT 在go1.19 中添加了两个参数，可以用它来控制GC，GOGC 用于控制垃圾回收的频率，而 GOMEMLIMIT 用于限制程序的最大内存使用量。关于 GOGC和GOMEMLIMIT 详细细节，可以参考官方文档 gc-guide\nGOGC 根据官方文档中的这个公式:\n$New heap memory = (Live heap + GC roots) * GOGC / 100$\n根据官方文档，如果我们将GOGC设置为1000，理论上，会将GC触发的频率降低10倍，代价是内存占用增加十倍。（这只是一个理论模型，实际上很复杂）\n试试呗？\n1 2 3 ➜ go_trace git:(main) ✗ time GOGC=1000 ./go_trace 2 \u0026gt; trace_gogc_1000.out 2024/08/05 16:57:29 find key word go 2400 count GOGC=1000 ./go_trace 2 \u0026gt; trace_gogc_1000.out 2.46s user 0.16s system 757% cpu 0.346 total RunTime :314ms, STW: 9.572ms, GC Occurrences: 5, GC STW AVE: 1.194ms\nGC 时间 占用总运行时间为: 9.572/314 ≈ 0.02\n最大内存占用为 451MB。\nFigure 6: GOGC, Max Heap\nFigure 7: GOGC, GC count\nGOMEMLIMIT GOMEMLIMIT 用来设置程序使用的内存上限，一般在关闭自动GC 的场景下使用，让我们可以手动管理程序占用的内存总数。当程序分配的内存到达上限的时候，会触发GC。需要注意，虽然GC已经很努力的在工作了，程序使用的内存上限，可能还是会超过GOMEMLIMIT 的设定。\n在 single 版本中，我们的程序使用了11.28M 内存,concurrent 版本我们有十个协程一起运行，按照 gc-guide 的指导，我们需要预留10%的内存应对突发情况。所以我们可以把GOMEMLIMIT 设置为 11.28MB * 1.1 ≈ 124MB\n1 2 3 ➜ go_trace git:(main) ✗ time GOGC=off GOMEMLIMIT=124MiB ./go_trace 2 \u0026gt; trace_mem_limit.out 2024/08/05 18:10:55 find key word go 2400 count GOGC=off GOMEMLIMIT=124MiB ./go_trace 2 \u0026gt; trace_mem_limit.out 2.83s user 0.15s system 766% cpu 0.389 total RunTime :376.455 ms, STW: 41.578ms, GC Occurrences: 14, GC STW AVE: 2.969ms\nGC 时间 占用总运行时间为: 41.578/376.455 ≈ 0.11\n最大内存占用为 120MB,比较接近我们设置的上限。\nFigure 8: GOMEMLIMIT, GC Max Heap\nFigure 9: GOMEMLIMIT GC count\n如果我们继续增大 GOMEMLIMIT参数，会得到更好的结果，比如GOMEMLIMIT=248Mib 得到的trace 为下图所示\nFigure 10: GOMEMLIMIT= 248Mib, GC\nRunTime :320.455 ms, STW: 11.429ms, GC Occurrences: 5, GC STW AVE: 2.285ms\n但是他不是没有边界的， 比如 GOMEMLIMIT=1024Mib RunTime 已经到了406ms\nFigure 11: GOMEMLIMIT= 1024Mib, GC\n风险 在 Suggested_uses 中已经个给出了很明确的建议，除非对自己的程序的运行环境，面对的负载特别熟悉，否则不要使用这两个参数。请您务必阅读 gc-guide\n总结 最后我们总结一下上面的过程优化过程结果\nFigure 12: Result Compare\n在合适的场景使用GOGC以及GOMEMLIMIT，能够有效的提升性能。并且有一种掌控某种不确定东西的成就感。但是一定要在受控环境中合理应用，以确保性能和可靠性，而在资源共享或不受控制的环境中应谨慎，避免因设置不当导致性能下降或程序崩溃。\n参考资料 [1]. https://www.youtube.com/watch?v=PYMs-urosXs\u0026t=2684s\n[2]. https://www.uber.com/en-TW/blog/how-we-saved-70k-cores-across-30-mission-critical-services/\n[3]. https://tip.golang.org/doc/gc-guide\n","date":"2024-08-06T18:22:18Z","image":"https://images.hxzhouh.com/blog-images/2024/08/42af44f7ae36f49965e3ad6452fca825.png","permalink":"https://huizhou92.com/zh-cn/p/go-%E9%AB%98%E6%80%A7%E8%83%BD%E7%BC%96%E7%A8%8B-ep8-%E5%A6%82%E4%BD%95%E9%80%9A%E8%BF%87%E4%BC%98%E5%8C%96gc%E6%9D%A5%E6%8F%90%E9%AB%98golang%E4%BB%A3%E7%A0%81%E7%9A%84%E6%80%A7%E8%83%BD/","title":"Go 高性能编程 EP8: 如何通过优化GC来提高Golang代码的性能"},{"content":"原文:Avoiding high GC overhead with large heaps\n当分配的内存量相对较小时，Go垃圾收集器 (GC) 工作得非常好,但是如果堆的大小较大，GC过程可能会消耗大量 的CPU。在极端情况下，它甚至可能无法完成任务（GC算法保证GC不会使用超过50%的CPU时间，如果超过这阈值，会导致内存泄露）。\n有什么问题？ GC的工作是确定哪些内存块可被释放，它通过扫描内存中分配的指针来完成这一任务。简单来说，如果没有指针指向某个内存分配，则可释放该内存分配。这种方法非常有效，但需要扫描的内存越多，所需时间就越长。\n这是一个大问题吗？ 有多严重？我们来揭晓！以下是 demonstrate 的小程序。我们分配 1e9 个 8 字节指针，即约 8GB 的内存。我们强制执行 GC，并测量它需要多长时间。我们会重复几次以获得一个稳定的值。还调用 runtime.KeepAlive() 以防止编译器优化。\n1 2 3 4 5 6 7 8 9 10 11 func main() { a := make([]*int, 1e9) for i := 0; i \u0026lt; 10; i++ { start := time.Now() fmt.Printf(\u0026#34;GC took %s\\n\u0026#34;, time.Since(start)) } runtime.KeepAlive(a) } 在我的 2015 年 MBP上，输出结果如下所示。\n1 2 3 4 5 6 7 8 9 10 GC took 4.275752421s GC took 1.465274593s GC took 652.591348ms GC took 648.295749ms GC took 574.027934ms GC took 560.615987ms GC took 555.199337ms GC took 1.071215002s GC took 544.226187ms GC took 545.682881ms GC需要花费0.5S以上的时间。我为它分配了10e9个指针。事实上，每检查一个指针所花费的时间不到一纳秒。对于检查指针的速度来说，这已经相当快了。\n然后呢？ 如果我们的应用程序真的需要在内存中维持一个巨大的Map或者数组，那可就麻烦了。如果GC坚持定期扫描我们分配的全部内存，我们就会损失大量的CPU时间。有什么办法可以解决这个问题吗？ 我们基本上只有两种选择:要么对 GC 隐藏内存，要么使GC对其不感兴趣，不扫描它。\n让GC不扫描这部分内存 怎样才能让GC不扫描这部分内存？GC在寻找指针。如果我们分配的对象的类型不包含指针，GC还会扫描吗？\n我们可以尝试一下。在下面的例子中，我们分配与之前完全相同数量的内存，但这次我们的分配中没有指针类型。我们分配了一块包含十亿个 8 字节整数（ints）的切片内存。再次强调，这是大约8GB的内存。\n1 2 3 4 5 6 7 8 9 func main() { a := make([]int, 1e9) for i := 0; i \u0026lt; 10; i++ { start := time.Now() runtime.GC() fmt.Printf(\u0026#34;GC took %s\\n\u0026#34;, time.Since(start)) } runtime.KeepAlive(a) } 再次在我的 2015 年款 MBP上运行了这个程序，结果如下：\n1 2 3 4 5 6 7 8 9 10 GC took 350.941µs GC took 179.517µs GC took 169.442µs GC took 191.353µs GC took 126.585µs GC took 127.504µs GC took 111.425µs GC took 163.378µs GC took 145.257µs GC took 144.757µs GC 的速度快了足足一千倍，而所分配的内存数量却完全一样。原来 Go 语言内存管理器能识别每一次内存分配的类型，并且会给不包含指针的内存打上标记，这样 GC 在扫描内存时就能跳过它们。如果我们能让大内存中不包含指针的话，那就太棒了。\n将内存隐藏起来 我们可以做另一件事就是将分配的内存隐藏起来，让GC看不见。如果我们直接向操作系统请求内存，GC就永远不会知道它，也就不会扫描它。与我们之前例子的做法相比，这样做稍微有些复杂！这里是我们的第一个程序的等价版本，我们使用 mmap 系统调用直接从操作系统内核分配 []*int 亿（1e9）个条目。注意，这只在 *unix 系统上有效，但在 Windows 上也有类似的方法。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 package main import ( \u0026#34;fmt\u0026#34; \u0026#34;reflect\u0026#34; \u0026#34;runtime\u0026#34; \u0026#34;syscall\u0026#34; \u0026#34;time\u0026#34; \u0026#34;unsafe\u0026#34; ) func main() { var example *int slice := makeSlice(1e9, unsafe.Sizeof(example)) a := *(*[]*int)(unsafe.Pointer(\u0026amp;slice)) for i := 0; i \u0026lt; 10; i++ { start := time.Now() runtime.GC() fmt.Printf(\u0026#34;GC took %s\\n\u0026#34;, time.Since(start)) } runtime.KeepAlive(a) } func makeSlice(len int, eltsize uintptr) reflect.SliceHeader { fd := -1 data, _, errno := syscall.Syscall6( syscall.SYS_MMAP, 0, // address uintptr(len)*eltsize, syscall.PROT_READ|syscall.PROT_WRITE, syscall.MAP_ANON|syscall.MAP_PRIVATE, uintptr(fd), // No file descriptor 0, // offset ) if errno != 0 { panic(errno) } return reflect.SliceHeader{ Data: data, Len: len, Cap: len, } } 这次的GC耗时为：\n1 2 3 4 5 6 7 8 9 10 GC took 460.777µs GC took 206.805µs GC took 174.58µs GC took 193.697µs GC took 184.325µs GC took 142.556µs GC took 132.48µs GC took 155.853µs GC took 138.54µs GC took 159.04µs 如果您想了解 a := *(*[]*int)(unsafe.Pointer(\u0026amp;slice)) ，请浏览 https://blog.gopheracademy.com/advent-2017/unsafe-pointer-and-system-calls/。\n现在，这部分内存对GC是不可见的。这会带来一个有趣的后果，即存储在这一内存中的指针，不会阻止它们指向的‘正常’分配的内存被GC回收。而这会带来糟糕的后果，我们很容易就可证明。\n在这里，我们尝试将 0、1 和 2 存入堆分配的整数中，并将指向它们的指针存入mmap分配的切片中（不受GC管控）。在为每个整数分配内存并存储指向它们的指针后，我们强制执行一次垃圾回收。\n我们的输出在这里。在每次垃圾回收后，支持我们整数的内存都会被释放并可能被重新使用。所以，我们的数据并不像我们预期的那样，很幸运程序没有崩溃。\n1 2 3 4 5 6 7 8 9 10 a[0] is C000016090 *a[0] is 0 a[1] is C00008C030 *a[1] is 1 a[2] is C00008C030 *a[2] is 2 *a[0] is 0 *a[1] is 811295018 *a[2] is 811295018 这样显然是不行的。如果我们修改成使用通常分配的 []*int ，如下所示，就可以得到预期的结果。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 func main() { a := make([]*int, 3) for j := range a { a[j] = getMeAnInt(j) fmt.Printf(\u0026#34;a[%d] is %X\\n\u0026#34;, j, a[j]) fmt.Printf(\u0026#34;*a[%d] is %d\\n\u0026#34;, j, *a[j]) runtime.GC() } fmt.Println() for j := range a { fmt.Printf(\u0026#34;*a[%d] is %d\\n\u0026#34;, j, *a[j]) } } 输出如下：\n1 2 3 4 5 6 7 8 9 10 a[0] is C00009A000 *a[0] is 0 a[1] is C00009A040 *a[1] is 1 a[2] is C00009A050 *a[2] is 2 *a[0] is 0 *a[1] is 1 *a[2] is 2 问题的本质 所以，最终我们证明指针是我们的敌人，无论我们在堆上分配了大量内存，还是试图通过将数据移动到我们自己的非堆内存分配来规避这个问题。如果我们能在分配的类型中避免使用指针，就不会造成GC的负担，从而无需使用任何奇技淫巧。如果我们使用非堆内存分配，则需要避免存储对堆内存的指针，除非这些内存也被GC可访问内存所引用。\n我们如何才能避免使用指针？ 在大的堆内存中，指针是邪恶的，必须避免。但是要避免它们，你就必须能识别出来，而它们并不总是很明显。字符串、切片和 time.Time 均包含指针。如果你在内存中存储了大量这些数据，就可能需要采取一些措施。\n我遇到大堆问题时，主要原因有以下几点。\n许多字符串 将对象上的时间戳使用 time.Time 进行翻译。 值为slice 的map key 为string的 map\n对于处理这些问题的不同策略，有很多话要说。在本帖中，我只讨论一种处理字符串的方法。 将字符串slice变成一个带索引的数组。 一条字符串由两个部分组成。一个是字符串头，它会告诉你字符串的长度以及在哪里找到原始数据；另一个就是实际的字符串数据了，它只是一系列字节的顺序。\n当你将一个字符串变量传递给一个函数时，只有字符串的头被写入栈中，如果你保持一个字符串切片，那么切片中的字符串头就会出现。\n字符串头的定义是 reflect.StringHeader ，长这样：\n1 2 3 4 type StringHeader struct { Data uintptr Len int } 字符串头包含指针，所以我们不想存储字符串！\n如果你的字符串只取几种固定的值，可以考虑使用整数常量替代 将日期和时间作为字符串存储的话，不妨将它们解析为整数并存储起来 如果你真的需要很多string，那就请继续阅读……\n假设我们正在存储一亿条记录。为了简单起见，我们假定这是个巨大的全局变量 var mystrings []string 。\n这里有什么？ mystrings 的基础架构是一个 reflect.SliceHeader ，它与我们刚刚看到的 reflect.StringHeader 相似。 1 2 3 4 5 type SliceHeader struct { Data uintptr Len int Cap int } 对于 mystrings ，Len 和 Cap 都是 10e8，Data 会指向一个足够容纳 10e8 个 StringHeader 的连续内存区域。这一块内存包含指针，因此会被GC扫描。\n字符串本身由两部分组成。这个切片中包含的是StringHeaders，以及每个字符串的数据，这些数据是单独的分配，数据本身没有包含指针。从垃圾回收的角度来看，问题在于字符串头部，而不是字符串数据本身。字符串数据不包含指针，因此不会被扫描。庞大的字符串头部数组包含指针，因此必须在每个垃圾回收周期中进行扫描。\n如果所有字符串的字节都存放在一块内存中，我们可以通过每个字符串相对于内存起始和终止位置的偏移量来跟踪它们。通过跟踪偏移量，我们就可以在大型slice中消除指针，跳过垃圾回收的扫描。\n这样做的坏处就是，丧失了slice 操作的便利性，slice 的修改变得特别复杂，我们为将字符串体复制到大的字节切片上增加了开销。\n这里有一个小程序来演示这个想法。我们将创建 10e8个字符串，将这些字符串的字节复制到一个大的字节切片中，并存储偏移量。可以看到GC耗时非常少，然后通过显示前 10 个字符串来证明我们可以检索这些字符串。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 package main import ( \u0026#34;fmt\u0026#34; \u0026#34;runtime\u0026#34; \u0026#34;strconv\u0026#34; \u0026#34;time\u0026#34; \u0026#34;unsafe\u0026#34; ) func main() { var stringBytes []byte var stringOffsets []int for i := 0; i \u0026lt; 1e8; i++ { val := strconv.Itoa(i) stringBytes = append(stringBytes, val...) stringOffsets = append(stringOffsets, len(stringBytes)) } runtime.GC() start := time.Now() runtime.GC() fmt.Printf(\u0026#34;GC took %s\\n\u0026#34;, time.Since(start)) sStart := 0 for i := 0; i \u0026lt; 10; i++ { sEnd := stringOffsets[i] bytes := stringBytes[sStart:sEnd] stringVal := *(*string)(unsafe.Pointer(\u0026amp;bytes)) fmt.Println(stringVal) sStart = sEnd } } 1 2 3 4 5 6 7 8 9 10 11 GC took 187.082µs 0 1 2 3 4 5 6 7 8 9 如果你永远不需要修改这些字符串，可以将它转换为一个更大数据块的索引方式，从而避免大量指针。如果你感兴趣，我实现了一个更复杂一点的东西，它遵循这一原则。\n我之前多次在博客中提到过遇到由大堆引发的垃圾回收（GC）问题。事实上，每当我遇到这个问题时，我都感到惊讶，并再次在博客中写道它。希望看到这里时，如果在你项目中发现这个问题的话，不会让你感到惊讶，你甚至会提前想到这个问题。\n以下是一些资源，希望对你解决这些问题有所帮助。\n我上面提到的string store interning library 一个用于 Go 语言的字符串 interning 库， variation 将字符串 ID 转换为整数 ID，从而可以用于快速比较和数组/切片查找。 ","date":"2024-07-24T10:16:50+08:00","permalink":"https://huizhou92.com/zh-cn/p/%E8%AF%91-go-action%E5%A6%82%E4%BD%95%E9%81%BF%E5%85%8D%E5%9B%A0%E4%B8%BA%E5%A4%A7%E5%A0%86%E4%BA%A7%E7%94%9F%E7%9A%84%E9%AB%98gc%E5%BC%80%E9%94%80/","title":"【译】 Go Action：如何避免因为大堆产生的高GC开销"},{"content":"在开发业务代码过程中，我们经常会使用缓存DB数据的方式来加速查询，这样的架构会有一个问题，我们常常需要解决缓存穿透、缓存雪崩和缓存击穿问题。缓存击穿问题是指，在平常高并发的系统中，大量的请求同时查询一个 key 时，如果这个 key 正好过期失效了，就会导致大量的请求都打到数据库上，造成数据库压力很大，这就是缓存击穿。如果能够将一段时间的相同的N个请求合成一个，那么穿透到数据库的压力是不是就从N变成了1？\nSingleFlight 就是这样的一个并发原语。本文介绍了SingleFlight , 的使用以及它的基本原理，还有一些使用上的细节。\nThis article was first published in the Medium MPP plan. If you are a Medium user, please follow me on Medium. Thank you very much.\nFigure 1：使用 SingleFlight 合并相同的请求。\nSingleFlight 使用 Go 官方将 singleflight ,放在了golang.org/x 中，说明他可能还会有一些变化。它提供了重复函数调用抑制机制，使用它可以避免同时进行相同的函数调用。第一个调用未完成时后续的重复调用会等待，当第一个调用完成时则会与它们分享结果，这样以来虽然只执行了一次函数调用但是所有调用都拿到了最终的调用结果。\nlist1: 使用 SingleFlight 合并DB请求\n从结果可以看出，我们我们模拟了5个请求cache miss 的情况，但是只有一个请求调用了DB，五个请求都拿到了相同的结果。这对于后端服务来说，是很可观的优化。他避免了数据库被缓存穿透。\n在go 源码中，同样能看到 SingleFlight 的使用，比如/src/net/lookup.go#L165/src/cmd/go/internal/vcs/vcs.go#L1385，缓存库 groupcache 也是使用SingleFlight 类似的实现来防止缓存穿透。\nSingleflight 分析 singleflight包中定义了一个名为Group的结构体类型，它表示一类工作，并形成一个命名空间，在这个命名空间中，可以使用重复抑制来执行工作单元。\nSingleFlight 的数据结构是 Group，它提供了三个方法。\nDo：这个方法执行一个函数，并返回函数执行的结果。你需要提供一个 key，对于同一个 key，在同一时间只有一个在执行，同一个 key 并发的请求会等待。第一个执行的请求返回的结果，就是它的返回结果。函数 fn 是一个无参的函数，返回一个结果或者 error，而 Do 方法会返回函数执行的结果或者是 error，shared 会指示 v 是否返回给多个请求。 DoChan：类似 Do 方法，只不过是返回一个 chan，等 fn 函数执行完，产生了结果以后，就能从这个 chan 中接收这个结果。 Forget：告诉 Group 忘记这个 key。这样一来，之后这个 key 请求会执行 fn，而不是等待前一个未完成的 fn 函数的结果。 使用细节 请求阻塞 singleflight 内部使用 waitGroup 来让同一个 key 的除了第一个请求的后续所有请求都阻塞。直到第一个请求执行 fn 返回后，其他请求才会返回。\n这意味着，如果 fn 执行需要很长时间，那么后面的所有请求都会被一直阻塞。\n这时候我们可以使用 DoChan 结合 ctx + select 做超时控制\nForget singleflight 的实现为，如果第一个请求失败了，那么后续所有等待的请求都会返回同一个 error。\n实际上可以根据DB使用情况定时 forget 一下 key，让更多的请求能有机会走到后续逻辑。\n1 2 3 4 go func() { time.Sleep(100 * time.Millisecond) g.Forget(name) }() 比如1秒内有100个请求过来，正常是第一个请求能执行 GetUserFromDB，后续99个都会阻塞。\n增加这个 Forget 之后，每 100ms 就能有一个请求执行 GetUserFromDB，相当于是多了几次尝试的机会，相对的也给DB造成了更大的压力，需要根据具体场景进去取舍。\n","date":"2024-07-23T15:49:00+08:00","image":"https://images.hxzhouh.com/blog-images/2024/07/d516998be001327a93e663f8f504840a.png","permalink":"https://huizhou92.com/zh-cn/p/go%E9%AB%98%E6%80%A7%E8%83%BD%E7%BC%96%E7%A8%8B-ep7-%E4%BD%BF%E7%94%A8-singleflight-%E5%90%88%E5%B9%B6%E7%9B%B8%E5%90%8C%E7%9A%84%E8%AF%B7%E6%B1%82/","title":"Go高性能编程 EP7:  使用 SingleFlight 合并相同的请求"},{"content":"当我们尝试去优化代码的性能时，首先得知道当前的性能怎么样，得到一个基准性能。Go语言标准库内置的 testing 测试框架提供了benchmark的能力。本文主要介绍 如何使用benchmark 进行基准测试，以及如何提高benchmark 的精准度，最后介绍了两个工具，帮助我们更加方便的进行benchmark。\nThis article was first published in the Medium MPP plan. If you are a Medium user, please follow me on Medium. Thank you very much.\n稳定的测试环境 性能测试受环境的影响很大，为了保证测试的可重复性，在进行性能测试时，尽可能地保持测试环境的稳定。\n机器处于闲置状态，测试时不要执行其他任务，也不要和其他人共享硬件资源。 机器是否关闭了节能模式，一般笔记本会默认打开这个模式，测试时关闭。 避免使用虚拟机和云主机进行测试，一般情况下，为了尽可能地提高资源的利用率，虚拟机和云主机 CPU 和内存一般会超售，超售机器的性能表现会非常地不稳定。 一次测试是没有意义的，统计意义下可对比的结果是关键，对于一般的benchmark，我一般会重复执行20次。 Benchmark 是如何工作的 benchmark 其实就是重复调用某个函数，然后记录函数的执行时间等指标，来度量它的性能。一个典型的benchamrk 函数如下所示：\n1 2 3 4 5 6 7 8 9 10 11 12 func fib(n int) int { if n \u0026lt; 2 { return n } return fib(n-1) + fib(n-2) } func BenchmarkFib20(b *testing.B) { for i := 0; i \u0026lt; b.N; i++ { // Call the function we\u0026#39;re benchmarking fib(20) } } benchmark 函数必须以 Benchmark 开始 我们可以这样运行它,都是等效的。\n1 2 go test -bench . go test -bench=\u0026#34;BenchmarkFib20\u0026#34; b.N benchmark 用例的参数 b *testing.B，有个属性 b.N 表示这个用例需要运行的次数。b.N 对于每个用例都是不一样的。\n那这个值是如何决定的呢？b.N 从 1 开始，如果该用例能够在 1s 内完成，b.N 的值便会增加，再次执行。b.N 的值大概以 1, 2, 3, 5, 10, 20, 30, 50, 100 这样的序列递增，越到后面，增加得越快\n进阶参数 count 控制运行次数，而不受由b.N 控制 benchtime 控制运行时间，而受1s控制 benchmem 度量内存分配的次数 cpu 指定使用几个CPU核心，默认使用的是go\n同时，benchmark 测试支持go test 的其他参数，比如cpuprofile 、memprofile 、trace 等 提升准确度 降低系统噪音:perflock perflock 作用是限制 CPU 时钟频率，从而一定程度上消除系统对性能测试程序的影响，减少结果的噪声，进而性能测量的结果方差更小也更加可靠。\nResetTimer 如果在 benchmark 开始前，需要一些准备工作，如果准备工作比较耗时，则需要将这部分代码的耗时忽略掉。\nStopTimer \u0026amp; StartTimer StopTimer \u0026amp; StartTimer 也是相同原理，每次函数调用前后需要一些准备工作和清理工作，我们可以使用 StopTimer 暂停计时以及使用 StartTimer 开始计时。\n度量 Benchmark benchstat 是官方提供的一个对比工具，用于比较两次benchmark之间的性能差别\nBenchstat computes statistical summaries and A/B comparisons of Go benchmarks.\n我们用benchstat对比一下 bubbleSort 跟quickSort 的性能\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 func softNums() { //bubbleSort(nums) //quickSort(nums) } func initNums(count int) { rand.Seed(time.Now().UnixNano()) nums = make([]int, count) for i := 0; i \u0026lt; count; i++ { nums[i] = rand.Intn(count) } } func BenchmarkSoftNums(b *testing.B) { initNums(10000) b.ResetTimer() for i := 0; i \u0026lt; b.N; i++ { softNums() } } 1 2 3 4 5 6 7 8 9 10 go test -bench=\u0026#34;BenchmarkSoftNums\u0026#34; -count=10 |tee quicksoft.txt go test -bench=\u0026#34;BenchmarkSoftNums\u0026#34; -count=10 |tee bubblesoft.txt ➜ benchmark git:(main) ✗ benchstat bubblesoft.txt quicksoft.txt goos: darwin goarch: arm64 pkg: blog-example/go/benchmark │ bubblesoft.txt │ quicksoft.txt │ │ sec/op │ sec/op vs base │ SoftNums-10 31942.4µ ± 1% 775.8µ ± 2% -97.57% (p=0.000 n=10) 这样的结果是不是很清晰？我们可以把他放在报告或者github issue 中，很专业。\n一些第三方的工具 bench bench 是一个为 Go 程序提供集成性能测量、自动性能锁定、统计分析和颜色指示的基准测试工具。\nfuncbench funcbench 是 Prometheus 项目中用于自动化 Go 代码基准测试和性能比较的工具。以下是其主要特点和功能：\n支持比较本地分支与GitHub 分支、性能锁定、性能比较 等特点，有利于提高开发效率。如果项目比较大，可以参考这种方式。\n参考资料 https://dave.cheney.net/high-performance-go-workshop/gophercon-2019.html#welcome https://golang.design/under-the-hood/zh-cn/part3tools/ch09analysis/perf/ 本文长期链接 如果您觉得我的博客对你有帮助，请通过 RSS订阅我。 或者在X上关注我。 如果您有Medium账号，能给我个关注嘛？我的文章第一时间都会发布在Medium。 ","date":"2024-07-12T15:05:32+08:00","image":"https://images.hxzhouh.com/blog-images/2024/07/7c30776c74ed13c1b32cfd9ed3690a56.png","permalink":"https://huizhou92.com/zh-cn/p/go%E9%AB%98%E6%80%A7%E8%83%BD%E7%BC%96%E7%A8%8B-ep5-%E6%9B%B4%E7%B2%BE%E5%87%86%E7%9A%84benchmark/","title":"Go高性能编程 EP5: 更精准的benchmark"},{"content":"reflect 为 Go 语言提供了运行时动态获取对象的类型和值以及动态创建对象的能力。反射可以帮助抽象和简化代码，提高开发效率。Go 语言标准库以及很多开源软件中都使用了 Go 语言的反射能力，例如用于序列化和反序列化的 json、ORM 框架 gorm/xorm 等。本文的目标是学习reflect，以及如何提高reflect的性能。\nThis article was first published in the Medium MPP plan. If you are a Medium user, please follow me on Medium. Thank you very much.\nExample Code 如何使用反射简化代码 我们利用反射实现一个简单的功能，来看看反射如何帮助我们简化代码的。\n假设有一个配置类 Config，每个字段是一个配置项。我们需要从环境变量中 读取 CONFIG_xxxx 。然后初始化Config。\nlist 1 ：MySQL config\n1 2 3 4 5 6 7 8 9 // https://github.com/go-sql-driver/mysql/blob/v1.8.1/dsn.go#L37 type Config struct { User string `json:\u0026#34;user\u0026#34;` // Username Passwd string `json:\u0026#34;passwd\u0026#34;` // Password (requires User) Net string `json:\u0026#34;net\u0026#34;` // Network (e.g. \u0026#34;tcp\u0026#34;, \u0026#34;tcp6\u0026#34;, \u0026#34;unix\u0026#34;. default: \u0026#34;tcp\u0026#34;) Addr string `json:\u0026#34;addr\u0026#34;` // Address (default: \u0026#34;127.0.0.1:3306\u0026#34; for \u0026#34;tcp\u0026#34; and \u0026#34;/tmp/mysql.sock\u0026#34; for \u0026#34;unix\u0026#34;) DBName string `json:\u0026#34;db_name\u0026#34;` // Database name // 。。。。。 } Footguns 我们很容易写出这样的代码，\nlist2: 使用 for 循环初始化 Config\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 func InitConfig() *Config { cfg := \u0026amp;Config{} keys := []string{\u0026#34;CONFIG_MYSQL_USER\u0026#34;, \u0026#34;CONFIG_MYSQL_PASSWD\u0026#34;, \u0026#34;CONFIG_MYSQL_NET\u0026#34;, \u0026#34;CONFIG_MYSQL_ADDR\u0026#34;, \u0026#34;CONFIG_MYSQL_DB_NAME\u0026#34;} for _, key := range keys { if env, exist := os.LookupEnv(key); exist { switch key { case \u0026#34;CONFIG_MYSQL_USER\u0026#34;: cfg.User = env case \u0026#34;CONFIG_MYSQL_PASSWORD\u0026#34;: cfg.Passwd = env case \u0026#34;CONFIG_MYSQL_NET\u0026#34;: cfg.Net = env case \u0026#34;CONFIG_MYSQL_ADDR\u0026#34;: cfg.Addr = env case \u0026#34;CONFIG_MYSQL_DB_NAME\u0026#34;: cfg.DBName = env } } } return cfg } 但是使用硬编码的话，如果Config 结构发生改变，比如了修改 json 对应的字段、删除或新增了一个配置项等，这块的逻辑也需要发生改变。而更大的问题在于：非常容易出错，不好测试。\n如果我们改成使用 反射实现，实现的代码就是这样的:\nlist3: 使用reflect 实现初始化Config\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 func InitConfig2() *Config { config := Config{} typ := reflect.TypeOf(config) value := reflect.Indirect(reflect.ValueOf(\u0026amp;config)) for i := 0; i \u0026lt; typ.NumField(); i++ { f := typ.Field(i) if v, ok := f.Tag.Lookup(\u0026#34;json\u0026#34;); ok { key := fmt.Sprintf(\u0026#34;CONFIG_MYSQL_%s\u0026#34;, strings.ToUpper(v)) if env, exist := os.LookupEnv(key); exist { value.FieldByName(f.Name).Set(reflect.ValueOf(env)) } } } return \u0026amp;config } 实现逻辑其实是非常简单的：\n在运行时，利用反射获取到 Config 的每个字段的 Tag 属性，拼接出对应的环境变量的名称。 查看该环境变量是否存在，如果存在就将环境变量的值赋值给该字段。\n这样，无论Config 添加还是删除字段，InitConfig 函数都不需要修改，是不是比使用for循环的方式简洁多了？ 反射的性能 我们在很多地方都听说过:反射的性能很差，并且我们在对比json解析库的时候也验证了官方库JSON Unmarshal 的性能比较低.因为他需要执行更多的指令。那么反射的性能到底有多差呢？ 我们做一次benchmark就知道了。\nlist 4 : benchmark test New And Reflect Performance\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 func BenchmarkNew(b *testing.B) { var config *Config for i := 0; i \u0026lt; b.N; i++ { config = new(Config) } _ = config } func BenchmarkReflectNew(b *testing.B) { var config *Config typ := reflect.TypeOf(Config{}) b.ResetTimer() for i := 0; i \u0026lt; b.N; i++ { config, _ = reflect.New(typ).Interface().(*Config) } _ = config } ---- ➜ go_reflect git:(main) ✗ go test --bench . goos: darwin goarch: arm64 pkg: blog-example/go/go_reflect BenchmarkNew-10 47675076 25.40 ns/op BenchmarkReflectNew-10 36163776 32.51 ns/op PASS ok blog-example/go/go_reflect 3.895s 如果只是创建的场景，两者的性能差距不是特别大。\n我们再测试一下修改字段场景，通过反射修改字段有两种方式\nFieldByName\nField 下标模式\n我们分别测试两种模式的性能\nlist5: 测试修改Field 的性能\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 func BenchmarkFieldSet(b *testing.B) { config := new(Config) b.ResetTimer() for i := 0; i \u0026lt; b.N; i++ { config.Net = \u0026#34;tcp4\u0026#34; config.Addr = \u0026#34;127.0.0.1:3306\u0026#34; config.Passwd = \u0026#34;123456\u0026#34; config.User = \u0026#34;admin\u0026#34; } } func BenchmarkFieldSetFieldByName(b *testing.B) { config := new(Config) value := reflect.ValueOf(config).Elem() b.ResetTimer() for i := 0; i \u0026lt; b.N; i++ { value.FieldByName(\u0026#34;Net\u0026#34;).SetString(\u0026#34;tcp4\u0026#34;) value.FieldByName(\u0026#34;Addr\u0026#34;).SetString(\u0026#34;127.0.0.1:3306\u0026#34;) value.FieldByName(\u0026#34;Passwd\u0026#34;).SetString(\u0026#34;123456\u0026#34;) value.FieldByName(\u0026#34;User\u0026#34;).SetString(\u0026#34;admin\u0026#34;) } } func BenchmarkFieldSetField(b *testing.B) { config := new(Config) value := reflect.Indirect(reflect.ValueOf(config)) b.ResetTimer() for i := 0; i \u0026lt; b.N; i++ { value.Field(0).SetString(\u0026#34;tcp4\u0026#34;) value.Field(1).SetString(\u0026#34;127.0.0.1:3306\u0026#34;) value.Field(2).SetString(\u0026#34;123456\u0026#34;) value.Field(3).SetString(\u0026#34;admin\u0026#34;) } } ---- ➜ go_reflect git:(main) ✗ go test --bench=\u0026#34;BenchmarkFieldSet*\u0026#34; goos: darwin goarch: arm64 pkg: blog-example/go/go_reflect BenchmarkFieldSet-10 1000000000 0.3282 ns/op BenchmarkFieldSetFieldByName-10 6471114 185.3 ns/op BenchmarkFieldSetField-10 100000000 11.88 ns/op PASS ok blog-example/go/go_reflect 3.910s 差距很大，非reflect 方式跟 reflect Field 下标模式 ，差两个数量级，跟reflect FieldByName 模式 甚至达到了三个数量级，比较疑问的一个点是FieldByName 模式 跟 Field 下标模式 差距竟然也有一个数量级。不过我们能够从源码中找到答案。\nlist 6: reflect/value.go\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 func (v Value) FieldByName(name string) Value { v.mustBe(Struct) if f, ok := toRType(v.typ()).FieldByName(name); ok { return v.FieldByIndex(f.Index) } return Value{} } // FieldByIndex returns the nested field corresponding to index.// It panics if evaluation requires stepping through a nil // pointer or a field that is not a struct. func (v Value) FieldByIndex(index []int) Value { if len(index) == 1 { return v.Field(index[0]) } v.mustBe(Struct) for i, x := range index { if i \u0026gt; 0 { if v.Kind() == Pointer \u0026amp;\u0026amp; v.typ().Elem().Kind() == abi.Struct { if v.IsNil() { panic(\u0026#34;reflect: indirection through nil pointer to embedded struct\u0026#34;) } v = v.Elem() } } v = v.Field(x) } return v } list 7：reflect/type.go\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 func (t *rtype) FieldByName(name string) (StructField, bool) { if t.Kind() != Struct { panic(\u0026#34;reflect: FieldByName of non-struct type \u0026#34; + t.String()) } tt := (*structType)(unsafe.Pointer(t)) return tt.FieldByName(name) } // FieldByName returns the struct field with the given name// and a boolean to indicate if the field was found. func (t *structType) FieldByName(name string) (f StructField, present bool) { // Quick check for top-level name, or struct without embedded fields. hasEmbeds := false if name != \u0026#34;\u0026#34; { for i := range t.Fields { tf := \u0026amp;t.Fields[i] if tf.Name.Name() == name { return t.Field(i), true } if tf.Embedded() { hasEmbeds = true } } } if !hasEmbeds { return } return t.FieldByNameFunc(func(s string) bool { return s == name }) } 在反射的内部，字段是按顺序存储的，因此按照下标访问查询效率为 O(1)，而按照 Name 访问，则需要遍历所有字段，查询效率为 O(N)。结构体所包含的字段(包括方法)越多，那么两者之间的效率差距则越大。但是我们需要记忆字段的顺序，这很容易出错。\n如何提高性能 尽量避免使用reflect 使用反射赋值，效率非常低下，如果有替代方案，尽可能避免使用反射，特别是会被反复调用的热点代码。例如 RPC 协议中，需要对结构体进行序列化和反序列化，这个时候避免使用 Go 语言自带的 json 的 Marshal 和 Unmarshal 方法，因为标准库中的 json 序列化和反序列化是利用反射实现的。我们可以使用fastjson等替代标准库，应该能带来十倍左右的提升。\n尽量使用 Field 下标模式 从前面的benchmark 看来， Field 下标模式比FieldByName 的方式快接近一个数量级，在字段数量多的时候，更加明显，但是使用Field 下标模式会比较麻烦，我们需要记忆下标，并且很难修改。这个时候，我们可以使用一个Map 将Name 跟下标缓存起来。\n比如：\nlist8: cache FieldByName and Field index\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 func BenchmarkFieldSetFieldByNameCache(b *testing.B) { config := new(Config) typ := reflect.TypeOf(Config{}) value := reflect.ValueOf(config).Elem() cache := make(map[string]int) for i := 0; i \u0026lt; typ.NumField(); i++ { cache[typ.Field(i).Name] = i } b.ResetTimer() for i := 0; i \u0026lt; b.N; i++ { value.Field(cache[\u0026#34;Net\u0026#34;]).SetString(\u0026#34;tcp4\u0026#34;) value.Field(cache[\u0026#34;Addr\u0026#34;]).SetString(\u0026#34;127.0.0.1:3306\u0026#34;) value.Field(cache[\u0026#34;Passwd\u0026#34;]).SetString(\u0026#34;123456\u0026#34;) value.Field(cache[\u0026#34;User\u0026#34;]).SetString(\u0026#34;admin\u0026#34;) } } ---- BenchmarkFieldSetFieldByNameCache-10 32121740 36.85 ns/op 比直接使用FieldByName 提升了4倍，很可观的提升。\n总结 本文没有深入介绍 reflect 的细节，如果您想要进一步学习reflect 可以参考下面的文章： https://medium.com/capital-one-tech/learning-to-use-go-reflection-822a0aed74b7 https://go101.org/article/reflection.html 在各个基础库中，大量使用reflect ，合理的使用reflect 有助于简化代码，但是reflect 有性能损耗，最极端的情况可能降低3个数量级。 可以用 Field index + cache 的方式来优化 性能。\n对于reflect 您有什么其他想法嘛？留言跟我一起讨论。 ","date":"2024-07-09T09:44:18+08:00","image":"https://images.hxzhouh.com/blog-images/2024/07/fafe2d9c964dbdd44c76d86834fd745b.png","permalink":"https://huizhou92.com/zh-cn/p/go%E9%AB%98%E6%80%A7%E8%83%BD%E7%BC%96%E7%A8%8B-ep4-%E5%8F%8D%E5%B0%84/","title":"Go高性能编程 EP4: 反射"},{"content":"Golang最大的使命就是简化异步编程，当我们遇到那种需要批量处理且耗时的操作时，传统的单线程执行就显得吃力，这时就会想到异步并行处理。本篇文章介绍一些Golang异步编程的技巧。\nThis article was first published in the Medium MPP plan. If you are a Medium user, please follow me on Medium. Thank you very much.\n首先介绍一个简化并发编程的的库conc 里面封装了很多实用的工具，比如WaitGroup，iter.Map等。我们并不一定要在生产代码中使用conc，但是学习他的一些思路还是可以的。\n使用方式 Go 最简单的最常用的方式：使用go关键词\n1 2 3 4 5 6 7 8 func main() { go func() { fmt.Println(\u0026#34;hello world1\u0026#34;) }() go func() { fmt.Println(\u0026#34;hello world2\u0026#34;) }() } 或者：\n1 2 3 4 5 6 7 func main() { go Announce(\u0026#34;hello world1\u0026#34;) go Announce(\u0026#34;hello world2\u0026#34;) } func Announce(message string) { fmt.Println(message) } 使用匿名函数传递参数\n1 2 3 4 5 data := \u0026#34;Hello, World!\u0026#34; go func(msg string) { // Use msg to perform asynchronous task logic processing fmt.Println(msg) }(data) 这种方式不需要考虑返回值问题，如果要考虑返回值，可以使用下面的方式。\n通过goroutine和channel来实现超时控制 1 2 3 4 5 6 7 8 9 10 11 12 13 ch := make(chan int, 1) timer := time.NewTimer(time.Second) go func() { time.Sleep(2 * time.Second) ch \u0026lt;- 1 close(ch) }() select { case \u0026lt;-timer.C: fmt.Println(\u0026#34;timeout\u0026#34;) case result := \u0026lt;-ch: fmt.Println(result) } 使用sync.WaitGroup sync.WaitGroup用于等待一组协程完成其任务。通过Add()方法增加等待的协程数量，Done()方法标记协程完成，Wait()方法阻塞直到所有协程完成。\n1 2 3 4 5 6 7 8 9 10 11 var wg sync.WaitGroup // 启动多个协程 for i := 0; i \u0026lt; 5; i++ { wg.Add(1) go func(index int) { defer wg.Done() // 异步任务逻辑 }(i) } wg.Wait() } 1.4、使用errgroup实现goroutine group的错误处理 如果想简单获取协程返回的错误，errgroup包很适合，errgroup包是Go语言标准库中的一个实用工具，用于管理一组协程并处理它们的错误。可以使用errgroup.Group结构来跟踪和处理协程组的错误。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 var eg errgroup.Group for i := 0; i \u0026lt; 5; i++ { eg.Go(func() error { return errors.New(\u0026#34;error\u0026#34;) }) eg.Go(func() error { return nil }) } if err := eg.Wait(); err != nil { // 处理错误 } 一些使用技巧 使用channel的range和close操作 range操作可以在接收通道上迭代值，直到通道关闭。可以使用close函数关闭通道，以向接收方指示没有更多的值。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 ch := make(chan int) go func() { for i := 0; i \u0026lt; 5; i++ { ch \u0026lt;- i // 发送值到通道 } close(ch) // 关闭通道 }() // 使用range迭代接收通道的值 for val := range ch { // 处理接收到的值 } // do somethings 使用select语句实现多个异步操作的等待 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 ch1 := make(chan int) ch2 := make(chan string) go func() { // 异步任务1逻辑 ch1 \u0026lt;- result1 }() go func() { // 异步任务2逻辑 ch2 \u0026lt;- result2 }() // 在主goroutine中等待多个异步任务完成 select { case res1 := \u0026lt;-ch1: // 处理结果1 case res2 := \u0026lt;-ch2: // 处理结果2 } 使用select和time.After()实现超时控制 如果需要在异步操作中设置超时，可以使用select语句结合time.After()函数实现。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 ch := make(chan int) go func() { // 异步任务逻辑 time.Sleep(2 * time.Second) ch \u0026lt;- result }() // 设置超时时间 select { case res := \u0026lt;-ch: // 处理结果 case \u0026lt;-time.After(3 * time.Second): // 超时处理 } 使用time.Tick()和time.After()进行定时操作 time.Tick()函数返回一个通道，定期发送时间值，可以用于执行定时操作。time.After()函数返回一个通道，在指定的时间后发送一个时间值。\n1 2 3 4 5 6 7 8 9 10 11 12 13 tick := time.Tick(1 * time.Second) // 每秒执行一次操作 for { select { case \u0026lt;-tick: // 执行定时操作 } } select { case \u0026lt;-time.After(5 * time.Second): // 在5秒后执行操作 } 使用sync.Mutex或sync.RWMutex进行并发安全访问 当多个协程并发访问共享数据时，需要确保数据访问的安全性。sync.Mutex和sync.RWMutex提供了互斥锁和读写锁，用于在访问共享资源之前进行锁定，以避免数据竞争。sync.RWMutex是一种读写锁，可以在多个协程之间提供对共享资源的并发访问控制。多个协程可以同时获取读锁，但只有一个协程可以获取写锁。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 var mutex sync.Mutex var data int // 写操作，使用互斥锁保护数据 mutex.Lock() data = 123 mutex.Unlock() // 读操作，使用读锁保护数据 //RLock()加读锁时，如果存在写锁，则无法加读锁；当只有读锁或者没有锁时，可以加读锁，读锁可以加载多个 mutex.RLock() value := data mutex.RUnlock() var rwMutex sync.RWMutex var sharedData map[string]string // 读操作，使用rwMutex.RLock读锁保护数据 func readData(key string) string { rwMutex.RLock() defer rwMutex.RUnlock() return sharedData[key] } // 写操作，使用rwMutex.Lock写锁保护数据 func writeData(key, value string) { rwMutex.Lock() defer rwMutex.Unlock() sharedData[key] = value } 注意：sync.Mutex 的锁是不可以嵌套使用的 sync.RWMutex 的 RLock()是可以嵌套使用的 sync.RWMutex 的 mu.Lock() 是不可以嵌套的 sync.RWMutex 的 mu.Lock() 中不可以嵌套 mu.RLock()\n使用sync.Cond进行条件变量控制 sync.Cond是一个条件变量，用于在协程之间进行通信和同步。它可以在指定的条件满足之前阻塞等待，并在条件满足时唤醒等待的协程。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 var cond = sync.NewCond(\u0026amp;sync.Mutex{}) var ready bool go func() { // 异步任务逻辑 ready = true // 通知等待的协程条件已满足 cond.Broadcast() }() // 在某个地方等待条件满足 cond.L.Lock() for !ready { cond.Wait() } cond.L.Unlock() 使用sync.Pool管理对象池 sync.Pool是一个对象池，用于缓存和复用临时对象，可以提高对象的分配和回收效率。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 type MyObject struct { // 对象结构 } var objectPool = sync.Pool{ New: func() interface{} { // 创建新对象 return \u0026amp;MyObject{} }, } // 从对象池获取对象 obj := objectPool.Get().(*MyObject) // 使用对象 // 将对象放回对象池 objectPool.Put(obj) 使用sync.Once实现只执行一次的操作 sync.Once用于确保某个操作只执行一次，无论有多少个协程尝试执行它，常用于初始化或加载资源等场景。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 var once sync.Once var resource *Resource func getResource() *Resource { once.Do(func() { // 执行初始化资源的操作，仅执行一次 resource = initResource() }) return resource } // 在多个协程中获取资源 go func() { res := getResource() // 使用资源 }() go func() { res := getResource() // 使用资源 }() 使用sync.Once和context.Context实现资源清理 可以结合使用sync.Once和context.Context来确保在多个协程之间只执行一次资源清理操作，并在取消或超时时进行清理。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 var once sync.Once func cleanup() { // 执行资源清理操作 } func doTask(ctx context.Context) { go func() { select { case \u0026lt;-ctx.Done(): once.Do(cleanup) // 只执行一次资源清理 } }() // 异步任务逻辑 } 使用sync.Map实现并发安全的Map sync.Map是Go语言标准库中提供的并发安全的映射类型，可在多个协程之间安全地进行读写操作。\n1 2 3 4 5 6 7 8 9 10 11 12 var m sync.Map // 存储键值对 m.Store(\u0026#34;key\u0026#34;, \u0026#34;value\u0026#34;) // 获取值 if val, ok := m.Load(\u0026#34;key\u0026#34;); ok { // 使用值 } // 删除键 m.Delete(\u0026#34;key\u0026#34;) 使用context.Context进行协程管理和取消 context.Context用于在协程之间传递上下文信息，并可用于取消或超时控制。可以使用context.WithCancel()创建一个可取消的上下文，并使用context.WithTimeout()创建一个带有超时的上下文。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 ctx, cancel := context.WithCancel(context.Background()) go func() { // 异步任务逻辑 if someCondition { cancel() // 取消任务 } }() // 等待任务完成或取消 select { case \u0026lt;-ctx.Done(): // 任务被取消或超时 } 使用context.WithDeadline()和context.WithTimeout()设置截止时间 context.WithDeadline()和context.WithTimeout()函数可以用于创建带有截止时间的上下文，以限制异步任务的执行时间。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 func doTask(ctx context.Context) { // 异步任务逻辑 select { case \u0026lt;-time.After(5 * time.Second): // 超时处理 case \u0026lt;-ctx.Done(): // 上下文取消处理 } } func main() { ctx := context.Background() ctx, cancel := context.WithTimeout(ctx, 3*time.Second) defer cancel() go doTask(ctx) // 继续其他操作 } 使用context.WithValue()传递上下文值 context.WithValue()函数可用于在上下文中传递键值对，以在协程之间共享和传递上下文相关的值。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 type keyContextValue string func doTask(ctx context.Context) { if val := ctx.Value(keyContextValue(\u0026#34;key\u0026#34;)); val != nil { // 使用上下文值 } } func main() { ctx := context.WithValue(context.Background(), keyContextValue(\u0026#34;key\u0026#34;), \u0026#34;value\u0026#34;) go doTask(ctx) // 继续其他操作 } 使用atomic包进行原子操作 atomic包提供了一组函数，用于实现原子操作，以确保在并发环境中对共享变量的读写操作是原子的。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 var counter int64 func increment() { atomic.AddInt64(\u0026amp;counter, 1) } func main() { var wg sync.WaitGroup for i := 0; i \u0026lt; 100; i++ { wg.Add(1) go func() { defer wg.Done() increment() }() } wg.Wait() fmt.Println(\u0026#34;Counter:\u0026#34;, counter) } 总结 本篇文章，我们介绍的是一些常用的关键字，掌握这些，应对常用的并发编程已经问题没有什么问题了。相信您也已经发现了，go源码中没有提供java ，c# 中常用的 Barrier 功能，虽然Barrier 的功能我们使用基本的并发语句也能实现，但是不如调用现成的API接口方便。其实在 golang.org/x中有SingleFlight 以及是第三方[CyclicBarrier](https://github.com/marusama/cyclicbarrier)。下一篇文章中，我们将介绍这两个并发原语。\n本文长期链接 如果您觉得我的博客对你有帮助，请通过 RSS订阅我。 或者在X上关注我。 如果您有Medium账号，能给我个关注嘛？我的文章第一时间都会发布在Medium。 ","date":"2024-07-08T17:38:59+08:00","permalink":"https://huizhou92.com/zh-cn/p/go%E9%AB%98%E6%80%A7%E8%83%BD%E7%BC%96%E7%A8%8B-ep6-%E5%BC%82%E6%AD%A5%E7%BC%96%E7%A8%8B%E7%9A%84%E6%8A%80%E5%B7%A7/","title":"Go高性能编程 EP6: 异步编程的技巧"},{"content":" 本文写作所有的例子以 macbookpro M1 为例，该CPU为64位架构\n本文是Go语言高性能编程第三篇，分析了为什么需要内存对齐，Go语言内存对齐的规则，以及实际例子中内存对齐的使用，最后分享了两个工具，帮助我们在开发过程中发现内存对齐问题。\nThis article was first published in the Medium MPP plan. If you are a Medium user, please follow me on Medium. Thank you very much.\n什么是内存对齐？ 在程序员眼里，内存可能就是一个巨大的数组，我们可以在内存中写一个int16 ,占用两个字节。也可以写一个int32，占用四个字节。 比如\n1 2 3 4 5 type T1 struct { a int8 b int64 c int16 } 这个 struce 不熟悉Go语言的人可能认为是下面这种布局。 总共占用11字节空间。\nFigure 1: Memory layout as understood by some people\n一个挨着一个，很紧凑，很完美。\n但是实际上并不是这样的。如果我们打印 T1 的变量地址，会发现，他们大概长这样。总共占用 24字节空间。\nFigure 2: T1 的实际内存布局\nList 1：T1 size\n1 2 3 4 5 6 7 8 9 10 func main() { t := T1{} fmt.Println(fmt.Sprintf(\u0026#34;%d %d %d %d\u0026#34;, unsafe.Sizeof(t.a), unsafe.Sizeof(t.b), unsafe.Sizeof(t.c), unsafe.Sizeof(t))) fmt.Println(fmt.Sprintf(\u0026#34;%p %p %p\u0026#34;, \u0026amp;t.a, \u0026amp;t.b, \u0026amp;t.c)) fmt.Println(unsafe.Alignof(t)) } // output // 1 8 2 24 // 0x14000114018 0x14000114020 0x14000114028 // 8 因为CPU从内存里面拿数据，是根据word size 来拿的，比如 64 位的 CPU ，word size 为 8字节，那么 CPU 访问内存的单位也是 8 字节，我们将处理器访问内存的大小称为内存访问粒度。\n这种现象，会造成几个严重的问题\n性能降低，因为多了一次CPU指令 原本读一个变量是原子操作的，现在变得不原子 一些其他意想不到的情况。\n所以一般编译器都会实现内存对齐，用牺牲内存空间的方式，保证了： 平台（移植性）\n不是所有的硬件平台都能够访问任意地址上的任意数据。例如：特定的硬件平台只允许在特定地址获取特定类型的数据，否则会导致异常情况。 性能\n若访问未对齐的内存，将会导致 CPU 进行两次内存访问，并且要花费额外的时钟周期来处理对齐及运算。而本身就对齐的内存仅需要一次访问就可以完成读取动作，这显然高效很多，是标准的空间换时间做法。 GO语言内存对齐 go spec 中约定了 go 对齐的规则。\n1 2 3 4 5 6 7 type size in bytes byte, uint8, int8 1 uint16, int16 2 uint32, int32, float32 4 uint64, int64, float64, complex64 8 complex128 16 For a variable x of any type: unsafe.Alignof(x) is at least 1. For a variable x of struct type: unsafe.Alignof(x) is the largest of all the values unsafe.Alignof(x.f) for each field f of x, but at least 1. For a variable x of array type: unsafe.Alignof(x) is the same as the alignment of a variable of the array\u0026rsquo;s element type. 绝大部分情况下，go编译器会帮我们自动内存对齐，我们不需要关心内存是否对齐，但是在有一种情况下，需要手动对齐。\n在 x86 平台上原子操作 64bit 指针。之所以要强制对齐，是因为在 32bit 平台下进行 64bit 原子操作要求必须 8 字节对齐，否则程序会 panic。\n比如下面这段代码：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 package main import \u0026#34;sync/atomic\u0026#34; type T3 struct { b int64 c int32 d int64 } func main() { a := T3{} atomic.AddInt64(\u0026amp;a.d, 1) } 在 amd64 架构下运行不会报错，但是在i386 架构下面就会panic。\nFigure 3: T3 panic\n原因就是 T3 在 32bit 平台上是 4 字节对齐，而在 64bit 平台上是 8 字节对齐。在 64bit 平台上其内存布局为：\nFigure 4: T3在 amd64 的内存布局\n但是在I386 的布局为：\nFigure 5: T3在 i386的内存布局\n这个问题在 atomic 的 文档中有写。\nOn 386, the 64-bit functions use instructions unavailable before the Pentium MMX.\nOn non-Linux ARM, the 64-bit functions use instructions unavailable before the ARMv6k core.\nOn ARM, 386, and 32-bit MIPS, it is the caller\u0026rsquo;s responsibility to arrange for 64-bit alignment of 64-bit words accessed atomically via the primitive atomic functions (types Int64 and Uint64 are automatically aligned). The first word in an allocated struct, array, or slice; in a global variable; or in a local variable (because the subject of all atomic operations will escape to the heap) can be relied upon to be 64-bit aligned. 为了解决这种情况，我们必须手动 padding T3，让其 “看起来” 像是 8 字节对齐的：\n1 2 3 4 5 6 type T3 struct { b int64 c int32 _ int32 d int64 } 在go源码和开源库中也能看到很多类似的操作。\n比如\nmgc groupcache 所幸的是，我们其实有很多工具来帮助我们识别与优化 这些问题。\n工程实践 fieldalignment fieldalignment 是golang 官方的工具，它会帮我们发现代码中可能的内存对齐优化以及自动帮我们对齐。 比如T1 它会自动 转成内存对齐的。\n1 2 3 4 5 6 7 8 9 ➜ go_mem_alignment git:(main) ✗ fieldalignment -fix . /Users/hxzhouh/workspace/github/blog-example/go/go_mem_alignment/main.go:8:8: struct of size 24 could be 16 // change type T1 struct { b int64 c int16 a int8 } 也可以在 golangci-link 中使用它，fieldalignment 是隶属于 govet 的一个子功能，在 .golangci.yaml 中可以这样启用它：\nlist :\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 # .golangci.yml linters: disable-all: true enable: - govet fast: false linters-settings: govet: # report about shadowed variables check-shadowing: false fast: false # disable: # - fieldalignment # I\u0026#39;m ok to waste some bytes enable: - fieldalignment 但是，fieldalignment 有一个比较恼火的地方：它会在重新排布结构体成员的时候，将所有空行、注释通通删去。 所以有时候，你应该 git commit 一次，然后用一下这个工具，然后通过 git diff 来 review 它所做的变更，然后进行若干后处理。所以我再生产环境很少使用这个 工具，一般使用structlayout\nstructlayout structlayout 可以显示struct的布局以及大小，可以输出svg或者json格式的数据。如果一个struct 比较复杂，可以用这个工具来优化。\n安装方式\n1 2 3 4 go install honnef.co/go/tools/cmd/structlayout@latest go install honnef.co/go/tools/cmd/structlayout-pretty@latest go install honnef.co/go/tools/cmd/structlayout-optimize@latest go install github.com/ajstarks/svgo/structlayout-svg@latest 用structlayout 分析一下 T1\n1 structlayout -json ./main.go T1 | structlayout-svg \u0026gt;T1.svg Figure 6: T1 Structure Layout\n我们可以很清楚的看到有两个padding。 7 size 和 6size\n优化后的T2：\n1 2 3 4 5 type T2 struct { a int8 c int16 b int64 } Figure 7: T2 Structure Layout\n只有也有两个地方有padding，但是只有5个size。\n总结 在程序设计中，内存对齐是一项关键技术，旨在提高程序性能和兼容性。本文以Go语言为例，详细讲解了内存对齐的基本概念和必要性，并通过代码示例展示了不同结构体在内存中的实际布局。\nGo语言中的内存对齐规则主要体现在结构体字段的排列顺序上。编译器通过自动对齐来保证性能和平台移植性，但在某些情况下需要开发者手动调整结构体字段以避免性能问题和潜在的错误。\nempty struct 是内存对齐优化的一个好帮手，具体操作可以参考我的另外一篇文章：Golang High-Performance Programming EP1: Empty Struct\n为帮助开发者检测和优化内存对齐问题，本文介绍了两个实用工具：\nfieldalignment：Go官方工具，能自动优化结构体的内存对齐。 structlayout：显示结构体的内存布局，帮助开发者更直观地理解和优化内存使用。 通过合理使用这些工具，开发者可以在保证程序性能和稳定性的同时，减少内存浪费，提升开发效率。\n参考资料 IBM DeveloperWorks: Data Alignment Go Specification: Size and Alignment Guarantees ","date":"2024-07-03T15:48:59+08:00","image":"https://images.hxzhouh.com/blog-images/2024/07/b3eca51256266ff32f8a27c85544e1c8.jpg","permalink":"https://huizhou92.com/zh-cn/p/go%E9%AB%98%E6%80%A7%E8%83%BD%E7%BC%96%E7%A8%8Bep3-%E5%86%85%E5%AD%98%E5%AF%B9%E9%BD%90/","title":"Go高性能编程EP3: 内存对齐"},{"content":"我们都知道，Go有一个很重要的特点，那就是它的编译速度非常快，编译速度是Go语言设计的时候就重点考虑的问题. 但是您有没有观察过Go语言编译后的二进制可执行文件的大小？我们先用一个简单的http server 的例子来看看。\nThis article was first published in the Medium MPP plan. If you are a Medium user, please follow me on Medium. Thank you very much.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 import ( \u0026#34;fmt\u0026#34; \u0026#34;net/http\u0026#34; ) func main() { // create a http server and create a handler hello, return hello world http.HandleFunc(\u0026#34;/\u0026#34;, func(w http.ResponseWriter, r *http.Request) { fmt.Fprintf(w, \u0026#34;Hello, World\\n\u0026#34;) }) // listen to port 8080 err := http.ListenAndServe(\u0026#34;:8080\u0026#34;, nil) if err != nil { return } } --- 编译后的体积达到了6.5M\n1 2 3 ➜ binary-size git:(main) ✗ go build -o server main.go ➜ binary-size git:(main) ✗ ls -lh server -rwxr-xr-x 1 hxzhouh staff 6.5M Jul 2 14:20 server Go语言的编译器会对二进制文件的大小进行裁剪，如果您对这部分的内容感兴趣，请阅读我的另外一篇文章How Does the Go Compiler Reduce Binary File Size?\n现在我们来尝试优化一下server 的大小。\n消除调试信息 Go 编译器默认编译出来的程序会带有符号表和调试信息，一般来说 release 版本可以去除调试信息以减小二进制体积。\n1 2 3 ➜ binary-size git:(main) ✗ go build -ldflags=\u0026#34;-s -w\u0026#34; -o server main.go ➜ binary-size git:(main) ✗ ls -lh server -rwxr-xr-x 1 hxzhouh staff 4.5M Jul 2 14:30 server -s：忽略符号表和调试信息。 -w：忽略DWARFv3调试信息，使用该选项后将无法使用gdb进行调试。\n体积从 6.5M 下降到 4.5M，下降约 30%。这是很好的第一步。 使用 Upx UPX is an advanced executable file compressor. UPX will typically reduce the file size of programs and DLLs by around 50%-70%, thus reducing disk space, network load times, download times and other distribution and storage costs.\n在Mac 上可以通过brew 安装upx\n1 brew install upx 单独使用upx 压缩 upx 有很多参数，最重要的则是压缩率，1-9，1 代表最低压缩率，9 代表最高压缩率。\n接下来，我们看一下，如果只使用 upx 压缩，二进制的体积可以减小多少呢。\n1 2 ➜ binary-size git:(main) ✗ go build -o server main.go \u0026amp;\u0026amp; upx -9 server \u0026amp;\u0026amp; ls -lh server -rwxr-xr-x 1 hxzhouh staff 3.9M Jul 2 14:38 server 压缩比例达到了 60%\nUpx + 编译器选项 同时开启 upx + -ldflags=\u0026quot;-s -w\u0026quot;\n1 2 ➜ binary-size git:(main) ✗ go build -ldflags=\u0026#34;-s -w\u0026#34; -o server main.go \u0026amp;\u0026amp; upx --brute server \u0026amp;\u0026amp; ls -lh server -rwxr-xr-x 1 hxzhouh staff 1.4M Jul 2 14:40 server 最终我们得到的的可执行文件的大小是 1.4M 对比不开启任何压缩的6.5M，大约节约了80%的空间，对于大型应用，还是挺可观的。\nUpx 的原理 upx 压缩后的程序和压缩前的程序一样，无需解压仍然能够正常地运行，这种压缩方法称之为带壳压缩，压缩包含两个部分：\n在程序开头或其他合适的地方插入解压代码； 将程序的其他部分压缩。 执行时，也包含两个部分：\n首先执行的是程序开头的插入的解压代码，将原来的程序在内存中解压出来； 再执行解压后的程序。\n也就是说，upx 在程序执行时，会有额外的解压动作，不过这个耗时几乎可以忽略。\n如果对编译后的体积没什么要求的情况下，可以不使用 upx 来压缩。一般在服务器端独立运行的后台服务，无需压缩体积。 最后 https://stackoverflow.com/questions/3861634/how-to-reduce-go-compiled-file-size\n这帖子里面有很多有意思的答案，\n比如用c语言跟go语言实现相同的功能（小demo）c语言生成的可执行大小是 go 语言的1/20(为什么呢？) 在Go语言中我们使用 println 来替代 fmt.println 就能避免引入fmt包，进一步缩小体积。 ","date":"2024-07-02T15:01:44+08:00","image":"https://images.yixiao9206.cn/blog-images/2024/07/5f408427cbeaa5018a5af3e3499fdb82.png","permalink":"https://huizhou92.com/zh-cn/p/go-%E9%AB%98%E6%80%A7%E8%83%BD%E7%BC%96%E7%A8%8Bep2-%E9%80%9A%E8%BF%87upx-%E7%BC%A9%E5%B0%8F%E5%8F%AF%E6%89%A7%E8%A1%8C%E4%BA%8C%E8%BF%9B%E5%88%B6%E6%96%87%E4%BB%B6%E7%9A%84%E4%BD%93%E7%A7%AF/","title":"Go 高性能编程EP2:  通过upx 缩小可执行二进制文件的体积"},{"content":"gRPC 一般不在 message 中定义错误。\n毕竟每个 gRPC 服务本身就带一个 error 的返回值，这是用来传输错误的专用通道。\ngRPC 中所有的错误返回都应该是 nil 或者 由 status.Status 产生的一个error。这样error可以直接被调用方Client识别。\nThis article is first published in the medium MPP plan. If you are a medium user, please follow me in medium. Thank you very much.\n1. 常规用法 当遇到一个go错误的时候，直接返回是无法被下游client识别的。\n恰当的做法是：\n调用 status.New 方法，并传入一个适当的错误码，生成一个 status.Status 对象 调用该 status.Err 方法生成一个能被调用方识别的error，然后返回 1 2 st := status.New(codes.NotFound, \u0026#34;some description\u0026#34;) err := st.Err() 传入的错误码是 codes.Code 类型。\n此外还有更便捷的办法：使用 status.Error。它避免了手动转换的操作。\n1 err := status.Error(codes.NotFound, \u0026#34;some description\u0026#34;) 2. 进阶用法 上面的错误有个问题，就是 code.Code 定义的错误码只有固定的几种，无法详尽地表达业务中遇到的错误场景。\ngRPC 提供了在错误中补充信息的机制：status.WithDetails 方法\nClient 通过将 error 重新转换位 status.Status ，就可以通过 status.Details 方法直接获取其中的内容。\nstatus.Details 返回的是个slice， 是interface{}的slice，然而go已经自动做了类型转换，可以通过断言直接使用。\n服务端示例服务端示例 生成一个 status.Status 对象 填充错误的补充信息 // 生成一个 status.Status\n1 2 3 4 5 6 7 8 9 10 11 12 func ErrorWithDetails() error { st := status.Newf(codes.Internal, fmt.Sprintf(\u0026#34;something went wrong: %v\u0026#34;, \u0026#34;api.Getter\u0026#34;)) v := \u0026amp;errdetails.PreconditionFailure_Violation{ //errDetails Type: \u0026#34;test\u0026#34;, Subject: \u0026#34;12\u0026#34;, Description: \u0026#34;32\u0026#34;, } br := \u0026amp;errdetails.PreconditionFailure{} br.Violations = append(br.Violations, v) st, _ = st.WithDetails(br) return st.Err() } 客户端的示例 调用RPC错误后，解析错误信息 通过断言直接获取错误详情 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 resp, err := odinApp.CreatePlan(cli.StaffId.AssetId, gentRatePlanMeta(cli.StaffId)) ​ if status.Code(err) != codes.InvalidArgument { logger.Error(\u0026#34;create plan error:%v\u0026#34;, err) } else { for _, d := range status.Convert(err).Details() { // switch info := d.(type) { case *errdetails.QuotaFailure: logger.Info(\u0026#34;Quota failure: %s\u0026#34;, info) case *errdetails.PreconditionFailure: detail := d.(*errdetails.PreconditionFailure).Violations for _, v1 := range detail { logger.Info(fmt.Sprintf(\u0026#34;details: %+v\u0026#34;, v1)) } case *errdetails.ResourceInfo: logger.Info(\u0026#34;ResourceInfo: %s\u0026#34;, info) ​ case *errdetails.BadRequest: logger.Info(\u0026#34;ResourceInfo: %s\u0026#34;, info) ​ default: logger.Info(\u0026#34;Unexpected type: %s\u0026#34;, info) } } } logger.Infof(\u0026#34;create plan success,resp=%v\u0026#34;, resp) 原理 这个错误是如何传递给调用方Client的呢？\n是放到 metadata中的，而metadata是放到HTTP的header中的。\nmetadata是key：value格式的数据。错误的传递中，key是个固定值：grpc-status-details-bin。\n而value，是被proto编码过的，是二进制安全的。\n目前大多数语言都实现了这个机制。\n注意 gRPC对响应头做了限制，上限为8K，所以错误不能太大。\n参考资料\nhttps://protobuf.dev/getting-started/gotutorial/\nhttps://pkg.go.dev/google.golang.org/genproto/googleapis/rpc/errdetails ","date":"2024-06-29T21:38:00Z","permalink":"https://huizhou92.com/zh-cn/p/go-action-error-handling-in-grpc/","title":"gRPC中的错误处理"},{"content":"gRPC 是Google开发的一个高性能RPC框架，gRPC 默认内置了两种认证方式：\nSSL/TLS 认证方式 基于 Token 的认证方式\n没有启用证书的gRPC服务和客户端进行的是明文通信，信息面临被任何第三方监听的风险。为了保证gRPC通信不被第三方监听、篡改或伪造，可以对服务器启动TLS加密特性。\n从 go 1.15 版本开始废弃 CommonName，因此推荐使用 SAN 证书。如果按照之前的步骤通过 OpenSSL 来生成密钥、CSR、证书，会出现这样的错误： 1 rpc error: code = Unavailable desc = connection error: desc = \u0026#34;transport: authentication handshake failed: x509: certificate relies on legacy Common Name field, use SANs instead\u0026#34;| This article was first published in the Medium MPP plan. If you are a Medium user, please follow me on Medium. Thank you very much.\n什么是SAN SAN(Subject Alternative Name) 是 SSL 标准 x509 中定义的一个扩展。使用了 SAN 字段的 SSL 证书，可以扩展此证书支持的域名，使得一个证书可以支持多个不同域名的解析。\n通俗点就是，在 SAN 证书中，可以有多个完整的 CN（CommonName），这样只需要购买一个证书就可以用在多个 URL。比如 skype.com 的证书，它就有很多 SAN。\n在本地创建SAN 证书 下面 我们将用一个例子在本地生成 客户端\u0026amp;服务端双向SAN 证书。\n假设gRPC服务端的主机名为localhost，需要为gRPC服务端和客户端之间的通信配置tls双向认证加密。\n新建 openssl.conf 来放相关信息 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 [req] req_extensions = v3_req distinguished_name = req_distinguished_name prompt = no [req_distinguished_name] countryName = CN stateOrProvinceName = state localityName = city organizationName = huizhou92 commonName = hello-world [v3_req] subjectAltName = @alt_names [alt_names] DNS.1 = localhost 其中内容 跟 以前创建ca的时候差不多。\n2. 生成ca根证书\n1 openssl req -x509 -newkey rsa:4096 -keyout ca.key -out ca.crt -subj \u0026#34;/CN=localhost\u0026#34; -days 3650 -nodes -nodes 是忽略密码,方便使用，但是请注意，这可能会降低私钥的安全性，因为任何人都可以读取未加密的私钥。\n3. 生成服务端证书\n1 2 openssl req -newkey rsa:2048 -nodes -keyout server.key -out server.csr -subj \u0026#34;/CN=localhost\u0026#34; -config openssl.cnf openssl x509 -req -in server.csr -out server.crt -CA ca.crt -CAkey ca.key -CAcreateserial -days 365 -extensions v3_req -extfile openssl.cnf 生成客户端证书 1 2 3 openssl req -newkey rsa:2048 -nodes -keyout client.key -out client.csr -subj \u0026#34;/CN=localhost\u0026#34; -config openssl.cnf openssl x509 -req -in client.csr -out client.crt -CA ca.crt -CAkey ca.key -CAcreateserial -days 365 -extensions v3_req -extfile openssl.cnf 最终生成的结果如下\n1 2 ➜ keys git:(day1) ✗ ls ca.crt ca.key ca.srl client.crt client.csr client.key openssl.cnf server.crt server.csr server.key 测试 我们定义一个最简单的grpc接口\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 // helloworld.proto syntax = \u0026#34;proto3\u0026#34;; option go_package = \u0026#34;./api;api\u0026#34;; package api; // The greeting service definition. service Greeter { // Sends a greeting rpc SayHello (HelloRequest) returns (HelloReply) {} } // The request message containing the user\u0026#39;s name. message HelloRequest { string name = 1; } // The response message containing the greetings message HelloReply { string message = 1; } 服务端实现 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 package main import ( \u0026#34;context\u0026#34; \u0026#34;crypto/tls\u0026#34; \u0026#34;crypto/x509\u0026#34; \u0026#34;fmt\u0026#34; \u0026#34;google.golang.org/genproto/googleapis/rpc/errdetails\u0026#34; \u0026#34;google.golang.org/grpc\u0026#34; \u0026#34;google.golang.org/grpc/codes\u0026#34; \u0026#34;google.golang.org/grpc/credentials\u0026#34; \u0026#34;google.golang.org/grpc/status\u0026#34; \u0026#34;hello-world/api\u0026#34; \u0026#34;io\u0026#34; \u0026#34;log\u0026#34; \u0026#34;net\u0026#34; \u0026#34;os\u0026#34; \u0026#34;time\u0026#34; ) type server struct { api.UnimplementedGreeterServer } func (s *server) SayHello(ctx context.Context, in *api.HelloRequest) (*api.HelloReply, error) { log.Printf(\u0026#34;Received: %v\u0026#34;, in.GetName()) select { case \u0026lt;-ctx.Done(): log.Println(\u0026#34;client timeout return\u0026#34;) return nil, ErrorWithDetails() case \u0026lt;-time.After(3 * time.Second): return \u0026amp;api.HelloReply{Message: \u0026#34;Hello \u0026#34; + in.GetName()}, nil } } func main() { certificate, err := tls.LoadX509KeyPair(\u0026#34;./keys/server.crt\u0026#34;, \u0026#34;./keys/server.key\u0026#34;) if err != nil { log.Fatalf(\u0026#34;Failed to load key pair: %v\u0026#34;, err) } // 通过CA创建证书池 certPool := x509.NewCertPool() ca, err := os.ReadFile(\u0026#34;./keys/ca.crt\u0026#34;) if err != nil { log.Fatalf(\u0026#34;Failed to read ca: %v\u0026#34;, err) } // 将来自CA的客户端证书附加到证书池 if ok := certPool.AppendCertsFromPEM(ca); !ok { log.Fatalf(\u0026#34;Failed to append ca certificate\u0026#34;) } opts := []grpc.ServerOption{ grpc.Creds( // 为所有传入的连接启用TLS credentials.NewTLS(\u0026amp;tls.Config{ ClientAuth: tls.RequireAndVerifyClientCert, Certificates: []tls.Certificate{certificate}, ClientCAs: certPool, }, )), } listen, err := net.Listen(\u0026#34;tcp\u0026#34;, fmt.Sprintf(\u0026#34;0.0.0.0:%d\u0026#34;, 50051)) if err != nil { log.Fatalf(\u0026#34;failed to listen %d port\u0026#34;, 50051) } // 通过传入的TLS服务器凭证创建新的gRPC服务实例 s := grpc.NewServer(opts...) api.RegisterGreeterServer(s, \u0026amp;server{}) log.Printf(\u0026#34;server listening at %v\u0026#34;, listen.Addr()) if err := s.Serve(listen); err != nil { log.Fatalf(\u0026#34;Failed to serve: %v\u0026#34;, err) } } func ErrorWithDetails() error { st := status.Newf(codes.Internal, fmt.Sprintf(\u0026#34;something went wrong: %v\u0026#34;, \u0026#34;api.Getter\u0026#34;)) v := \u0026amp;errdetails.PreconditionFailure_Violation{ //errDetails Type: \u0026#34;test\u0026#34;, Subject: \u0026#34;12\u0026#34;, Description: \u0026#34;32\u0026#34;, } br := \u0026amp;errdetails.PreconditionFailure{} br.Violations = append(br.Violations, v) st, _ = st.WithDetails(br) return st.Err() } 我们直接运行服务端 go run main.go\n客户端 首先我们使用一个不带证书的请求\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 func Test_server_SayHello_No_Cert(t *testing.T) { conn, err := grpc.Dial(\u0026#34;localhost:50051\u0026#34;, grpc.WithTransportCredentials(insecure.NewCredentials())) if err != nil { log.Fatalf(\u0026#34;Connect to %s failed\u0026#34;, \u0026#34;localhost:50051\u0026#34;) } defer conn.Close() client := api.NewGreeterClient(conn) // 创建带有超时时间的上下文, cancel可以取消上下文 ctx, cancel := context.WithTimeout(context.Background(), time.Second*5) defer cancel() // 业务代码处理部分 ... r, err := client.SayHello(ctx, \u0026amp;api.HelloRequest{Name: \u0026#34;Hello\u0026#34;}) if err != nil { log.Printf(\u0026#34;Failed to greet, error: %v\u0026#34;, err) } else { log.Printf(\u0026#34;Greeting: %v\u0026#34;, r.GetMessage()) } // Set up a connection to the server. log.Printf(\u0026#34;Greeting: %s\u0026#34;, r.GetMessage()) } 输出\n1 2024/05/12 19:18:51 Failed to greet, error: rpc error: code = Unavailable desc = connection error: desc = \u0026#34;error reading server preface: EOF\u0026#34; 服务不可用\n我们再使用一个携带证书的请请求\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 func Test_server_SayHello(t *testing.T) { certificate, err := tls.LoadX509KeyPair(\u0026#34;./keys/client.crt\u0026#34;, \u0026#34;./keys/client.key\u0026#34;) if err != nil { log.Fatalf(\u0026#34;Failed to load client key pair, %v\u0026#34;, err) } certPool := x509.NewCertPool() ca, err := os.ReadFile(\u0026#34;./keys/ca.crt\u0026#34;) if err != nil { log.Fatalf(\u0026#34;Failed to read %s, error: %v\u0026#34;, \u0026#34;./keys/ca.crt\u0026#34;, err) } if ok := certPool.AppendCertsFromPEM(ca); !ok { log.Fatalf(\u0026#34;Failed to append ca certs\u0026#34;) } opts := []grpc.DialOption{ grpc.WithTransportCredentials(credentials.NewTLS( \u0026amp;tls.Config{ ServerName: \u0026#34;localhost\u0026#34;, Certificates: []tls.Certificate{certificate}, RootCAs: certPool, })), } // conn, err := grpc.Dial(*addr, grpc.WithTransportCredentials(insecure.NewCredentials())) conn, err := grpc.Dial(\u0026#34;localhost:50051\u0026#34;, opts...) if err != nil { log.Fatalf(\u0026#34;Connect to %s failed\u0026#34;, \u0026#34;localhost:50051\u0026#34;) } defer conn.Close() client := api.NewGreeterClient(conn) // 创建带有超时时间的上下文, cancel可以取消上下文 ctx, cancel := context.WithTimeout(context.Background(), time.Second*5) defer cancel() // 业务代码处理部分 ... r, err := client.SayHello(ctx, \u0026amp;api.HelloRequest{Name: \u0026#34;Hello\u0026#34;}) if err != nil { log.Printf(\u0026#34;Failed to greet, error: %v\u0026#34;, err) } else { log.Printf(\u0026#34;Greeting: %v\u0026#34;, r.GetMessage()) } // Set up a connection to the server. log.Printf(\u0026#34;Greeting: %s\u0026#34;, r.GetMessage()) } 输出\n1 2 === RUN Test_server_SayHello 2024/05/12 19:20:17 Greeting: Hello Hello 总结 我们可以使用tls实现gRPC 的加密通信， 从go1.15 开始，go不建议使用CA而是使用SAN证书 ","date":"2024-06-29T21:41:50+08:00","image":"https://images.yixiao9206.cn/blog-images/2024/05/4976a194a8daca00ff6991a866c2ee53.png","permalink":"https://huizhou92.com/zh-cn/p/%E4%BD%BF%E7%94%A8%E8%87%AA%E7%AD%BE%E5%90%8D%E8%AF%81%E4%B9%A6san%E4%B8%BAgrpc%E5%BB%BA%E7%AB%8Btls-%E8%BF%9E%E6%8E%A5/","title":" 使用自签名证书SAN为gRPC建立TLS 连接"},{"content":"网页设计和开发是一个不断进化的领域，设计师和前端开发者们经常面临一个共同的挑战：如何快速、高效地将概念化的设计草图转化为实际可用的 HTML 代码。这一过程不仅耗时而且容易出错，尤其是在将复杂的设计想法具体实现时。在初步设计阶段，往往需要频繁地修改和调整，如果每一次修改都需要手动编写代码，无疑会大大拖慢项目的进度，增加项目成本。\nThis article is first published in the medium MPP plan. If you are a medium user, please follow me in medium. Thank you very much.\n目前我们我们有两种办法解决这个问题，第一种是低代码模式，第二种是使用AI。我个人认为，Ai将会合并低代码模式，目前已经有很多商业公司在做这件事情了，今天的主角是一个在GitHub上有一个超过13k star 的项目⁠draw-a-ui 它是这样描述自己的\nDraw a mockup and generate html for it\ndraw-a-ui 它是基于 tldraw 和 gpt-4-vision api，旨在通过用户绘制的线框图自动生成 HTML 代码。用户只需绘制一个模拟界面的草图，draw-a-ui 就能将其转换为配备 Tailwind CSS 的 HTML 文件，极大缩短从设计到开发的时间。项目目前尚处于开发阶段，但核心功能——将绘图画布的 SVG 转换为 PNG，再将该 PNG 传送给 gpt-4-vision 以指令形式返回单个 HTML 文件——已经完善。\n使用这个项目很简单， 克隆下来，然后配置一下你的openai key就好\n1 2 3 echo \u0026#34;OPENAI_API_KEY=sk-your-key\u0026#34; \u0026gt; .env.local npm install npm run dev 然后你就能 通过 http://localhost:3000 访问了。\nhttps://github.com/SawyerHood/draw-a-ui/blob/main/demo.gif\n它支持在线设计，也支持上传png 图像, 比如我将 medium 主页截图，然后上传上去。等待20s 左右（录屏有加速）,我们就能得到结果。\n尽管目前 draw-a-ui 项目标注为演示用途，并不建议在生产环境中直接使用，目前看来生成的但其背后的理念和技术实现无疑展现了未来开发的趋势。该项目利用最新的人工智能技术（如 GPT-4），为前端开发带来了革命性的工作模式改变。\n我真的很期待这个技术，毕竟我讨厌写css。🐶\n","date":"2024-06-26T18:21:43+08:00","permalink":"https://huizhou92.com/zh-cn/p/%E8%AE%BE%E8%AE%A1%E7%A8%BF%E7%94%9F%E6%88%90%E4%BB%A3%E7%A0%81web%E5%BC%80%E5%8F%91%E7%9A%84%E6%9C%AA%E6%9D%A5/","title":"设计稿生成代码，web开发的未来？"},{"content":"什么是 一致性hash 算法 首先摘抄一段维基百科的定义\n一致哈希 是一种特殊的哈希算法。在使用一致哈希算法后，哈希表槽位数（大小）的改变平均只需要对𝐾/𝑛 个关键字重新映射，其中 𝐾 是关键字的数量，𝑛是槽位数量。然而在传统的哈希表中，添加或删除一个槽位的几乎需要对所有关键字进行重新映射。 \u0026mdash; wikipedia\n分布式系统中, 一致性hash无处不在，CDN，KV，负载均衡等地方都有它的影子，是分布式系统的基石算法之一。一致性hash 有以下几个优点。\n均衡负载： 一致性哈希算法能够将数据在节点上均匀分布。 扩展性： 在一致性哈希算法中，当节点数量增加或减少时，只有部分数据需要重新映射，系统能够进行水平扩展更容易，可以增加节点数量以应对更大的负载需求； 减少数据迁移： 相比传统的哈希算法，一致性哈希算法在节点增减时需要重新映射的数据量较少，可以大幅降低数据迁移的开销，减少系统的不稳定性和延迟；\n本篇文章的目标就是学习一致性hash 算法以及它的简单实现。 This article is first published in the medium MPP plan. If you are a medium user, please follow me in medium. Thank you very much.\n一致性hash算法的原理 基本一致性hash 算法 最基础的一致性 hash 算法就是把节点直接分布到环上，从而划分出值域， key 经过 hash( x ) 之后，落到不同的值域，则由对应的节点处理。最常见的值域空间大小是：2^32 - 1，节点落到这个空间，来划分不同节点所属的值域。如图所示。\nNode A 存储 的 hash 范围为 [0,2^12) .\nNode B 存储 的 hash 范围为 [2^12,2^28) .\nNode C 存储 的 hash 范围为 [2^28,0) .\n上述基本的一致性哈希算法有明显的缺点：\n随机分布节点的方式使得很难均匀的分布哈希值域，从上面可以看出，三个节点存储的数据不均匀。 在动态增加节点后，原先的分布就算均匀也很难再继续保证均匀； 增删节点带来的一个较为严重的缺点是： 当一个节点异常时，该节点的压力全部转移到相邻的一个节点； 当一个新节点加入时只能为一个相邻节点分摊压力； 虚拟节点 Go语言之父 rob pike 曾今说过 计算机领域里，没有什么问题是加一层间接寻址解决不了的. 一致性hash 也是一样。\n如果三个节点 存在不均衡的问题，那么我们就把他虚拟成N个节点。A[a1,a2\u0026hellip;.a1024], 然后将他们映射到hash_ring 上，就是这样样子的。\n每个虚拟节点都有对应的hash区间。负责一段key，然后根据虚拟node 的名字找到对应的物理node读写数据。\n引入虚拟节点后，就完美的解决了上面的三个问题。\n只要我们的虚拟节点足够多，各个节点的数据就能平衡，（⚠️：这个在工程上是有代价的） 如果一个节点宕机了，它的数据会均衡的分布到整个集群所有节点，同理，新增的节点 也能负担所有节点的压力。 Go语言实现 完整的代码：https://github.com/hxzhouh/blog-example/tree/main/Distributed/consistent_hashing\n首先定义一个hash_ring, 使用 crc32.ChecksumIEEE 作为默认的hash function\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 type VirtualNode struct { // 虚拟节点 Hash uint32 Node *Node } type Node struct { // 物理节点 ID string Addr string } type HashRing struct { Nodes map[string]*Node VirtualNodes []VirtualNode. mu sync.Mutex hash HashFunc } func NewHashRing(hash HashFunc) *HashRing { if hash == nil { hash = crc32.ChecksumIEEE } return \u0026amp;HashRing{ Nodes: make(map[string]*Node), VirtualNodes: make([]VirtualNode, 0), hash: hash, } } 我们来看一下怎么添加节点：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 func (hr *HashRing) AddNode(node *Node) { hr.mu.Lock() defer hr.mu.Unlock() hr.Nodes[node.ID] = node for i := 0; i \u0026lt; VirtualNodesPerNode; i++ { virtualNodeID := fmt.Sprintf(\u0026#34;%s-%d\u0026#34;, node.ID, i) hash := hr.hash([]byte(virtualNodeID)) hr.VirtualNodes = append(hr.VirtualNodes, VirtualNode{Hash: hash, Node: node}) } sort.Slice(hr.VirtualNodes, func(i, j int) bool { return hr.VirtualNodes[i].Hash \u0026lt; hr.VirtualNodes[j].Hash }) } 我们每添加一个节点，就要创建对应数量的虚拟节点，并且要保证虚拟节点有序（这样才能查找）\n同样，remove 的时候，也需要删除虚拟节点\n1 2 3 4 5 6 7 8 9 10 11 12 13 func (hr *HashRing) RemoveNode(nodeID string) { hr.mu.Lock() defer hr.mu.Unlock() delete(hr.Nodes, nodeID) virtualNodes := make([]VirtualNode, 0) for _, vn := range hr.VirtualNodes { if vn.Node.ID != nodeID { virtualNodes = append(virtualNodes, vn) } } hr.VirtualNodes = virtualNodes } 查询的时候，我们先找到对应的虚拟节点，然后再根据虚拟节点找到对应的物理节点\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 func (hr *HashRing) GetNode(key string) *Node { hr.mu.Lock() defer hr.mu.Unlock() if len(hr.VirtualNodes) == 0 { return nil } hash := hr.hash([]byte(key)) idx := sort.Search(len(hr.VirtualNodes), func(i int) bool { return hr.VirtualNodes[i].Hash \u0026gt;= hash }) if idx == len(hr.VirtualNodes) { idx = 0 } return hr.VirtualNodes[idx].Node } 最后我们来看看，业务如何使用 这个hash_ring\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 type KVSystem struct { hashRing *HashRing kvStores map[string]*kvstorage.KVStore } func NewKVSystem(nodes int) *KVSystem { hashRing := NewHashRing(crc32.ChecksumIEEE) for i := 0; i \u0026lt; nodes; i++ { // init node node := \u0026amp;Node{ ID: fmt.Sprintf(\u0026#34;Node%d\u0026#34;, i), Addr: fmt.Sprintf(\u0026#34;192.168.1.%d\u0026#34;, i+1), } hashRing.AddNode(node) } kvStores := make(map[string]*kvstorage.KVStore) //init storage for id := range hashRing.Nodes { kvStores[id] = kvstorage.NewKVStore() } return \u0026amp;KVSystem{ hashRing: hashRing, kvStores: kvStores, } } func (kv *KVSystem) Get(key string) (string, bool) { //get value node := kv.hashRing.GetNode(key) return kv.kvStores[node.ID].Get(key) } func (kv *KVSystem) Set(key string, value string) { // set value node := kv.hashRing.GetNode(key) kv.kvStores[node.ID].Set(key, value) } func (kv *KVSystem) Delete(key string) { node := kv.hashRing.GetNode(key) kv.kvStores[node.ID].Delete(key) } // DeleteNode 需要将存储在节点上的数据重新分配。 func (kv *KVSystem) DeleteNode(nodeID string) { allData := kv.kvStores[nodeID].GetAll() kv.hashRing.RemoveNode(nodeID) delete(kv.kvStores, nodeID) for key, value := range allData { kv.Set(key, value) } } func (kv *KVSystem) AddNode() { node := \u0026amp;Node{ ID: fmt.Sprintf(\u0026#34;Node%d\u0026#34;, len(kv.hashRing.Nodes)), Addr: fmt.Sprintf(\u0026#34;192.168.1.%d\u0026#34;, len(kv.hashRing.Nodes)+1), } kv.hashRing.AddNode(node) kv.kvStores[node.ID] = kvstorage.NewKVStore() } 这样我们就实现了一个最简单的基于一致性hash的kv 存储，是不是特别简单? 但是它却支撑了我们整个网络世界的运转。\n参考资料 Consistent_hashing\n本文长期连接 如果您觉得我的博客对你有帮助，请通过 RSS订阅我。 或者在X上关注我。 如果您有Medium账号，能给我个关注嘛？我的文章第一时间都会发布在Medium。 ","date":"2024-06-19T21:22:15+08:00","image":"https://images.yixiao9206.cn/blog-images/2024/06/f3b53488c2407a75d85406be58526010.png","permalink":"https://huizhou92.com/zh-cn/p/%E5%88%86%E5%B8%83%E5%BC%8F%E5%9F%BA%E7%9F%B3%E7%AE%97%E6%B3%951-%E4%B8%80%E8%87%B4%E6%80%A7hash/","title":"分布式基石算法1:  一致性hash"},{"content":"在 go语言中，正常的 struct 一定是需要占用一块内存的，但是有一种特殊情况，如果是一个空struct，那么它的大小为0. 这是怎么回事，空struct 又有什么用呢？\n1 2 3 4 5 6 7 8 9 10 11 12 13 type Test struct { A int B string } func main() { fmt.Println(unsafe.Sizeof(new(Test))) fmt.Println(unsafe.Sizeof(struct{}{})) } /* 8 0 */ Empty Struct 的 秘密 特殊变量：zerobase 空结构体是没有内存大小的结构体。这句话是没有错的，但是更准确的来说，其实是有一个特殊起点的，那就是 zerobase 变量，这是一个 uintptr 全局变量，占用 8 个字节。当在任何地方定义无数个 struct {} 类型的变量，编译器都只是把这个 zerobase 变量的地址给出去。换句话说，在 golang 里面，涉及到所有内存 size 为 0 的内存分配，那么就是用的同一个地址 \u0026amp;zerobase 。\n例如\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 // https://go.dev/play/p/WNxfXviET_i package main import \u0026#34;fmt\u0026#34; type emptyStruct struct {} func main() { a := struct{}{} b := struct{}{} c := emptyStruct{} fmt.Printf(\u0026#34;%p\\n\u0026#34;, \u0026amp;a) fmt.Printf(\u0026#34;%p\\n\u0026#34;, \u0026amp;b) fmt.Printf(\u0026#34;%p\\n\u0026#34;, \u0026amp;c) } // 0x58e360 // 0x58e360 // 0x58e360 空结构体的变量的内存地址都是一样的。这是因为编译器在编译期间，遇到 struct {} 这种特殊类型的内存分配，会给他分配\u0026amp;zerobase，这个代码逻辑是在 mallocgc 函数里面：\n1 2 3 4 5 6 7 //go:linkname mallocgc func mallocgc(size uintptr, typ *_type, needzero bool) unsafe.Pointer { .... if size == 0 { return unsafe.Pointer(\u0026amp;zerobase) } ..... 这就是Empty struct 的秘密有了这个特殊的 变量，我们利用它可以完成很多功能。\nEmpty struct 与内存对其\n一般情况下，struct 中包含 empty struct ，这个字段是不占用内存空间的，但是有一种情况是特殊的，那就是 empty struct 位于最后一位，它会触发内存对齐 。\n比如\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 //https://go.dev/play/p/HcxlywljovS type A struct { x int y string z struct{} } type B struct { x int z struct{} y string } func main() { println(unsafe.Alignof(A{})) println(unsafe.Alignof(B{})) println(unsafe.Sizeof(A{})) println(unsafe.Sizeof(B{})) } /** 8 8 32 24 **/ 因为如果有指针指向该字段, 返回的地址将在结构体之外，如果此指针一直存活不释放对应的内存，就会有内存泄露的问题（该内存不因结构体释放而释放）。\n因此，当 struct{} 作为其他 struct 最后一个字段时，需要填充额外的内存保证安全,如果 empty struct 在开始位置，或者中间位置，那么它的地址是下一个变量的地址\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 type A struct { x int y string z struct{} } type B struct { x int z struct{} y string } func main() { a := A{} b := B{} fmt.Printf(\u0026#34;%p\\n\u0026#34;, \u0026amp;a.y) fmt.Printf(\u0026#34;%p\\n\u0026#34;, \u0026amp;a.z) fmt.Printf(\u0026#34;%p\\n\u0026#34;, \u0026amp;b.y) fmt.Printf(\u0026#34;%p\\n\u0026#34;, \u0026amp;b.z) } /** 0x1400012c008 0x1400012c018 0x1400012e008 0x1400012e008 **/ Empty 的使用场景 空结构体 struct{ } 为什么会存在的核心理由就是为了节省内存。当你需要一个结构体，但是却丝毫不关系里面的内容，那么就可以考虑空结构体。golang 核心的几个复合结构 map ，chan ，slice 都能结合 struct{} 使用。\nmap \u0026amp; struct{} 1 2 3 4 5 6 // 创建 map m := make(map[int]struct{}) // 赋值 m[1] = struct{}{} // 判断 key 键存不存在 _, ok := m[1] chan \u0026amp; struct{} channel 和 struct{} 结合是一个最经典的场景，struct{} 通常作为一个信号来传输，并不关注其中内容。chan 的分析在前几篇文章有详细说明。chan 本质的数据结构是一个管理结构加上一个 ringbuffer ，如果 struct{} 作为元素的话，ringbuffer 就是 0 分配的。\nchan 和 struct{} 结合基本只有一种用法，就是信号传递，空结构体本身携带不了值，所以也只有这一种用法啦，一般来说，配合 no buffer 的 channel 使用。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 // 创建一个信号通道 waitc := make(chan struct{}) // ... goroutine 1: // 发送信号: 投递元素 waitc \u0026lt;- struct{} // 发送信号: 关闭 close(waitc) goroutine 2: select { // 收到信号，做出对应的动作 case \u0026lt;-waitc: } 这种场景我们思考下，是否一定是非 struct{} 不可？其实不是，而且也不多这几个字节的内存，所以这种情况真的就只是不关心 chan 的元素值而已，所以才用的 struct{}。\n总结 空结构体也是结构体，只是 size 为 0 的类型而已； 所有的空结构体都有一个共同的地址：zerobase 的地址； 我们可以利用empty struct 不占用内存的特性，来优化代码，比如利用map 实现set 以及 chan 等。 参考链接 The empty struct, Dave Cheney Go 最细节篇— struct{} 空结构体究竟是啥？ ","date":"2024-06-17T23:18:02+08:00","image":"https://images.yixiao9206.cn/blog-images/2024/06/c78d096394f1791445b7c10f88dd0378.jpg","permalink":"https://huizhou92.com/zh-cn/p/go%E9%AB%98%E6%80%A7%E8%83%BD%E7%BC%96%E7%A8%8B-ep1-empty-struct/","title":"Go高性能编程 EP1 : empty struct"},{"content":"原文链接how-quic-is-displacing-tcp-for-speed\n引言 在过去的三十年中，HTTP（超文本传输协议）一直是互联网的支柱。我们能够浏览网页、下载文件、流式传输电影等，都是因为HTTP。这个协议多年来不断发展，见证了重大的改进。\nHTTP协议是一个应用层协议，工作在TCP（传输控制协议）之上。TCP协议有一些限制，导致网络应用程序响应性较差。\n谷歌开发了一种改变游戏规则的传输协议QUIC，以克服TCP的缺点。QUIC几年前被标准化并加入到IETF（互联网工程任务组）。\n在过去几年中，QUIC的采用呈指数级增长。大多数科技公司，如谷歌、Facebook、Pinterest等，已经开始采用使用QUIC作为传输层的HTTP/3.0。这些公司在使用HTTP/3.0和QUIC后，其网站性能有了显著提升。\n让我们开始我们的旅程，了解QUIC如何取代TCP。我们首先将了解一些基本的TCP和UDP网络概念。之后，我们将看看HTTP的演变，以及每个版本是如何克服前一个版本的限制的。然后，我们将了解QUIC是什么以及它的工作原理。我们将探讨为什么QUIC的性能比TCP高。\nTCP和UDP是如何工作的？ TCP（传输控制协议）和UDP（用户数据报协议）是传输层协议。这些协议管理互联网数据包流向和来自任何电子设备的过程。让我们详细了解这两个协议是如何工作的。\nTCP TCP是一种基于连接的协议。客户端与服务器建立连接，然后发送数据。TCP连接是通过一种称为三次握手的机制建立的。下图展示了三次握手过程：\n这个过程包括三个步骤：\nSYN - 客户端向服务器发送一个SYN数据包。\nACK - 服务器接收到SYN后，通过ACK数据包向客户端发送确认。\nSYN-ACK - 客户端收到服务器的ACK数据包后，最终通过SYN-ACK向服务器发送确认。\nTCP是一个有状态和可靠的协议。它保证从一台设备到另一台设备的所有数据包的传输。此外，它允许客户端和服务器使用相同的连接进行通信。\nUDP UDP是一种无连接协议。与TCP不同，客户端和服务器之间没有三次握手。客户端向服务器发送数据包，不等待服务器的确认。\nUDP不能保证100%的数据包传输。数据包可能会丢失，可能无法到达另一台设备。UDP不像TCP那样可靠。\n由于没有初始握手，UDP比TCP快得多。出于性能原因，UDP主要用于流式数据应用程序，如音乐/视频。\n这是一个流行的互联网梗，对TCP/UDP进行了调侃：\n到目前为止，我们已经了解了TCP和UDP协议是如何工作的。现在让我们探索HTTP协议，这是一个应用层协议。\nHTTP的演变 由Tim Berners-Lee在CERN开发的HTTP的第一个版本是在1989年。从那时起，该协议经历了多次优化和性能改进。大多数现代设备使用HTTP 1.1/ HTTP 2.0和HTTP 3.0。让我们回顾一下HTTP的历史，了解协议经历的重大变化。\nHTTP/1.0 在最初的HTTP/0.9版本之后，HTTP/1.0开始支持头、请求体、文本文件等。客户端每次使用HTTP从服务器获取数据时，都必须创建一个TCP连接。这导致在建立连接时显著浪费资源。\nHTTP/1.1 这个协议增加了对重用客户端和服务器之间现有TCP连接以获取新数据的支持。这是通过HTTP头keep-alive实现的。\n如果客户端想要获取10个JavaScript文件，那么它将与服务器建立一个连接。然后，它将重用相同的连接来获取这10个文件，而不是为每个文件创建一个新连接。\n这导致资源浪费减少和性能提升，因为它避免了创建多余的连接。然而，一个主要的缺点是众所周知的_队头阻塞_问题。\n下图展示了_队头阻塞_问题。\n让我们通过一个例子来理解这个概念。如上图所示，你有3个文件 - 图像、文本和视频。视频文件体积较大，传输时间会更长。由于视频文件传输时间较长，它会阻塞图像和文本文件的发送。\nHTTP/2.0 HTTP 2.0通过多路复用解决了_队头阻塞_问题。通过多路复用，多个文件可以通过同一个TCP连接发送。\n这导致了性能提升，并解决了应用层面的队头阻塞问题。然而，在TCP层面，如果发生数据包丢失，它必须等待数据包重传。\n多路复用解决方案在数据包丢失的情况下并不像预期的那样有效。实际上，如果数据包丢失超过5%，HTTP 1.1的性能比HTTP 2.0更好。_队头阻塞_问题从应用层转移到了传输层。\n下图展示了单个数据包丢失如何导致多个流延迟：\n当一个数据包丢失时，TCP将其后续数据包存储在其缓冲区中，直到收到丢失的数据包。然后TCP使用重传来获取丢失的数据包。HTTP无法看到TCP重传。因此，在这种情况下，不同的流会看到传输延迟。\n什么是QUIC？ 在过去的几个部分中，我们看到了TCP有一些固有的限制，如三次握手和队头阻塞。这些限制可以通过增强TCP或用新协议替换TCP来解决。\n尽管增强TCP很简单，但TCP存在于最低层，与操作系统紧密耦合。简单来说，TCP的代码存在于内核层而不是用户空间。考虑到大量的设备，实施内核空间的更改将需要大量的时间才能到达所有用户。\n因此，谷歌提出了一种新的协议QUIC，作为TCP的替代品。像TCP一样，QUIC也是一个传输层协议。然而，它位于用户空间而不是内核空间。这使得它容易更改和增强，与TCP不同。\nQUIC在UDP之上工作。它通过使用UDP克服了TCP的限制。它只是一个在UDP之上的层或包装器。该包装器添加了TCP的功能，如拥塞控制、数据包重传、多路复用等。它内部使用UDP，并在其上添加了TCP的最佳功能。\n下图显示了QUIC如何适应网络栈：\n现在我们已经了解了QUIC的基础知识，让我们深入了解这个协议的工作原理。\nQUIC是如何工作的？ QUIC握手 QUIC在UDP上工作，它不需要经过三次握手过程。三次握手过程增加了额外的开销，增加了延迟。因此，QUIC通过减少连接延迟来提高性能。\n在TCP的情况下，还有一个额外的用于TLS的握手，这也增加了延迟。QUIC将TLS握手和QUIC握手合并为一个调用。它优化了握手过程并提高了性能。\n可靠性 您可能会想“既然QUIC在UDP上工作，数据包会丢失吗？”。答案是不。QUIC在UDP堆栈上添加了可靠性。它实现了数据包重传，以防它没有收到必要的数据包。例如：如果服务器没有收到来自客户端的第5个数据包，协议将检测到它并要求客户端重新发送相同的数据包。\n多路复用 与TCP类似，QUIC也实现了多路复用。客户端可以使用单个通道同时传输多个文件。QUIC为每个流（传输的文件）创建一个UUID。它使用UUID来识别流。然后，多个流通过单个通道发送。\n下图展示了QUIC中多路复用是如何工作的：\nQUIC还通过其多路复用解决了TCP面临的队头阻塞问题。如果一个流遭受数据包丢失，只有该流会受到影响。QUIC中的流是独立的，不会影响彼此的工作。\n安全性 此外，QUIC 还支持 TLS 1.3（传输层安全性）。这保证了数据的安全性和保密性。TLS 加密了 QUIC 协议的大部分内容，例如数据包编号和连接关闭信号。\n为什么选择QUIC？ 降低延迟 - QUIC通过将TLS握手与连接建立结合起来，最小化了延迟。这也被称为0-RTT（零往返时间）。它实现了更快的连接建立，并提高了网络应用程序的性能。 多路复用 - 通过多路复用，QUIC可以在单个通道上发送多个数据流。这对于下载多个文件（如图像、JavaScript、CSS等）的客户端应用程序非常有用。 连接迁移 - 使用QUIC，您可以在不出现任何问题的情况下从一种网络接口切换到另一种（例如从Wi-Fi切换到移动数据）。这对于移动设备很重要，并提高了用户体验。 提高安全性 - QUIC使用TLS 1.3，提供更好的安全性。此外，它还加密了协议的大部分，与只加密HTTP有效载荷的TCP和TLS不同。与TCP相比，它更能抵御安全攻击。 广泛支持 - 自其诞生以来，它的采用率一直在上升。这进一步加强了它的有效性。 HTTP/3和QUIC HTTP/3是超文本传输协议（HTTP）的最新版本。它内部使用QUIC而不是TCP。它旨在为现代网络提供更有效和安全的基础。它拥有QUIC提供的所有优势。\nHTTP/3由IETF标准化。今天，很大一部分互联网流量依赖于HTTP/3。以下是显示HTTP/3采用率的图表：\n从上述图表中可以看出，采用率已经飙升至30%，并逐渐超越了HTTP/1.1。按照目前的发展速度，HTTP/3.0将在未来几年逐渐超越HTTP/2.0。\n结论 自三十年前HTTP诞生以来，互联网已经走过了漫长的道路。HTTP的演变使在线体验更加高效和响应迅速。随着现代应用程序需求的增长，我们意识到了底层协议如TCP的固有限制。\n谷歌开发了改变游戏规则的协议QUIC。它利用UDP并解决了TCP的所有不足。降低延迟、多路复用、增强安全性和连接迁移是QUIC的一些显著特点。QUIC带来的创新解决了队头阻塞等问题。\n像谷歌和Facebook这样的大型科技公司通过在HTTP/3中采用QUIC，在性能上取得了显著提升。随着采用率的上升和日益增长的支持，HTTP/3将成为互联网通信的标准。在未来几年，互联网将发展并过渡到HTTP/3，以实现效率、可靠性和性能。\n参考文献 TCP VS UDP 梗 为什么HTTP/3.0正在吞噬世界？ Pinterest现在使用HTTP/3.0 与谷歌对等 - QUIC ","date":"2024-06-14T09:38:42+08:00","image":"https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd0e30c17-275b-4a94-8883-74c546ead5e5_5955x3350.jpeg","permalink":"https://huizhou92.com/zh-cn/p/%E8%AF%91quic-%E5%A6%82%E4%BD%95%E5%9C%A8%E9%80%9F%E5%BA%A6%E5%92%8C%E5%AE%89%E5%85%A8%E6%80%A7%E6%96%B9%E9%9D%A2%E5%8F%96%E4%BB%A3-tcp/","title":"【译】QUIC 如何在速度和安全性方面取代 TCP？"},{"content":"对比 fastjson，gjson，jsonparser 的性能以及优缺点。\n这篇文章深入源码分析一下在 Go 中标准库是如何解析 JSON 的，然后再看看有哪些比较流行的 Json 解析库，以及这些库都有什么特点，在什么场景下能更好的帮助我们进行开发。\nThis article is first published in the medium MPP plan. If you are a medium user, please follow me on the medium. Thank you very much.\n其实本来我是没打算去看 JSON 库的性能问题的，但是最近我对我的项目做了一次 pprof，从下面的火焰图中可以发现在业务逻辑处理中，有一半多的性能消耗都是在 JSON 解析过程中，所以就有了这篇文章。\n这篇文章深入源码分析一下在 Go 中标准库是如何解析 JSON 的，然后再看看有哪些比较流行的 Json 解析库，以及这些库都有什么特点，在什么场景下能更好的帮助我们进行开发。\n主要介绍分析以下几个库（2024-06-13）：\n库名 Star 标准库 JSON Unmarshal valyala/fastjson 2.2 k tidwall/gjson 13.8 k buger/jsonparser 5.4 k 标准库 JSON Unmarshal 1 func Unmarshal(data []byte, v interface{}) 官方的 JSON 解析库需要传两个参数，一个是需要被序列化的对象，另一个是表示这个对象的类型。\n在真正执行 JSON 解析之前会调用 reflect.ValueOf来获取参数 v 的反射对象。然后会获取到传入的 data 对象的开头非空字符来界定该用哪种方式来进行解析。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 func (d *decodeState) value(v reflect.Value) error { switch d.opcode { default: panic(phasePanicMsg) // 数组 case scanBeginArray: ... // 结构体或map case scanBeginObject: ... // 字面量，包括 int、string、float 等 case scanBeginLiteral: ... } return nil } 如果被解析的对象是以[开头，那么表示这是个数组对象会进入到 scanBeginArray 分支；如果是以{开头，表明被解析的对象是一个结构体或 map，那么进入到 scanBeginObject 分支 等等。\n小结 通过看 Unmarshal 源码中可以看到其中使用了大量的反射来获取字段值，如果是多层嵌套的 JSON 的话，那么还需要递归进行反射获取值，可想而知性能是非常差的了。\n但是如果对性能不是那么看重的话，直接使用它其实是一个非常好的选择，功能完善的同时并且官方也一直在迭代优化，说不定在以后的版本中性能也会得到质的飞跃。并且他应该是唯一一个可以直接把JSON对象转成 go struct 的。\nfastjson 这个库的特点和它的名字一样就是快，它的介绍页是这么说的：\nFast. As usual, up to 15x faster than the standard encoding/json.\n它的使用也是非常的简单,如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 func main() { var p fastjson.Parser v, _ := p.Parse(`{ \u0026#34;str\u0026#34;: \u0026#34;bar\u0026#34;, \u0026#34;int\u0026#34;: 123, \u0026#34;float\u0026#34;: 1.23, \u0026#34;bool\u0026#34;: true, \u0026#34;arr\u0026#34;: [1, \u0026#34;foo\u0026#34;, {}] }`) fmt.Printf(\u0026#34;foo=%s\\n\u0026#34;, v.GetStringBytes(\u0026#34;str\u0026#34;)) fmt.Printf(\u0026#34;int=%d\\n\u0026#34;, v.GetInt(\u0026#34;int\u0026#34;)) fmt.Printf(\u0026#34;float=%f\\n\u0026#34;, v.GetFloat64(\u0026#34;float\u0026#34;)) fmt.Printf(\u0026#34;bool=%v\\n\u0026#34;, v.GetBool(\u0026#34;bool\u0026#34;)) fmt.Printf(\u0026#34;arr.1=%s\\n\u0026#34;, v.GetStringBytes(\u0026#34;arr\u0026#34;, \u0026#34;1\u0026#34;)) } // Output: // foo=bar // int=123 // float=1.230000 // bool=true // arr.1=foo 使用 fastjson 首先要将被解析的 JSON 串交给 Parser 解析器进行解析，然后通过 Parse 方法返回的对象来获取。如果是嵌套对象可以直接在 Get 方法传参的时候传入相应的父子 key 即可。\n分析 fastjson 在设计上和标准库 Unmarshal 不同的是，它将 JSON 解析划分为两部分：Parse、Get。\nParse 负责将 JSON 串解析成为一个结构体并返回，然后通过返回的结构体来获取数据。在 Parse 解析的过程是无锁的，所以如果想要在并发地调用 Parse 进行解析需要使用 ParserPool\nfastjson 是从上往下依次遍历 JSON ，然后解析好的数据存放在 Value 结构体中：\n1 type Value struct { o Object a []*Value s string t Type } 这个结构体非常简成：\no Object：表示被解析的结构是一个对象； a []*Value：表示表示被解析的结构是个数组； s string：如果被解析的结构不是对象也不是数组，那么其他类型的值会以字符串的形式存放在这个字段中； t Type：表示这个结构的类型，有 TypeObject、TypeArray、TypeString、TypeNumber等。 1 type Object struct { kvs []kv keysUnescaped bool } type kv struct { k string v *Value } 这个结构存放对象的递归结构。如果把上面例子中的 JSON 串解析完毕之后就是这样一个结构：\n代码 在代码实现上，由于没有了反射部分的代码，所以整个解析过程变得非常的清爽。我们直接看看主干部分的解析：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 func parseValue(s string, c *cache, depth int) (*Value, string, error) { if len(s) == 0 { return nil, s, fmt.Errorf(\u0026#34;cannot parse empty string\u0026#34;) } depth++ // 最大深度的json串不能超过MaxDepth if depth \u0026gt; MaxDepth { return nil, s, fmt.Errorf(\u0026#34;too big depth for the nested JSON; it exceeds %d\u0026#34;, MaxDepth) } // 解析对象 if s[0] == \u0026#39;{\u0026#39; { v, tail, err := parseObject(s[1:], c, depth) if err != nil { return nil, tail, fmt.Errorf(\u0026#34;cannot parse object: %s\u0026#34;, err) } return v, tail, nil } // 解析数组 if s[0] == \u0026#39;[\u0026#39; { ... } // 解析字符串 if s[0] == \u0026#39;\u0026#34;\u0026#39; { ... } ... return v, tail, nil } parseValue 会根据字符串的第一个非空字符来判断要解析的类型。这里用一个对象类型来做解析：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 func parseObject(s string, c *cache, depth int) (*Value, string, error) { ... o := c.getValue() o.t = TypeObject o.o.reset() for { var err error // 获取Ojbect结构体中的 kv 对象 kv := o.o.getKV() ... // 解析 key 值 kv.k, s, err = parseRawKey(s[1:]) ... // 递归解析 value 值 kv.v, s, err = parseValue(s, c, depth) ... // 遇到 ，号继续往下解析 if s[0] == \u0026#39;,\u0026#39; { s = s[1:] continue } // 解析完毕 if s[0] == \u0026#39;}\u0026#39; { return o, s[1:], nil } return nil, s, fmt.Errorf(\u0026#34;missing \u0026#39;,\u0026#39; after object value\u0026#34;) } } parseObject 函数也非常简单，在循环体中会获取 key 值，然后调用 parseValue 递归解析 value 值，从上往下依次解析 JSON 对象，直到最后遇到 }退出。\n小结 通过上面的分析可以知道 fastjson 在实现上比标准库简单不少，性能也高上不少。使用 Parse 解析好 JSON 树之后可以多次反复使用，避免了需要反复解析进而提升性能。\n但是它的功能是非常的简陋的，没有常用的如 JSON 转 Struct 或 JSON 转 map 的操作。如果只是想简单的获取 JSON 中的值，那么使用这个库是非常方便的，但是如果想要把 JSON 值转化成一个结构体就需要自己动手一个个设值了。\nGJSON GJSON 在我的测试中，虽然性能是没有 fastjson 这么极致，但是功能是非常完善，性能也是相当 OK 的，下面先简单介绍一下 GJSON 的功能。\nGJSON 的使用是和 fastjson 差不多的，也是非常的简单，只要在参数中传入 json 串以及需要获取的值即可：\n1 2 json := `{\u0026#34;name\u0026#34;:{\u0026#34;first\u0026#34;:\u0026#34;li\u0026#34;,\u0026#34;last\u0026#34;:\u0026#34;dj\u0026#34;},\u0026#34;age\u0026#34;:18}` lastName := gjson.Get(json, \u0026#34;name.last\u0026#34;) 除了这个功能以外还可以进行简单的模糊匹配，支持在键中包含通配符*和?，*匹配任意多个字符，?匹配单个字符，如下：\n1 2 3 4 5 6 7 json := `{ \u0026#34;name\u0026#34;:{\u0026#34;first\u0026#34;:\u0026#34;Tom\u0026#34;, \u0026#34;last\u0026#34;: \u0026#34;Anderson\u0026#34;}, \u0026#34;age\u0026#34;: 37, \u0026#34;children\u0026#34;: [\u0026#34;Sara\u0026#34;, \u0026#34;Alex\u0026#34;, \u0026#34;Jack\u0026#34;] }` fmt.Println(\u0026#34;third child*:\u0026#34;, gjson.Get(json, \u0026#34;child*.2\u0026#34;)) fmt.Println(\u0026#34;first c?ild:\u0026#34;, gjson.Get(json, \u0026#34;c?ildren.0\u0026#34;)) child*.2：首先child*匹配children，.2读取第 3 个元素； c?ildren.0：c?ildren匹配到children，.0读取第一个元素； 除了模糊匹配以外还支持修饰符操作：\n1 2 3 4 5 6 json := `{ \u0026#34;name\u0026#34;:{\u0026#34;first\u0026#34;:\u0026#34;Tom\u0026#34;, \u0026#34;last\u0026#34;: \u0026#34;Anderson\u0026#34;}, \u0026#34;age\u0026#34;: 37, \u0026#34;children\u0026#34;: [\u0026#34;Sara\u0026#34;, \u0026#34;Alex\u0026#34;, \u0026#34;Jack\u0026#34;] }` fmt.Println(\u0026#34;third child*:\u0026#34;, gjson.Get(json, \u0026#34;children|@reverse\u0026#34;)) children|@reverse 先读取数组children，然后使用修饰符@reverse翻转之后返回，输出。\n1 nestedJSON := `{\u0026#34;nested\u0026#34;: [\u0026#34;one\u0026#34;, \u0026#34;two\u0026#34;, [\u0026#34;three\u0026#34;, \u0026#34;four\u0026#34;]]}` fmt.Println(gjson.Get(nestedJSON, \u0026#34;nested|@flatten\u0026#34;)) @flatten将数组nested的内层数组平坦到外层后返回：\n1 [\u0026#34;one\u0026#34;,\u0026#34;two\u0026#34;,\u0026#34;three\u0026#34;, \u0026#34;four\u0026#34;] 等等还有一些其他有意思的功能，大家可以去查阅一下官方文档。\n分析 GJSON 的 Get 方法参数是由两部分组成，一个是 JSON 串，另一个叫做 Path 表示需要获取的 JSON 值的匹配路径。\n在 GJSON 中因为要满足很多的定义的解析场景，所以解析是分为两部分的，需要先解析好 Path 之后才去遍历解析 JSON 串。\n在解析过程中如果遇到可以匹配上的值，那么会直接返回，不需要继续往下遍历，如果是匹配多个值，那么会一直遍历完整个 JSON 串。如果遇到某个 Path 在 JSON 串中匹配不到，那么也是需要遍历完整个 JSON 串。\n在解析的过程中也不会像 fastjson 一样将解析的内容保存在一个结构体中，可以反复的利用。所以当调用 GetMany 想要返回多个值的时候，其实也是需要遍历 JSON 串多次，因此效率会比较低。\n除此之外，在解析 JSON 的时候并不会对它进行校验，即使这个放入的字符串不是个 JSON 也会照样解析，所以需要用户自己去确保放入的是 JSON 。\n代码 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 func Get(json, path string) Result { // 解析 path if len(path) \u0026gt; 1 { ... } var i int var c = \u0026amp;parseContext{json: json} if len(path) \u0026gt;= 2 \u0026amp;\u0026amp; path[0] == \u0026#39;.\u0026#39; \u0026amp;\u0026amp; path[1] == \u0026#39;.\u0026#39; { c.lines = true parseArray(c, 0, path[2:]) } else { // 根据不同的对象进行解析,这里会一直循环，直到找到 \u0026#39;{\u0026#39; 或 \u0026#39;[\u0026#39; for ; i \u0026lt; len(c.json); i++ { if c.json[i] == \u0026#39;{\u0026#39; { i++ parseObject(c, i, path) break } if c.json[i] == \u0026#39;[\u0026#39; { i++ parseArray(c, i, path) break } } } if c.piped { res := c.value.Get(c.pipe) res.Index = 0 return res } fillIndex(json, c) return c.value } Get 方法里面可以看到有很长一串的代码是用来解析各种 Path，然后一个 for 循环一直遍历 JSON 直到找到 ‘{‘ 或 ‘[‘，然后才进行相应的逻辑进行处理。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 func parseObject(c *parseContext, i int, path string) (int, bool) { var pmatch, kesc, vesc, ok, hit bool var key, val string rp := parseObjectPath(path) if !rp.more \u0026amp;\u0026amp; rp.piped { c.pipe = rp.pipe c.piped = true } // 嵌套两个 for 循环 寻找 key 值 for i \u0026lt; len(c.json) { for ; i \u0026lt; len(c.json); i++ { if c.json[i] == \u0026#39;\u0026#34;\u0026#39; { i++ var s = i for ; i \u0026lt; len(c.json); i++ { if c.json[i] \u0026gt; \u0026#39;\\\\\u0026#39; { continue } // 找到 key 值跳转到 parse_key_string_done if c.json[i] == \u0026#39;\u0026#34;\u0026#39; { i, key, kesc, ok = i+1, c.json[s:i], false, true goto parse_key_string_done } ... } key, kesc, ok = c.json[s:], false, false // 直接break parse_key_string_done: break } if c.json[i] == \u0026#39;}\u0026#39; { return i + 1, false } } if !ok { return i, false } // 校验是否是模糊匹配 if rp.wild { if kesc { pmatch = match.Match(unescape(key), rp.part) } else { pmatch = match.Match(key, rp.part) } } else { if kesc { pmatch = rp.part == unescape(key) } else { pmatch = rp.part == key } } // 解析 value hit = pmatch \u0026amp;\u0026amp; !rp.more for ; i \u0026lt; len(c.json); i++ { switch c.json[i] { default: continue case \u0026#39;\u0026#34;\u0026#39;: i++ i, val, vesc, ok = parseString(c.json, i) if !ok { return i, false } if hit { if vesc { c.value.Str = unescape(val[1 : len(val)-1]) } else { c.value.Str = val[1 : len(val)-1] } c.value.Raw = val c.value.Type = String return i, true } case \u0026#39;{\u0026#39;: if pmatch \u0026amp;\u0026amp; !hit { i, hit = parseObject(c, i+1, rp.path) if hit { return i, true } } else { i, val = parseSquash(c.json, i) if hit { c.value.Raw = val c.value.Type = JSON return i, true } } ... break } } return i, false } 在上面看 parseObject 这段代码的时候其实不是想让大家学习如何解析 JSON，以及遍历字符串，而是想要让大家看看一个 bad case 是怎样的。for 循环一层套一层，if 一个接以一个看得我 San 值狂掉，这片代码大家是不是看起来很眼熟？是不是有点像工作中遇到的某个同事写的代码？\n小结 优点：\n性能相对标准库来说还算不错； 可玩性高，可以各种检索、自定义返回值，这点非常方便；\n缺点： 不会校验 JSON 的正确性； 代码的 Code smell 很重。 需要注意的是，如果需要解析返回 JSON 的值的话，GetMany 函数会根据指定的 key 值来一次次遍历 JSON 字符串，解析为 map 可以减少遍历次数。\njsonparser 这也是一个比较热门，并且号称高性能，能比标准库快十倍的解析速度。\n分析 jsonparser 也是传入一个 JSON 的 byte 切片，以及可以通过传入多个 key 值来快速定位到相应的值，并返回。\n和 GJSON 一样，在解析过程中是不会像 fastjson 一样有个数据结构缓存已解析过的 JSON字符串，但是遇到需要解析多个值的情况可以使用 EachKey 函数来解析多个值，只需要遍历一次 JSON字符串即可实现获取多个值的操作。\n如果遇到可以匹配上的值，那么会直接返回，不需要继续往下遍历，如果是匹配多个值，那么会一直遍历完整个 JSON 串。如果遇到某个 Path 在 JSON 串中匹配不到，那么也是需要遍历完整个 JSON 串。\n并且在遍历 JSON 串的时候通过循环的方式来减少递归的使用，减少了调用栈的深度，一定程度上也是可以提升性能。\n在功能性上 ArrayEach、ObjectEach、EachKey 等三个函数都可以传入一个自定义的函数，通过函数来实现个性化的需求，使得实用性大大增强。\n对于 jsonparser 来说，代码没什么可分析的，非常的清晰，感兴趣的可以自己去看看。\n小结 对于 jsonparser 来说相对标准库比较而言性能如此高的原因可以总结为：\n使用 for 循环来减少递归的使用； 相比标准库而言没有使用反射； 在查找相应的 key 值找到了便直接退出，可以不用继续往下递归； 所操作的 JSON 串都是已被传入的，不会去重新再去申请新的空间，减少了内存分配； 除此之外在 api 的设计上也是非常的实用，ArrayEach、ObjectEach、EachKey 等三个函数都可以传入一个自定义的函数在实际的业务开发中解决了不少问题。\n缺点也是非常的明显，不能对 JSON 进行校验，即使这个 传入的不是 JSON。\n性能对比 解析小 JSON 字符串\n解析一个结构简单，大小约 190 bytes 的字符串\n库名 操作 每次迭代耗时 占用内存数 分配内存次数 性能 标准库 解析为map 724 ns/op 976 B/op 51 allocs/op 慢 解析为struct 297 ns/op 256 B/op 5 allocs/op 一般 fastjson get 68.2 ns/op 0 B/op 0 allocs/op 最快 parse 35.1 ns/op 0 B/op 0 allocs/op 最快 GJSON 转map 255 ns/op 1009 B/op 11 allocs/op 一般 get 232 ns/op 448 B/op 1 allocs/op 一般 jsonparser get 106 ns/op 232 B/op 3 allocs/op 快 解析中等大小 JSON 字符串\n解析一个具有一定复杂度，大小约 2.3KB 的字符串\n库名 操作 每次迭代耗时 占用内存数 分配内存次数 性能 标准库 解析为map 4263 ns/op 10212 B/op 208 allocs/op 慢 解析为struct 4789 ns/op 9206 B/op 259 allocs/op 慢 fastjson get 285 ns/op 0 B/op 0 allocs/op 最快 parse 302 ns/op 0 B/op 0 allocs/op 最快 GJSON 转map 2571 ns/op 8539 B/op 83 allocs/op 一般 get 1489 ns/op 448 B/op 1 allocs/op 一般 jsonparser get 878 ns/op 2728 B/op 5 allocs/op 快 解析大 JSON 字符串\n解析复杂度比较高，大小约 2.2MB 的字符串\n库名 操作 每次迭代耗时 占用内存数 分配内存次数 性能 标准库 解析为map 2292959 ns/op 5214009 B/op 95402 allocs/op 慢 解析为struct 1165490 ns/op 2023 B/op 76 allocs/op 一般 fastjson get 368056 ns/op 0 B/op 0 allocs/op 快 parse 371397 ns/op 0 B/op 0 allocs/op 快 GJSON 转map 1901727 ns/op 4788894 B/op 54372 allocs/op 一般 get 1322167 ns/op 448 B/op 1 allocs/op 一般 jsonparser get 233090 ns/op 1788865 B/op 376 allocs/op 最快 总结 在这次的分享过程中，我找了很多 JSON 的解析库分别进行对比分析，可以发现这些高性能的解析库基本上都有一些共同的特点：\n不使用反射； 通过遍历 JSON 字符串的字节来挨个解析； 尽量使用传入的 JSON 字符串来进行解析遍历，减少内存分配； 牺牲了一定的兼容性； 尽管如此，但是功能上，每个都有一定的特色 fastjson 的 api 操作最简单；GJSON 提供了模糊查找的功能，自定义程度最高；jsonparser 在实现高性能的解析过程中，还可以插入回调函数执行，提供了一定程度上的便利。\n综上，回到文章的开头中，对于我自己的业务来说，业务也只是简单的解析 http 请求返回的 JSON 串的部分字段，并且字段都是确定的，无需搜索功能，但是有时候需要做一些自定义的操作，所以对我来说 jsonparser 是最合适的。\n所以如果各位对性能有一定要求，不妨结合自己的业务情况来挑选一款 JSON 解析器。\nReference https://github.com/buger/jsonparser\nhttps://github.com/tidwall/gjson\nhttps://github.com/valyala/fastjson\nhttps://github.com/json-iterator/go\nhttps://github.com/mailru/easyjson\nhttps://github.com/Jeffail/gabs\nhttps://github.com/bitly/go-simplejson\n本文长期链接 如果您觉得我的博客对你有帮助，请通过 RSS订阅我。 或者在X上关注我。 如果您有Medium账号，能给我个关注嘛？我的文章第一时间都会发布在Medium。 ","date":"2024-06-13T17:10:25+08:00","permalink":"https://huizhou92.com/zh-cn/p/%E6%B7%B1%E5%85%A5-go-%E4%B8%AD%E5%90%84%E4%B8%AA%E9%AB%98%E6%80%A7%E8%83%BD-json-%E8%A7%A3%E6%9E%90%E5%BA%93/","title":"深入 Go 中各个高性能 JSON 解析库"},{"content":"上周，Go 1.23 进入冻结期，这意味着不会添加任何新功能，并且任何已添加的功能不太可能被删除。这是一个预览即将发生的变化的好机会。\n这篇文章，来了解一下 1.23 转正的 iter 包。\nThis article is first published in the medium MPP plan. If you are a medium user, please follow me in medium. Thank you very much.\n在Go 1.22中，引入了range over func实验性功能，但需要通过参数GOEXPERIMENT=rangefunc启用。在Go 1.23中，可以直接使用代码实现这种迭代方式。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 func Backward(s []string) func(yield func(string) bool) { return func(yield func(string) bool) { for i := len(s) - 1; i \u0026gt;= 0; i-- { yield(strings.ToUpper(s[i])) } } } ​ func ToUpperByIter() { sl := []string{\u0026#34;hello\u0026#34;, \u0026#34;world\u0026#34;, \u0026#34;golang\u0026#34;} for v := range Backward(sl) { // do business } } yield是传递给迭代器的可调用函数的常规名称。\n我们考虑一下如何在不使用“iter”包的情况下编写代码来实现相同的功能：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 func Convert[S any, D any](src []S, mapFn func(s S) D) []D { r := make([]D, 0, len(src)) for _, i := range src { r = append(r, mapFn(i)) } return r } func ToUpByString() { sl := []string{\u0026#34;hello\u0026#34;, \u0026#34;world\u0026#34;, \u0026#34;golang\u0026#34;} s0 := Convert(sl, func(v string) string { return strings.ToUpper(v) }) for _, v := range s0 { // do business } } 性能对比 1 2 3 4 5 6 7 8 9 10 11 12 13 ➜ huizhou92 git:(master) ✗ go test -bench . -count=3 goos: darwin goarch: arm64 pkg: huizhou92 cpu: Apple M1 Pro BenchmarkToUpByString-10 8568332 128.7 ns/op BenchmarkToUpByString-10 9310351 128.6 ns/op BenchmarkToUpByString-10 9344986 128.5 ns/op BenchmarkToUpByIter-10 12440120 96.22 ns/op BenchmarkToUpByIter-10 12436645 96.25 ns/op BenchmarkToUpByIter-10 12371175 96.64 ns/op PASS ok huizhou92 8.162s 结果很明显：ToUpperByIter 性能更好，因为它不会重新分配新的slice，使得它比以前的方法更高效。\niter 的目标 iter 包旨在提供统一且高效的迭代方法。它为自定义容器类（尤其是在引入泛型之后）提供了标准的迭代接口，并可以替换一些返回切片的现有 API。通过使用迭代器并利用编译器优化，可以提高性能。此外，它还提供了适合函数式编程风格的标准迭代机制。\n如何使用 iter iter支持两种类型的迭代器：\n1 2 3 4 5 6 7 8 9 // Seq is an iterator over sequences of individual values. // When called as seq(yield), seq calls yield(v) for each value v in the sequence, // stopping early if yield returns false. type Seq[V any] func(yield func(V) bool) // Seq2 is an iterator over sequences of pairs of values, most commonly key-value pairs. // When called as seq(yield), seq calls yield(k, v) for each pair (k, v) in the sequence, // stopping early if yield returns false. type Seq2[K, V any] func(yield func(K, V) bool) map 包已经使用 iter 来添加了诸如 All 和 Keys 等方法。这里是它的实现参考：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 //https://go.googlesource.com/go/blob/c83b1a7013784098c2061ae7be832b2ab7241424/src/maps/iter.go#L12 // All returns an iterator over key-value pairs from m. // The iteration order is not specified and is not guaranteed // to be the same from one call to the next. func All[Map ~map[K]V, K comparable, V any](m Map) iter.Seq2[K, V] { return func(yield func(K, V) bool) { for k, v := range m { if !yield(k, v) { return } } } } // Keys returns an iterator over keys in m. // The iteration order is not specified and is not guaranteed // to be the same from one call to the next. func Keys[Map ~map[K]V, K comparable](m Map) iter.Seq[K] { return func(yield func(K) bool) { for k := range m { if !yield(k) { return } } } } 争论 “在我看来，yield 是一个足够复杂的概念，会导致出现大量糟糕的、难以理解的代码。这个建议只提供了语法糖，用于编写语言中已经超出可能范围的内容。我认为这违背了“一个问题 - 一个解决方案”的规则。拜托，让 Go 保持无聊。” 来源\n这是社区内常见的反对意见。yield 不容易理解，并且我们可以通过多种方式实现迭代器。\n结论 我支持添加iter。\niter包为开发人员提供了许多可能性，旨在简化代码并采用更多的函数式编程实践。然而，由于对性能、复杂性和学习曲线的担忧，它的接受度存在分歧。\n与任何新工具一样，关键是在提供明显好处的地方平衡其使用，并同时注意潜在缺点。毫无疑问，Go社区将继续探索和辩论如何利用iter的力量而不损害该语言的基本原则。\n参考资料 61405 56413 iterators_in_go_123 ","date":"2024-06-11T17:33:16+08:00","permalink":"https://huizhou92.com/zh-cn/p/go-1.23-new-iter-package/","title":"Go 1.23: 新包 Iter"},{"content":"上周，Go 1.23 进入冻结期，这意味着不会添加任何新功能，并且任何已添加的功能不太可能被删除。这是一个预览即将发生的变化的好机会。\n这篇文章，我们来介绍引入的新包unique\nThis article is first published in the medium MPP plan. If you are a medium user, please follow me in medium. Thank you very much.\n根据wikipedia的描述，interning是按需重复使用具有同等值对象的技术，减少创建新对象的动作。这种创建模式经常用于不同编程语言中的数和字符串，可以避免不必要的对象重复分配的开销。\nunique 参考了go4.org/intern ,将它移动到了 官方库，并且做了相应的修改。 issue #62483\n就像官方描述的一样 unique 这个包提供了一种轻量化（unique仅仅八个字节）的比较两个变量是否相等的实现。比如下面这段代码\n性能提升还是很明显的\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 ➜ unique git:(master) ✗ /Users/hxzhouh/workspace/googlesource/go/bin/go test -bench=\u0026#39;BenchmarkMake1\u0026#39; -count=5 goos: darwin goarch: arm64 pkg: unique cpu: Apple M1 Pro BenchmarkMake1-10 122033748 9.692 ns/op BenchmarkMake1-10 123878858 9.688 ns/op BenchmarkMake1-10 123927121 9.706 ns/op BenchmarkMake1-10 123849468 9.759 ns/op BenchmarkMake1-10 123306187 9.673 ns/op PASS ok unique 11.055s ➜ unique git:(master) ✗ /Users/hxzhouh/workspace/googlesource/go/bin/go test -bench=\u0026#39;BenchmarkMake2\u0026#39; -count=5 goos: darwin goarch: arm64 pkg: unique cpu: Apple M1 Pro BenchmarkMake2-10 1000000000 0.3118 ns/op BenchmarkMake2-10 1000000000 0.3114 ns/op BenchmarkMake2-10 1000000000 0.3119 ns/op BenchmarkMake2-10 1000000000 0.3136 ns/op BenchmarkMake2-10 1000000000 0.3115 ns/op PASS ok unique 1.875s 但是 你不应该把他当作一个全局变量来用,存储共享数据，unique 的底层实现其实是一个map,查询的成本也是很高的。\n比如\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 ➜ huizhou92_test git:(master) ✗ /Users/hxzhouh/workspace/googlesource/go/bin/go test --bench=BenchmarkBusinessUnique --count=5 goos: darwin goarch: arm64 pkg: huizhou92_test cpu: Apple M1 Pro BenchmarkBusinessUnique-10 3114 373867 ns/op BenchmarkBusinessUnique-10 3280 390818 ns/op BenchmarkBusinessUnique-10 2941 376503 ns/op BenchmarkBusinessUnique-10 3291 389665 ns/op BenchmarkBusinessUnique-10 2954 398610 ns/op PASS ok huizhou92_test 6.320s ➜ huizhou92_test git:(master) ✗ /Users/hxzhouh/workspace/googlesource/go/bin/go test --bench=BenchmarkBusinessString --count=5 goos: darwin goarch: arm64 pkg: huizhou92_test cpu: Apple M1 Pro BenchmarkBusinessString-10 526721706 2.185 ns/op BenchmarkBusinessString-10 548612287 2.183 ns/op BenchmarkBusinessString-10 549425077 2.188 ns/op BenchmarkBusinessString-10 549012100 2.182 ns/op BenchmarkBusinessString-10 548929644 2.183 ns/op PASS ok huizhou92_test 7.237s 正是因为这样，关于unique的讨论其实还在继续，可能是因为用到的地方不是很多？不管怎么样， 这个新的包进入标准库已经是事实了。net/netip 已经用unique 重构了它，用来比对IP地址的详细信息。\n","date":"2024-06-04T09:54:42+08:00","image":"https://images.yixiao9206.cn/blog-images/2024/06/0a8a9a271b2db6d5922f8e58e589b187.png","permalink":"https://huizhou92.com/zh-cn/p/golang-1.23-%E6%96%B0%E7%9A%84-unique-%E5%8C%85/","title":"Golang 1.23: 新的 unique 包"},{"content":"众所周知，HTTPS可以解决HTTP明文传输过程中的安全性问题，尤其是中间人攻击问题。其最初的全称是HTTP over SSL（或者说 http Security）。其中的SSL是指Secure Sockets Layer，后来SSL被TLS（Transport Layer Security ）所取代。今天我们就来总结一下HTTPS的要点\nThis article is first published in the medium MPP plan. If you are a medium user, please follow me in medium. Thank you very much.\nHTTPS 版本 当前人们一般将SSL,TLS这两个协议统称为SSL/TLS协议，但大家日常说SSL的时，默认还是指TLS协议。\nTLS 协议在版本上有1.1、1.2、1.3，其中1.2曾经是主流，现在推荐使用改进后的 TLS 1.3，它升级了HandShake和Record协议，会使得通信更加安全和高效。\n安全上，TLS 1.3 移除了一些在 TLS 1.2 中被认为是不安全的加密算法，如 RC4、DES、3DES、AES-CBC 和 MD5 等，这样可以减少安全漏洞的风险。\n性能上，TLS 1.3 减少了握手过程中的往返次数（RTT），从而加快了连接的建立速度。在最佳情况下，TLS 1.3 只需要一次往返就可以完成握手，同时支持0-RTT扩展，而 TLS 1.2 需要两次或更多。\n当然，作为设计精良的互联网协议，TLS 1.3也通过hello握手消息的扩展协议考虑了最大化向前兼容，这点不再赘述。\nHTTPS 核心流程 依据不同版本的差异，细节流程会略有不同，不追求严谨细致的情况下，HTTPS工作流程如下。\nbytebytego 的这个图非常具有表现力，展示了关键的交互和核心的加密流程。最关键的几步在于如何建立TCP链接，如何通过非对称加密协商获取对称加密的密钥，以及最后通过对称加密进行通信。\nHTTPS，准确来说是TLS，设计严密，其中最关键的是Record Layer和几种Protocol，前者是数据承载管道，各种子Protocol都跑在它上面 ，其中的Record是TLS数据收发传输的基本单位，类似TCP的segment，IP的Packet，这也是下面这幅图的含义。\n上图中Protocol里最重要的是Handshake协议，针对Client Hello进行抓包后，在Wireshark中体现得会更清晰。\nHTTPS SNI 扩展 互联网早期，单机服务器没那么强大，配套的HTTPS比如SSL v2也有设计缺陷。那时有一个假定，认为拥有一个IP的单台服务器只会托管一个域名服务，所以DNS解析以后，直连IP时就能非常确定要使用具体某个域名的证书。但后面云计算、虚拟主机大爆发，以及IPv4中IP的稀缺性，一台服务器托管多个域名的场景无可避免，这时服务器面临无法知道客户端到底想要访问哪个域名的SSL证书的问题，从而导致了HTTPS SNI的出现。\nSNI（Server Name Indication）是TLS协议的一个扩展，它允许客户端在握手过程中向服务器发送目标主机名信息。这样，服务器就可以在同一个IP地址上托管多个域名的HTTPS服务，并为每个域名提供正确的证书。\n这个问题看似简单，在HTTPS逐渐普及，各互联网服务商走向全站HTTPS化的早期，很多CDN厂商甚至都是不支持SNI的。当然在2024年的今天，无论是Nginx等软件生态，还是各厂商，都已经支持了的。\nSNI信息是通过TLS握手协议传输的，抓包示意大概是下面这样子。\n具体到实操，可以使用openssl s_client子命令中的-servername选项来指定SNI：\n1 openssl s_client -connect example.com:443 -servername example.com 如果使用OpenSSL Library，也可以使用SSL_set_tlsext_host_name和BIO_set_conn_hostname等函数来在代码中设置。\nHTTPS 证书机制 HTTPS通过公钥 体系里的非对称、对称及摘要算法，实现了一系列的加解密、签名、验签等功能，基本实现了安全四大特性：机密性、完整性，身份认证和不可否认。如典型的中间人攻击（Man-in-the-middle attack，MITM），也都有了解决方案。\n这里为了解决公钥的信任问题，又引入了证书和信任链机制。证书（Certificate）是由第三方CA（Certificate Authority，证书认证机构）颁发的，本质上是一个文件，通常是.crt、.cer 或 .pem 等扩展名存储。这个文件按照一定的标准（如X.509）编码，包含了公钥、证书持有者信息、颁发机构信息、有效期和数字签名等信息。\n有一些世界知名的 CA 机构，比如 DigiCert、VeriSign、Entrust、Let’s Encrypt 等，它们签发的证书分 DV、OV、EV 三种，对应不同的可信程度。但CA自己也有信任问题，小CA的信任靠大CA签名认证，但逐层向上到了链条的最后，就是 Root CA，就只能用“自签名证书”（Self-Signed Certificate）或者“根证书”（Root Certificate）了。\n大部分操作系统和浏览器都内置了各大 CA 的根证书，HTTPS通信时会顺着证书链（Certificate Chain）逐层验证到根证书。\nHTTPS 软件生态 HTTPS，或是说TLS，生态虽然丰富，但OpenSSL一家独大。它几乎支持所有公开的加密算法和协议，已经成为了事实上的标准，许多应用软件都会使用它作为底层库来实现 TLS 功能，比如著名的 Apache、Nginx 等。\nOpenSSL源于SSLeay，其后开枝散叶，形成众多分支，如 Google 的 BoringSSL、OpenBSD 的 LibreSSL。OpenSSL的内容也极其庞杂，可以优先使用openssl命令进行学习，具体可以参考ChatGPT。\nHTTPS 加速方案 HTTPS很美好，但美好的事物都有成本。所以关于HTTPS全站铺开后的各种优化，基本上可以写成独立的一篇文章，这里先简单提下。\n首先是优化RTT，这个在IO密集型的互联网场景下尤为重要，主要是通过升级协议，如升级HTTP/3，升级TLS 1.3，都可以通过不同原理来优化RTT。其次是优化单步骤性能，如增加TLS加速卡，设置单独的TLS集群或模块等，还有一些TLS session resumption等名词也可以关注。\n我以前写过一篇文章分享为什么HTTPS为什么这么慢的文章，有兴趣可以阅读一下。\nWhy does HTTPS need 7 handshakes and 9 times delay?\n参考资料 What\u0026rsquo;s the difference between HTTP and HTTPS?\nhow-does-https-work\n本文长期连接 如果您觉得我的博客对你有帮助，请通过 RSS订阅我。 或者在X上关注我。 如果您有Medium账号，能给我个关注嘛？我的文章第一时间都会发布在Medium。 ","date":"2024-05-27T18:30:32+08:00","image":"https://images.yixiao9206.cn/blog-images/2024/05/9113c36ee94b362ffe79a997b75c8efe.png","permalink":"https://huizhou92.com/zh-cn/p/%E4%BA%86%E8%A7%A3-https%E5%85%B3%E9%94%AE%E7%82%B9%E5%92%8C%E6%B5%81%E7%A8%8B%E8%AF%A6%E8%A7%A3/","title":"了解 HTTPS：关键点和流程详解"},{"content":"上周 go1.23 已经进入冻结期了，应该不会再添加新功能，相应的已经添加了的功能 也不太可能会被移除。\n这正好可以让我们提前尝鲜这些即将到来的新特性。\nhttps://groups.google.com/g/golang-dev/c/vXE304_MnKM\nThis article is first published in the medium MPP plan. If you are a medium user, please follow me in medium. Thank you very much.\n今天要说的就是1.23中对//go:linkname指令的变更。\n相关讨论的issue 在这里：\nhttps://github.com/golang/go/issues/67401\nTL;DR //go:linkname指令官方并不推荐使用，且不保证任何向前或者向后兼容性，因此明智的做法是尽量别用\n牢记这一点之后，我们可以接着往下看了。至于为啥和“我”也就是本文的作者有关，我们先看完新版本带来的新变化再说。\nlinkname指令是做什么的 简单的说，linkname指令用于向编译器和链接器传递信息。具体的含义根据用法可以分为三类。\n第一类叫做“pull”，意思是拉取，使用方式如下：\n1 2 3 4 5 6 import _ \u0026#34;unsafe\u0026#34; // 必须有这行才能用linkname import _ \u0026#34;fmt\u0026#34; // 被拉取的包需要显式导入（除了runtime包） //go:linkname my_func fmt.Println func my_func(...any) (n int, err error) 这种用法的指令格式是//go:linkname \u0026lt;指令下方的只有声明的函数或包级别变量名\u0026gt; \u0026lt;本包或者其他包中的有完整定义的函数或变量\u0026gt;。\n这个指令的作用就是告诉编译器和连接器，my_func的函数体直接使用fmt.Println的，my_func类似fmt.Println的别名，和它共享同一份代码，就像把指令第二个参数指定的函数和变量拉取下来给第一个参数使用一样。\n正因如此，指令下方给出的声明必须和被拉取的函数/变量完全一致，否则很容易因为类型不匹配导致panic（是的没错，除非拉取的对象不存在，否则都不会出现编译错误）。\n这个指令最恐怖的地方在于它能无视函数或者变量是否是export的，包私有的东西也能被拉取出来使用。因为这一点这种用法在早期的社区中很常见，比如很多人喜欢这么干：//go:linkname myRand runtime.fastrand，因为runtime提供了一个性能还不错的随机数实现，但没有公开出来，所以有人会用linkname指令把它导出为己所用，当然随着1.21的发布这种用法不再有任何意义了，请永远都不要去模仿。\n第二种用法叫做“push”，即推送。形式上是下面这样：\n1 2 3 4 5 6 7 8 9 10 11 12 import _ \u0026#34;unsafe\u0026#34; // 必须有这行才能用linkname //go:linkname main.fastHandle func fastHandle(input io.Writer) error { ... } // package main func fastHandle(input io.Writer) error // 后面main包中可以直接使用fastHandle // 这种情况下需要在main包下创建一个空的asm文件（通常以.s作为扩展名），以告诉编译器fastHandle的定义在别处 在这种用法中，我们只需要把函数/变量名当作第一个参数传给指令，注意需要给出想用这个函数/变量的包的名字，这里是main。同时指令声明的变量或函数必须要在同包内有完整的定义，通常推荐直接把完整定义写在linkname指令下方。\n这种用法是告诉编译器和链接器这个函数/变量的名字就是xxx.yyy，如果遇到这个函数就使用linkname指定的函数/变量的代码，这个模式下甚至能在本包定义别的包里的函数。\n当然这种用法的语义作用更明显，它意味着这个函数会在任何地方被使用，修改它需要小心，因为改变了函数的行为可能会让其他调用它的代码出bug；修改了函数的签名则很可能导致运行时panic；删除了这个函数则会导致代码无法编译。\n最后一类叫做“handshake”，即握手。他是把第一类和第二类方法结合使用：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 package mypkg import _ \u0026#34;unsafe\u0026#34; // 必须有这行才能用linkname //go:linkname fastHandle func fastHandle(input io.Writer) error { ... } package main import _ \u0026#34;unsafe\u0026#34; // 必须有这行才能用linkname //go:linkname fastHandle mypkg.fastHandle func fastHandle(input io.Writer) error “pull”的一方没什么区别，但“push”的一方不用再写包名，同时用来告诉编译器函数定义在别的地方的空的asm文件也不需要了。这种就像通讯协议中的“握手”，一方告诉编译器这边允许某个函数/变量被linkname操作，另一边则明确像编译器要求它要使用某个包的某个函数/变量。\n通常“pull”和“push”应该成对出现，也就是你只应该使用“handshake”模式。\n然而不幸的是，当前（1.22）的go语言支持“pull-only”的用法，即可以随便拉取任何包里的任何函数/变量，但不需要被拉取的对象使用“push”标记自己。而被linkname拉取的一方是完全无感知的。\n这就导致了非常大的隐患。\nlinkname带来的隐患 最大的隐患在于这个指令可以在不通知被拉取的packages的情况下随意使用包中私有的函数/变量。\n举个例子：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 // pkg/mymath/mymath.go package mymath func uintPow(n uint) uint { return n*n } // main.go package main import ( \u0026#34;fmt\u0026#34; _ \u0026#34;linkname/pkg/mymath\u0026#34; _ \u0026#34;unsafe\u0026#34; ) //go:linkname pow linkname/pkg/mymath.uintPow func pow(n uint) uint func main() { fmt.Println(pow(6)) // 36 } 正常来说，uintPow是不可能被外部使用的，然而通过linkname指令我们直接无视了接口的公开和私有，有什么就能用什么了。\n这当然是非常危险的，比如我们把uintPow的参数类型改成string：\n1 2 3 4 5 package mymath func uintPow(n string) string { return n + n } 这时候编译还是能正常编译，但运行的时候就会出现各种bug，在我的机器上表现是卡死和段错误。为什么呢？因为我们把uint强行传递了过去，但参数需要是string，类型对不上，自然会出现稀奇古怪的bug。这种在别的语言里是严重的类型相关的内存错误。\n另外如果我们直接删了uintPow或者给他改个名，链接器会在编译期间报错：\n1 2 3 4 $ go build # linkname main.main: relocation target linkname/pkg/mymath.uintPow not defined 而且我们导出的是私有函数，通常没人会认为自己写的私有级别的帮助函数会被导出到包外并被使用，因此在开发时大家都是保证公开接口的稳定性，私有的函数/变量是随时可以被大规模修改甚至删除的。\n而linkname将这种在别的语言里最基本的规矩给粉碎了。\n而且事实上也是如此，从1.18开始几乎每个版本都有因为编译器或者标准库内部的私有函数被修改/删除从而导致某些第三方库在新版本无法使用的问题，因为这些库在内部悄悄用//go:linkname用了一些未公开的功能。最近一次发生在广泛使用的知名json库上类似的问题可以在这里看到。\nlinkname的正面作用 既然这个指令如此危险，为什么还一直存在呢？答案是有不得不用的理由，其中一个就在启动go程序的时候。\n我们来看下go的runtime里是怎么用linkname的：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 // runtime/proc.go //go:linkname main_main main.main func main_main() // runtime.main // 所有go程序的入口 func main() { // 初始化runtime // 调用main.main fn := main_main // make an indirect call, as the linker doesn\u0026#39;t know the address of the main package when laying down the runtime fn() // main退出后做清理工作 } 因为程序的入口在runtime里（要初始化runtime，比如gc等），所以入口函数必须在runtime包里。而我们又需要调用用户定义在main包里的main函数，但main包不能被import，因此只能靠linkname指令让链接器绕过所有编译器附加的限制来调用main函数。\n这是目前在go自身的源代码里看到的唯一一处不得不使用“pull-only”模式的地方。\n另外“handshake”模式也有存在的必要性，因为像runtime和reflect需要共享很多实现上的细节，因此reflect作为pull的一方，runtime作为push的一方，可以极大减少代码维护的复杂度。\n除了上述这些情况，绝大数linkname的使用都可以算作_abuse_。\ngolang1.23对linkname指令的改动 鉴于上述情况，golang核心团队决定限制linkname的使用。\n第一个改动是标准库里新添加的包全部禁止使用linkname导出其中的内容，目前是通过黑名单实现的，1.23中新添加的几个包以及它们的internal依赖都在名单上，这样可以防止已有的linkname问题继续扩大。这对已有的代码也是完全无害的。\n第二个变更时添加了新的ldflags: -checklinkname=1。1代表开启对linkname的限制，0代表维持1.22的行为不变。目前默认是0，但官方决定在1.23发布时默认值为1开启限制。个人建议尽量不要关闭这个限制。这个限制眼下只针对标准库，但按官方的说法效果好的话以后所有的代码不管标准库还是第三方都会启用限制。\n最后也是最大的变动，禁止对标准库的 “pull-only” linkname指令，但允许“handshake”模式。\n虽然go从来不保证linkname的向后兼容性，但这样还是会大量较大的破坏，因此官方已经对常见的go第三方库做了扫描，会把一些经常被人用linkname拉取的接口改成符合“handshake”模式的形式，这种改动只用加一行指令即可。而且该限制目前只针对标准库，其他第三方库暂时不受影响。\n因为这个变更，下面的代码在1.23是无法编译通过的：\n1 2 3 4 5 6 7 8 package main import _ \u0026#34;unsafe\u0026#34; //go:linkname corostart runtime.corostart func corostart() func main() { corostart() } 因为runtime.corostart并不符合handshake模式，所以对它的linkname被禁止了：\n1 2 3 4 5 $ go version go version devel go1.23-13d36a9b46 Wed May 27 21:51:49 2024 +0000 windows/amd64 $ go build -ldflags=-checklinkname=1 # linkname link: main: invalid reference to runtime.corostart linkname指令今后的发展 大趋势肯定是以后只允许handshake模式。不过作为过渡目前还是允许push模式的，并且官方应该会在进入功能冻结后把之前说的扫描到的常用的内部函数添加上linkname指令。\n这里比较重要的是作为开发者的我们应该怎么办：\n1.23发布之后或者现在就开始利用-checklinkname=1排查代码，及时清除不必要的linkname指令。 如果linkname指令非用不可，建议马上提issue或者熟悉go开发流程的立刻提pr补上handshake模式需要的指令，不过我不怎么推荐这种做法，因为内部api尤其是runtime以外的库的本来就不该随便被导出使用，没有一个强力的能说服所有人的理由，这些issue和pr多半不会被接受。 向官方提案，尝试把你要用的私有api变成公开接口，这一步难度也很高，私有api之所以当初不公开一定是有原因的，现在再想公开可能性也不高。 你的追求比较低，只要代码能跑就行，那可以在构建脚本里加上-ldflags=-checklinkname=0关闭限制，这样也许能岁月静好几个版本，直到某一天程序突然没法编译或者运行了一半被莫名其妙的panic打断。 4是万不得已时的保底方案，按优先度我推荐1 \u0026gt; 3 \u0026gt; 2的顺序去适配go1.23。2和3不仅仅适用于go标准库，常用的第三方库也可以。通过这些适配工作说不定也有机会让你成为go或者知名第三方库的贡献者。\n从现在开始完全是来得及的，毕竟离1.23的第一个测试版发布还有一个月左右，离正式版发布还有两个月。而且方案2的修改并不算作新功能，不受功能冻结的影响。\n当然，大部分开发者应该不用担心，比较linkname的使用是少数，一些主动使用linkname的库比如quic-go也知道兼容性问题，很小心地做了不同版本的适配，加上官方承诺的兜底这一对linkname指令的改动的影响应该比想象中小，但是是提高代码安全性的一大步。\n总结 最后总结就一句话：没事别用//go:linkname 可能会留下不可预知的隐患。\n","date":"2024-05-27T09:37:25+08:00","permalink":"https://huizhou92.com/zh-cn/p/%23-golang-1.23-changes-to-/golinkname-and-what-it-means-for-developers/","title":"Golang 1.23：`//go:linkname` 的变更及其对开发人员的意义"},{"content":"\nBacklink | |Photo by Anna Demianenko on Unsplash 背景 gRPC是google开源的高性能跨语言的RPC方案。gRPC的设计目标是在任何环境下运行，支持可插拔的负载均衡，跟踪，运行状况检查和身份验证。它不仅支持数据中心内部和跨数据中心的服务调用，它也适用于分布式计算的最后一公里，将设备，移动应用程序和浏览器连接到后端服务。\n关于 GRPC设计的动机和原则 我们可以从这篇文章里面找到答案，gRPC Motivation and Design Principles\nThis article is first published in the medium MPP plan. If you are a medium user, please follow me in medium. Thank you very much.\n官方的文章令人印象深刻的点：\n内部有Stubby的框架，但是它不是基于任何一个标准的 支持任意环境使用，支持物联网、手机、浏览器 支持stream和流控 实际上：性能不是gRPC 设计的第一目标。那么为什么选择HTTP/2?\nHTTP/2是什么 在正式讨论gRPC为什么选择HTTP/2之前，我们先来简单了解下HTTP/2。\nHTTP/2可以简单用一个图片来介绍：\n来自：https://hpbn.co/\nHTTP/1里的header对应HTTP/2里的 HEADERS frame HTTP/1里的payload对应HTTP/2里的 DATA frame\n在Chrome浏览器里，打开chrome://net-internals/#http2，可以看到http2链接的信息。\n目前很多网站都已经跑在HTTP/2上了。\ngRPC Over HTTP/2 准确来说gRPC设计上是分层的，底层支持不同的协议，目前gRPC支持：\ngRPC over HTTP2 gRPC Web 但是大多数情况下，讨论都是基于gRPC over HTTP2。\n下面从一个真实的gRPC SayHello请求，查看它在HTTP/2上是怎样实现的。用Wireshark抓包：\n可以看到下面这些Header：\n1 2 3 4 5 6 Header: :authority: localhost:50051 Header: :path: /helloworld.Greeter/SayHello Header: :method: POST Header: :scheme: http Header: content-type: application/grpc Header: user-agent: grpc-java-netty/1.11.0 然后请求的参数在DATA frame里：\nGRPC Message: /helloworld.Greeter/SayHello, Request\n简而言之，gGRPC把元数据放到HTTP/2 Headers里，请求参数序列化之后放到 DATA frame里。\n基于HTTP/2 协议的优点 HTTP/2 是一个公开的标准 Google本身把这个事情想清楚了，它并没有把内部的Stubby开源，而是选择重新做。现在技术越来越开放，私有协议的空间越来越小。\nHTTP/2 是一个经过实践检验的标准 HTTP/2是先有实践再有标准，这个很重要。很多不成功的标准都是先有一大堆厂商讨论出标准后有实现，导致混乱而不可用，比如CORBA。HTTP/2的前身是Google的SPDY，没有Google的实践和推动，可能都不会有HTTP/2。\nHTTP/2 天然支持物联网、手机、浏览器 实际上先用上HTTP/2的也是手机和手机浏览器。移动互联网推动了HTTP/2的发展和普及。\n基于HTTP/2 多语言的实现容易 只讨论协议本身的实现，不考虑序列化。\n每个流行的编程语言都会有成熟的HTTP/2 Client HTTP/2 Client是经过充分测试，可靠的 用Client发送HTTP/2请求的难度远低于用socket发送数据包/解析数据包 HTTP/2支持Stream和流控 在业界，有很多支持stream的方案，比如基于websocket的，或者rsocket。但是这些方案都不是通用的。\nHTTP/2里的Stream还可以设置优先级，尽管在rpc里可能用的比较少，但是一些复杂的场景可能会用到。\n基于HTTP/2 在Gateway/Proxy很容易支持 nginx对gRPC的支持 envoy对gRPC的支持 HTTP/2 安全性有保证 HTTP/2 天然支持SSL，当然gRPC可以跑在clear text协议（即不加密）上。 很多私有协议的rpc可能自己包装了一层TLS支持，使用起来也非常复杂。开发者是否有足够的安全知识？使用者是否配置对了？运维者是否能正确理解？ HTTP/2 在公有网络上的传输上有保证。比如这个CRIME攻击，私有协议很难保证没有这样子的漏洞。 HTTP/2 鉴权成熟 从HTTP/1发展起来的鉴权系统已经很成熟了，可以无缝用在HTTP/2上 可以从前端到后端完全打通的鉴权，不需要做任何转换适配\n比如传统的rpc dubbo，需要写一个dubbo filter，还要考虑把鉴权相关的信息通过thread local传递进去。rpc协议本身也需要支持。总之，非常复杂。实际上绝大部分公司里的rpc都是没有鉴权的，可以随便调。 基于HTTP/2 的缺点 Rpc的元数据的传输不够高效 尽管HPAC可以压缩HTTP Header，但是对于rpc来说，确定一个函数调用，可以简化为一个int，只要两端去协商过一次，后面直接查表就可以了，不需要像HPAC那样编码解码。\n可以考虑专门对gRPC做一个优化过的HTTP/2解析器，减少一些通用的处理，感觉可以提升性能。\nHTTP/2 里一次gRPC调用需要解码两次 一次是HEADERS frame，一次是DATA frame。\nHTTP/2 标准本身是只有一个TCP连接，但是实际在gRPC里是会有多个TCP连接，使用时需要注意。\ngRPC选择基于HTTP/2，那么它的性能肯定不会是最顶尖的。但是对于rpc来说中庸的qps可以接受，通用和兼容性才是最重要的事情。我们可以参考一下官方的benchmark：https://grpc.io/docs/guides/benchmarking.html\nhttps://github.com/hank-whu/rpc-benchmark\n如果您的场景是搞 Google制定标准的能力 近10年来，Google制定标准的能力越来越强。下面列举一些标准：\nHTTP/2 WebP图片格式 WebRTC 网页即时通信 VP9/AV1 视频编码标准 Service Worker/PWA QUIC/ HTTP/3\n当然google也并不都会成功，很多事情它想推也失败了，比如Chrome的Native Client。 gRPC目前是k8s生态里的事实标准。 gRPC是否会成为更多地方，更大领域的RPC标准？\n为什么会出现gRPC 准确来说为什么会出现基于HTTP/2的RPC？\n个人认为一个重要的原因是，在Cloud Native的潮流下，开放互通的需求必然会产生基于HTTP/2的RPC。即使没有gRPC，也会有其它基于HTTP/2的RPC。\ngRPC在Google的内部也是先用在Google Cloud Platform和公开的API上：https://opensource.google.com/projects/grpc\n总结 尽管gRPC它可能替换不了内部的RPC实现，但是在开放互通的时代，不止在k8s上，gRPC会有越来越多的舞台可以施展。\n参考资料 https://grpc.io/ https://hpbn.co/ https://grpc.io/blog/loadbalancing https://http2.github.io/faq https://github.com/grpc/grpc 本文长期链接 如果您觉得我的博客对你有帮助，请通过 RSS订阅我。 或者在X上关注我。 如果您有Medium账号，能给我个关注嘛？我的文章第一时间都会发布在Medium。 ","date":"2024-05-23T10:25:02+08:00","permalink":"https://huizhou92.com/zh-cn/p/%E4%B8%BA%E4%BB%80%E4%B9%88-google-%E9%80%89%E6%8B%A9%E4%BD%BF%E7%94%A8http-2-%E5%AE%9E%E7%8E%B0-grpc/","title":"为什么 Google 选择使用HTTP 2 实现 gRPC"},{"content":"摘要 wireshark 是一个 流行的抓取网络报文的工具,他不仅自己可以抓包，也可以解析tcpdump抓包的文件。\ngRPC 是Google开发的一个高性能RPC框架，基于HTTP/2协议+protobuf序列化协议.\n本文主要介绍如何使用wireshark抓取gRPC的报文，并解析报文内容。\nThis article is first published in the medium MPP plan. If you are a medium user, please follow me in medium. Thank you very much.\nWireshark version: 4.2.2\n配置 因为gRPC 是基于protobuf序列化协议，所以我们需要先添加protobuf的文件地址。\n点击 Wireshark -\u0026gt; Preferences\u0026hellip; -\u0026gt; Protocols -\u0026gt; Protobuf -\u0026gt; Protobuf search paths -\u0026gt; Edit\u0026hellip;\n点击+ 添加您要抓包的protobuf 文件路径，不要忘记勾选右边的 Load all files\n具体操作 首先我们写一个最简单的gRPC服务，\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 syntax = \u0026#34;proto3\u0026#34;; option go_package = \u0026#34;example.com/hxzhouh/go-example/grpc/helloworld/api\u0026#34;; package api; // The greeting service definition. service Greeter { // Sends a greeting rpc SayHello (HelloRequest) returns (HelloReply) {} } // The request message containing the user\u0026#39;s name. message HelloRequest { string name = 1; } // The response message containing the greetings message HelloReply { string message = 1; } 它仅仅就一个函数 Greeter ,补充完服务端代码，把它运行起来。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 type server struct { api.UnimplementedGreeterServer } func (s *server) SayHello(ctx context.Context, in *api.HelloRequest) (*api.HelloReply, error) { log.Printf(\u0026#34;Received: %v\u0026#34;, in.GetName()) return \u0026amp;api.HelloReply{Message: \u0026#34;Hello \u0026#34; + in.GetName()}, nil } func main() { lis, err := net.Listen(\u0026#34;tcp\u0026#34;, \u0026#34;:50051\u0026#34;) if err != nil { log.Fatalf(\u0026#34;failed to listen: %v\u0026#34;, err) } s := grpc.NewServer() api.RegisterGreeterServer(s, \u0026amp;server{}) if err := s.Serve(lis); err != nil { log.Fatalf(\u0026#34;failed to serve: %v\u0026#34;, err) } } 然后我们打开 wireshark ，选择本地网卡，监听 tcp.port == 50051\n如果您以前没接触过 wireshark，我建议您先看看这篇文章：https://www.lifewire.com/wireshark-tutorial-4143298\n一元函数 现在我们有一个gRPC 服务运行再本地的50051 端口， 我们可以使用BloomRPC 或者其他您任何喜欢的工具对服务端发起一个RPC请求,或者直接像我一样使用下面的代码\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 func Test_server_SayHello(t *testing.T) { // Set up a connection to the server. conn, err := grpc.Dial(\u0026#34;localhost:50051\u0026#34;, grpc.WithInsecure(), grpc.WithBlock()) if err != nil { log.Fatalf(\u0026#34;did not connect: %v\u0026#34;, err) } defer conn.Close() c := api.NewGreeterClient(conn) // Contact the server and print out its response. name := \u0026#34;Hello\u0026#34; ctx, cancel := context.WithTimeout(context.Background(), time.Second) defer cancel() r, err := c.SayHello(ctx, \u0026amp;api.HelloRequest{Name: name}) if err != nil { log.Fatalf(\u0026#34;could not greet: %v\u0026#34;, err) } log.Printf(\u0026#34;Greeting: %s\u0026#34;, r.GetMessage()) } 这个时候，wireshark 应该就能抓到流量包了。\n前面我们说过，gRPC = http2+protobuf, 并且我们前面已经加载了protobuf 文件，理论上我们现在已经能解析报文了。\n使用wireshark快捷键 shift+command+U 或者 用鼠标点击 Analyze -\u0026gt; Decode As... 然后设置一下将报文解析成HTTP2 格式。\n这个时候，我们就能很清晰的看到这个请求了\nmetadata 我们知道 gRPC 的metadata 是通过 http2 的header 来传递的。 现在我们通过抓包来验证一下。\n稍微改造一下客户端代码\n1 2 3 4 5 6 7 8 9 10 11 12 func Test_server_SayHello(t *testing.T) { // Set up a connection to the server. ..... // add md md := map[string][]string{\u0026#34;timestamp\u0026#34;: {time.Now().Format(time.Stamp)}} md[\u0026#34;testmd\u0026#34;] = []string{\u0026#34;testmd\u0026#34;} ctx := metadata.NewOutgoingContext(context.Background(), md) // Contact the server and print out its response. name := \u0026#34;Hello\u0026#34; ctx, cancel := context.WithTimeout(ctx, time.Second) .... } 然后重新抓包。 我们就能看到 md 确实放在 header 里面。\n并且我们还在header 看到了grpc-timeout 可见请求超时操作也是房子啊header 里面的。里面涉及的具体细节，我可能会出一篇专门的文章来说明，今天我们只关注抓包。\nTLS 上面使用的例子都是明文 传输的 我们再Dial 的时候使用了 grpc.WithInsecure() ,但是在生产环境中，我们一般使用TLS 对进行加密传输。具体的细节可以参考我以前写的文章。\nhttps://medium.com/gitconnected/secure-communication-with-grpc-from-ssl-tls-certification-to-san-certification-d9464c3d706f\n我们改造一下 服务端代码\nhttps://gist.github.com/hxzhouh/e08546cf0457d28a614d59ec28870b11 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 func main() { certificate, err := tls.LoadX509KeyPair(\u0026#34;./keys/server.crt\u0026#34;, \u0026#34;./keys/server.key\u0026#34;) if err != nil { log.Fatalf(\u0026#34;Failed to load key pair: %v\u0026#34;, err) } certPool := x509.NewCertPool() ca, err := os.ReadFile(\u0026#34;./keys/ca.crt\u0026#34;) if err != nil { log.Fatalf(\u0026#34;Failed to read ca: %v\u0026#34;, err) } if ok := certPool.AppendCertsFromPEM(ca); !ok { log.Fatalf(\u0026#34;Failed to append ca certificate\u0026#34;) } opts := []grpc.ServerOption{ grpc.Creds( // 为所有传入的连接启用TLS credentials.NewTLS(\u0026amp;tls.Config{ ClientAuth: tls.RequireAndVerifyClientCert, Certificates: []tls.Certificate{certificate}, ClientCAs: certPool, }, )), } listen, err := net.Listen(\u0026#34;tcp\u0026#34;, fmt.Sprintf(\u0026#34;0.0.0.0:%d\u0026#34;, 50051)) if err != nil { log.Fatalf(\u0026#34;failed to listen %d port\u0026#34;, 50051) } // 通过传入的TLS服务器凭证创建新的gRPC服务实例 s := grpc.NewServer(opts...) api.RegisterGreeterServer(s, \u0026amp;server{}) log.Printf(\u0026#34;server listening at %v\u0026#34;, listen.Addr()) if err := s.Serve(listen); err != nil { log.Fatalf(\u0026#34;Failed to serve: %v\u0026#34;, err) } } client\nhttps://gist.github.com/hxzhouh/46a7a31e2696b87fe6fb83c8ce7e036c 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 func Test_server_SayHello(t *testing.T) { certificate, err := tls.LoadX509KeyPair(\u0026#34;./keys/client.crt\u0026#34;, \u0026#34;./keys/client.key\u0026#34;) if err != nil { log.Fatalf(\u0026#34;Failed to load client key pair, %v\u0026#34;, err) } certPool := x509.NewCertPool() ca, err := os.ReadFile(\u0026#34;./keys/ca.crt\u0026#34;) if err != nil { log.Fatalf(\u0026#34;Failed to read %s, error: %v\u0026#34;, \u0026#34;./keys/ca.crt\u0026#34;, err) } if ok := certPool.AppendCertsFromPEM(ca); !ok { log.Fatalf(\u0026#34;Failed to append ca certs\u0026#34;) } opts := []grpc.DialOption{ grpc.WithTransportCredentials(credentials.NewTLS( \u0026amp;tls.Config{ ServerName: \u0026#34;localhost\u0026#34;, Certificates: []tls.Certificate{certificate}, RootCAs: certPool, })), } // conn, err := grpc.Dial(*addr, grpc.WithTransportCredentials(insecure.NewCredentials())) conn, err := grpc.Dial(\u0026#34;localhost:50051\u0026#34;, opts...) if err != nil { log.Fatalf(\u0026#34;Connect to %s failed\u0026#34;, \u0026#34;localhost:50051\u0026#34;) } defer conn.Close() client := api.NewGreeterClient(conn) ctx, cancel := context.WithTimeout(context.Background(), time.Second*5) defer cancel() r, err := client.SayHello(ctx, \u0026amp;api.HelloRequest{Name: \u0026#34;Hello\u0026#34;}) if err != nil { log.Printf(\u0026#34;Failed to greet, error: %v\u0026#34;, err) } else { log.Printf(\u0026#34;Greeting: %v\u0026#34;, r.GetMessage()) } } 这个时候我们再抓包，然后使用相同的方式解析。但是，我们会发现，使用HTTP2 已经无法解密了，但是可以解码成 TLS1.3\n总结 这篇文章，首先总结了使用 Wireshark 抓gRPC 包的一个基本流程。\n然后我们通过抓包知道了gRPC的参数传递是通过 HTTP2 的data-frame，CTX 等meta 是通过 header 传递的。这些知识我们以前肯定听过，但是只有动手实验才能加深理解。\n通过TLS 我们可以实现 安全的gRPC 通信，下一篇文章，我们将尝试解密TLS 报文。\n参考资料 Wireshark Tutorial https://grpc.io/blog/wireshark/ https://www.lifewire.com/wireshark-tutorial-4143298 ","date":"2024-05-19T21:36:25Z","image":"https://images.yixiao9206.cn/blog-images/2024/05/a8ca43282aece789e1e0b1d2a2db7a5f.png","permalink":"https://huizhou92.com/zh-cn/p/how-to-capture-and-analyze-grpc-packets/","title":"使用 wireshark 抓包GRPC"},{"content":"我最近几年一直再打造自己的第二大脑，下面是我的几个经验教训。\n频繁切换笔记软件/博客系统 我先后使用过 EverNote，WizNote，VNote，CSDN blog，Google blogspot, WordPress，最终只造成博客散落在多个互联网角落。解决办法就是 all in one 。我现在选择的是Obsidian\n频繁切换笔记格式 我先后使用过 txt, orgmode, markdown，富文本等多种格式，最终只造成各种格式转换烦恼，跟第一条一样，每个笔记系统的格式可能不通用，选择Obsidian的原因就是它的markdown语法。如果我需要，我可以轻易的将它迁移到任何笔记系统，\n闪念笔记和真正有用的笔记混杂 闪念笔记用于快速捕捉一瞬间的灵感，但只有你在一两天内回顾它并把它变成有用的合适的笔记才有意义。如果不及时回顾，好的想法将淹没在大量的突发奇想中。我们每天大多数的想法没有太大意义应该被丢弃，而那些可以成为重大有意义的想法我们必须将他们识别出来。\n项目笔记和知识笔记混杂 只记录特定项目相关的笔记，将导致项目期间有趣的观点或者想法信息丢失。正确的做法是在项目中提取通用的知识。我推荐使用P.A.R.A 方法来整理笔记，有关P.A.R.A 您可以参考 这个网页\n频繁整理笔记的「洁癖」 大量堆积的笔记将造成知识整理冲动，多来几次就会影响坚持记录的信心。解决方法是，确定自己关注的领域和负责的责任范围，并不完全采用自下而上的知识管理方法。在达到心理挤压点时，使用 MOCS（Maps of Content）的方法整理笔记（双链绝对是你值得尝试的。）。知识管理系统最重要的是在同一个地方，用同样的格式和一致的标准记录你的洞见。\n","date":"2024-05-06T10:19:00+08:00","image":"https://images.yixiao9206.cn/blog-images/2024/05/5ab6b54893dc2241704444526269572a.jpg","permalink":"https://huizhou92.com/zh-cn/p/crafting-your-second-brain-lessons-learned-from-my-note-taking-journey/","title":"知识管理的几个误区"},{"content":"进程是操作系统的伟大发明之一，对应用程序屏蔽了CPU调度、内存管理等硬件细节，而抽象出一个进程的概念，让应用程序专心于实现自己的业务逻辑既可，而且在有限的CPU上可以“同时”进行许多个任务。但是它为用户带来方便的同时，也引入了一些额外的开销。如下图，在进程运行中间的时间里，虽然CPU也在忙于干活，但是却没有完成任何的用户工作，这就是进程机制带来的额外开销。\n在进程A切换到进程B的过程中，先保存A进程的上下文，以便于等A恢复运行的时候，能够知道A进程的下一条指令是啥。然后将要运行的B进程的上下文恢复到寄存器中。这个过程被称为上下文切换。上下文切换开销在进程不多、切换不频繁的应用场景下问题不大。但是现在Linux操作系统被用到了高并发的网络程序后端服务器。在单机支持成千上万个用户请求的时候，这个开销就得拿出来说道说道了。因为用户进程在请求Redis、Mysql数据等网络IO阻塞掉的时候，或者在进程时间片到了，都会引发上下文切换。\n一个简单的进程上下文切换开销测试实验 废话不多说，我们先用个实验测试一下，到底一次上下文切换需要多长的CPU时间！实验方法是创建两个进程并在它们之间传送一个令牌。其中一个进程在读取令牌时就会引起阻塞。另一个进程发送令牌后等待其返回时也处于阻塞状态。如此往返传送一定的次数，然后统计他们的平均单次切换时间开销。\ntest04\n1 2 3 4 ## gcc main.c -o main ## ./main./main Before Context Switch Time1565352257 s, 774767 us After Context SWitch Time1565352257 s, 842852 us 每次执行的时间会有差异，多次运行后平均每次上下文切换耗时3.5us左右。当然了这个数字因机器而异，而且建议在实机上测试。\n前面我们测试系统调用的时候，最低值是200ns。可见，上下文切换开销要比系统调用的开销要大。系统调用只是在进程内将用户态切换到内核态，然后再切回来，而上下文切换可是直接从进程A切换到了进程B。显然这个上下文切换需要完成的工作量更大。\n进程上下文切换开销都有哪些 那么上下文切换的时候，CPU的开销都具体有哪些呢？开销分成两种，一种是直接开销、一种是间接开销。\n直接开销就是在切换时，cpu必须做的事情，包括：\n1、==切换页表全局目录== 2、==切换内核态堆栈== 3、==切换硬件上下文==（进程恢复前，必须装入寄存器的数据统称为硬件上下文） ip(instruction pointer)：指向当前执行指令的下一条指令 bp(base pointer): 用于存放执行中的函数对应的栈帧的栈底地址 sp(stack poinger): 用于存放执行中的函数对应的栈帧的栈顶地址 cr3:页目录基址寄存器，保存页目录表的物理地址 \u0026hellip;\u0026hellip; 4、刷新TLB 5、系统调度器的代码执行 间接开销主要指的是虽然切换到一个新进程后，==由于各种缓存并不热，速度运行会慢一些==。如果进程始终都在一个CPU上调度还好一些，如果跨CPU的话，之前热起来的TLB、L1、L2、L3因为运行的进程已经变了，所以以局部性原理cache起来的代码、数据也都没有用了，导致新进程穿透到内存的IO会变多。 其实我们上面的实验并没有很好地测量到这种情况，所以实际的上下文切换开销可能比3.5us要大。\n想了解更详细操作过程的同学请参考《深入理解Linux内核》中的第三章和第九章。\n一个更为专业的测试工具-lmbench lmbench用于评价系统综合性能的多平台开源benchmark，能够测试包括文档读写、内存操作、进程创建销毁开销、网络等性能。使用方法简单，但就是跑有点慢，感兴趣的同学可以自己试一试。\n这个工具的优势是是进行了多组实验，每组2个进程、8个、16个。每个进程使用的数据大小也在变，充分模拟cache miss造成的影响。我用他测了一下结果如下：\n1 2 3 4 5 ------------------------------------------------------------------------- Host OS 2p/0K 2p/16K 2p/64K 8p/16K 8p/64K 16p/16K 16p/64K ctxsw ctxsw ctxsw ctxsw ctxsw ctxsw ctxsw --------- ------------- ------ ------ ------ ------ ------ ------- ------- bjzw_46_7 Linux 2.6.32- 2.7800 2.7800 2.7000 4.3800 4.0400 4.75000 5.48000 lmbench显示的进程上下文切换耗时从2.7us到5.48之间。\n线程上下文切换耗时 前面我们测试了进程上下文切换的开销，我们再继续在Linux测试一下线程。看看究竟比进程能不能快一些，快的话能快多少。\n在Linux下其实本并没有线程，只是为了迎合开发者口味，搞了个轻量级进程出来就叫做了线程。轻量级进程和进程一样，都有自己独立的task_struct进程描述符，也都有自己独立的pid。从操作系统视角看，调度上和进程没有什么区别，都是在等待队列的双向链表里选择一个task_struct切到运行态而已。只不过轻量级进程和普通进程的区别是可以共享同一内存地址空间、代码段、全局变量、同一打开文件集合而已。\n同一进程下的线程之所有getpid()看到的pid是一样的，其实task_struct里还有一个tgid字段。 对于多线程程序来说，getpid()系统调用获取的实际上是这个tgid，因此隶属同一进程的多线程看起来PID相同。\n我们用一个实验来测试一下test06。其原理和进程测试差不多，创建了20个线程，在线程之间通过管道来传递信号。接到信号就唤醒，然后再传递信号给下一个线程，自己睡眠。 这个实验里单独考虑了给管道传递信号的额外开销，并在第一步就统计了出来。\n1 2 3 ## gcc -lpthread main.c -o main 0.508250 4.363495 每次实验结果会有一些差异，上面的结果是取了多次的结果之后然后平均的，大约每次线程切换开销大约是3.8us左右。从上下文切换的耗时上来看，Linux线程（轻量级进程）其实和进程差别不太大。\nLinux相关命令 既然我们知道了上下文切换比较的消耗CPU时间，那么我们通过什么工具可以查看一下Linux里究竟在发生多少切换呢？如果上下文切换已经影响到了系统整体性能，我们有没有办法把有问题的进程揪出来，并把它优化掉呢？\n1 2 3 4 5 6 7 8 ## vmstat 1 procs -----------memory---------- ---swap-- -----io---- --system-- -----cpu----- r b swpd free buff cache si so bi bo in cs us sy id wa st 2 0 0 595504 5724 190884 0 0 295 297 0 0 14 6 75 0 4 5 0 0 593016 5732 193288 0 0 0 92 19889 29104 20 6 67 0 7 3 0 0 591292 5732 195476 0 0 0 0 20151 28487 20 6 66 0 8 4 0 0 589296 5732 196800 0 0 116 384 19326 27693 20 7 67 0 7 4 0 0 586956 5740 199496 0 0 216 24 18321 24018 22 8 62 0 8 或者是\n1 2 3 4 5 6 7 8 9 10 11 12 13 ## sar -w 1 proc/s Total number of tasks created per second. cswch/s Total number of context switches per second. 11:19:20 AM proc/s cswch/s 11:19:21 AM 110.28 23468.22 11:19:22 AM 128.85 33910.58 11:19:23 AM 47.52 40733.66 11:19:24 AM 35.85 30972.64 11:19:25 AM 47.62 24951.43 11:19:26 AM 47.52 42950.50 ...... 上图的环境是一台生产环境机器，配置是8核8G的KVM虚机，环境是在nginx+fpm的，fpm数量为1000，平均每秒处理的用户接口请求大约100左右。其中cs列表示的就是在1s内系统发生的上下文切换次数，大约1s切换次数都达到4W次了。粗略估算一下，每核大约每秒需要切换5K次，则1s内需要花将近20ms在上下文切换上。要知道这是虚机，本身在虚拟化上还会有一些额外开销，而且还要真正消耗CPU在用户接口逻辑处理、系统调用内核逻辑处理、以及网络连接的处理以及软中断，所以20ms的开销实际上不低了。\n那么进一步，我们看下到底是哪些进程导致了频繁的上下文切换？\n1 2 3 4 5 6 ## pidstat -w 1 11:07:56 AM PID cswch/s nvcswch/s Command 11:07:56 AM 32316 4.00 0.00 php-fpm 11:07:56 AM 32508 160.00 34.00 php-fpm 11:07:56 AM 32726 131.00 8.00 php-fpm ...... 由于fpm是同步阻塞的模式，每当请求Redis、Memcache、Mysql的时候就会阻塞导致cswch/s自愿上下文切换，而只有时间片到了之后才会触发nvcswch/s非自愿切换。可见fpm进程大部分的切换都是自愿的、非自愿的比较少。\n如果想查看具体某个进程的上下文切换总情况，可以在/proc接口下直接看，不过这个是总值。\n1 2 3 grep ctxt /proc/32583/status voluntary_ctxt_switches: 573066 nonvoluntary_ctxt_switches: 89260 结论 上下文切换具体做哪些事情我们没有必要记，只需要记住一个结论既可，在我的工作机上下文切换的开销大约是2.7-5.48us左右，你自己的机器可以用我提供的代码或工具进行一番测试。 可以使用 vmstat sar 等工具查看进程的上下文切换，进而定位性能问题。 lmbench相对更准确一些，因为考虑了切换后Cache miss导致的额外开销。 本文长期连接 如果您觉得我的博客对你有帮助，请通过 RSS订阅我。 或者在X上关注我。 如果您有Medium账号，能给我个关注嘛？我的文章第一时间都会发布在Medium。 ","date":"2024-03-19T18:45:00Z","permalink":"https://huizhou92.com/zh-cn/p/%E8%AE%A1%E7%AE%97%E6%9C%BA%E4%B8%AD%E7%9A%84%E6%97%B6%E9%97%B4-%E7%BA%BF%E7%A8%8B%E4%B8%8A%E4%B8%8B%E6%96%87%E5%88%87%E6%8D%A2%E4%BC%9A%E7%94%A8%E6%8E%89%E4%BD%A0%E5%A4%9A%E5%B0%91cpu/","title":"计算机中的时间 线程上下文切换会用掉你多少CPU？"}]