[{"content":"gRPC 一般不在 message 中定义错误。\n毕竟每个 gRPC 服务本身就带一个 error 的返回值，这是用来传输错误的专用通道。\ngRPC 中所有的错误返回都应该是 nil 或者 由 status.Status 产生的一个error。这样error可以直接被调用方Client识别。\nThis article is first published in the medium MPP plan. If you are a medium user, please follow me in medium. Thank you very much.\n1. 常规用法 当遇到一个go错误的时候，直接返回是无法被下游client识别的。\n恰当的做法是：\n调用 status.New 方法，并传入一个适当的错误码，生成一个 status.Status 对象 调用该 status.Err 方法生成一个能被调用方识别的error，然后返回 1 2 st := status.New(codes.NotFound, \u0026#34;some description\u0026#34;) err := st.Err() 传入的错误码是 codes.Code 类型。\n此外还有更便捷的办法：使用 status.Error。它避免了手动转换的操作。\n1 err := status.Error(codes.NotFound, \u0026#34;some description\u0026#34;) 2. 进阶用法 上面的错误有个问题，就是 code.Code 定义的错误码只有固定的几种，无法详尽地表达业务中遇到的错误场景。\ngRPC 提供了在错误中补充信息的机制：status.WithDetails 方法\nClient 通过将 error 重新转换位 status.Status ，就可以通过 status.Details 方法直接获取其中的内容。\nstatus.Details 返回的是个slice， 是interface{}的slice，然而go已经自动做了类型转换，可以通过断言直接使用。\n服务端示例服务端示例 生成一个 status.Status 对象 填充错误的补充信息 // 生成一个 status.Status\n1 2 3 4 5 6 7 8 9 10 11 12 func ErrorWithDetails() error { st := status.Newf(codes.Internal, fmt.Sprintf(\u0026#34;something went wrong: %v\u0026#34;, \u0026#34;api.Getter\u0026#34;)) v := \u0026amp;errdetails.PreconditionFailure_Violation{ //errDetails Type: \u0026#34;test\u0026#34;, Subject: \u0026#34;12\u0026#34;, Description: \u0026#34;32\u0026#34;, } br := \u0026amp;errdetails.PreconditionFailure{} br.Violations = append(br.Violations, v) st, _ = st.WithDetails(br) return st.Err() } 客户端的示例 调用RPC错误后，解析错误信息 通过断言直接获取错误详情 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 resp, err := odinApp.CreatePlan(cli.StaffId.AssetId, gentRatePlanMeta(cli.StaffId)) ​ if status.Code(err) != codes.InvalidArgument { logger.Error(\u0026#34;create plan error:%v\u0026#34;, err) } else { for _, d := range status.Convert(err).Details() { // switch info := d.(type) { case *errdetails.QuotaFailure: logger.Info(\u0026#34;Quota failure: %s\u0026#34;, info) case *errdetails.PreconditionFailure: detail := d.(*errdetails.PreconditionFailure).Violations for _, v1 := range detail { logger.Info(fmt.Sprintf(\u0026#34;details: %+v\u0026#34;, v1)) } case *errdetails.ResourceInfo: logger.Info(\u0026#34;ResourceInfo: %s\u0026#34;, info) ​ case *errdetails.BadRequest: logger.Info(\u0026#34;ResourceInfo: %s\u0026#34;, info) ​ default: logger.Info(\u0026#34;Unexpected type: %s\u0026#34;, info) } } } logger.Infof(\u0026#34;create plan success,resp=%v\u0026#34;, resp) 原理 这个错误是如何传递给调用方Client的呢？\n是放到 metadata中的，而metadata是放到HTTP的header中的。\nmetadata是key：value格式的数据。错误的传递中，key是个固定值：grpc-status-details-bin。\n而value，是被proto编码过的，是二进制安全的。\n目前大多数语言都实现了这个机制。\n注意 gRPC对响应头做了限制，上限为8K，所以错误不能太大。\n参考资料\nhttps://protobuf.dev/getting-started/gotutorial/\nhttps://pkg.go.dev/google.golang.org/genproto/googleapis/rpc/errdetails ","date":"2024-06-29T21:38:00Z","permalink":"https://huizhou92.com/zh-cn/p/go-action-error-handling-in-grpc/","title":"gRPC中的错误处理"},{"content":"什么是 一致性hash 算法 首先摘抄一段维基百科的定义\n一致哈希 是一种特殊的哈希算法。在使用一致哈希算法后，哈希表槽位数（大小）的改变平均只需要对𝐾/𝑛 个关键字重新映射，其中 𝐾 是关键字的数量，𝑛是槽位数量。然而在传统的哈希表中，添加或删除一个槽位的几乎需要对所有关键字进行重新映射。 \u0026mdash; wikipedia\n分布式系统中, 一致性hash无处不在，CDN，KV，负载均衡等地方都有它的影子，是分布式系统的基石算法之一。一致性hash 有以下几个优点。\n均衡负载： 一致性哈希算法能够将数据在节点上均匀分布。 扩展性： 在一致性哈希算法中，当节点数量增加或减少时，只有部分数据需要重新映射，系统能够进行水平扩展更容易，可以增加节点数量以应对更大的负载需求； 减少数据迁移： 相比传统的哈希算法，一致性哈希算法在节点增减时需要重新映射的数据量较少，可以大幅降低数据迁移的开销，减少系统的不稳定性和延迟；\n本篇文章的目标就是学习一致性hash 算法以及它的简单实现。 This article is first published in the medium MPP plan. If you are a medium user, please follow me in medium. Thank you very much.\n一致性hash算法的原理 基本一致性hash 算法 最基础的一致性 hash 算法就是把节点直接分布到环上，从而划分出值域， key 经过 hash( x ) 之后，落到不同的值域，则由对应的节点处理。最常见的值域空间大小是：2^32 - 1，节点落到这个空间，来划分不同节点所属的值域。如图所示。\nNode A 存储 的 hash 范围为 [0,2^12) .\nNode B 存储 的 hash 范围为 [2^12,2^28) .\nNode C 存储 的 hash 范围为 [2^28,0) .\n上述基本的一致性哈希算法有明显的缺点：\n随机分布节点的方式使得很难均匀的分布哈希值域，从上面可以看出，三个节点存储的数据不均匀。 在动态增加节点后，原先的分布就算均匀也很难再继续保证均匀； 增删节点带来的一个较为严重的缺点是： 当一个节点异常时，该节点的压力全部转移到相邻的一个节点； 当一个新节点加入时只能为一个相邻节点分摊压力； 虚拟节点 Go语言之父 rob pike 曾今说过 计算机领域里，没有什么问题是加一层间接寻址解决不了的. 一致性hash 也是一样。\n如果三个节点 存在不均衡的问题，那么我们就把他虚拟成N个节点。A[a1,a2\u0026hellip;.a1024], 然后将他们映射到hash_ring 上，就是这样样子的。\n每个虚拟节点都有对应的hash区间。负责一段key，然后根据虚拟node 的名字找到对应的物理node读写数据。\n引入虚拟节点后，就完美的解决了上面的三个问题。\n只要我们的虚拟节点足够多，各个节点的数据就能平衡，（⚠️：这个再工程上是有代价的） 如果一个节点宕机了，它的数据会均衡的分布到整个集群所有节点，同理，新增的节点 也能负担所有节点的压力。 go语言实现 完整的代码：https://github.com/hxzhouh/blog-example/tree/main/Distributed/consistent_hashing\n首先定义一个hash_ring, 使用 crc32.ChecksumIEEE 作为默认的hash function\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 type VirtualNode struct { // 虚拟节点 Hash uint32 Node *Node } type Node struct { // 物理节点 ID string Addr string } type HashRing struct { Nodes map[string]*Node VirtualNodes []VirtualNode. mu sync.Mutex hash HashFunc } func NewHashRing(hash HashFunc) *HashRing { if hash == nil { hash = crc32.ChecksumIEEE } return \u0026amp;HashRing{ Nodes: make(map[string]*Node), VirtualNodes: make([]VirtualNode, 0), hash: hash, } } 我们来看一下怎么添加节点：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 func (hr *HashRing) AddNode(node *Node) { hr.mu.Lock() defer hr.mu.Unlock() hr.Nodes[node.ID] = node for i := 0; i \u0026lt; VirtualNodesPerNode; i++ { virtualNodeID := fmt.Sprintf(\u0026#34;%s-%d\u0026#34;, node.ID, i) hash := hr.hash([]byte(virtualNodeID)) hr.VirtualNodes = append(hr.VirtualNodes, VirtualNode{Hash: hash, Node: node}) } sort.Slice(hr.VirtualNodes, func(i, j int) bool { return hr.VirtualNodes[i].Hash \u0026lt; hr.VirtualNodes[j].Hash }) } 我们每添加一个节点，就要创建对应数量的虚拟节点，并且要保证虚拟节点有序（这样才能查找）\n同样，remove 的时候，也需要删除虚拟节点\n1 2 3 4 5 6 7 8 9 10 11 12 13 func (hr *HashRing) RemoveNode(nodeID string) { hr.mu.Lock() defer hr.mu.Unlock() delete(hr.Nodes, nodeID) virtualNodes := make([]VirtualNode, 0) for _, vn := range hr.VirtualNodes { if vn.Node.ID != nodeID { virtualNodes = append(virtualNodes, vn) } } hr.VirtualNodes = virtualNodes } 查询的时候，我们先找到对应的虚拟节点，然后再根据虚拟节点找到对应的物理节点\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 func (hr *HashRing) GetNode(key string) *Node { hr.mu.Lock() defer hr.mu.Unlock() if len(hr.VirtualNodes) == 0 { return nil } hash := hr.hash([]byte(key)) idx := sort.Search(len(hr.VirtualNodes), func(i int) bool { return hr.VirtualNodes[i].Hash \u0026gt;= hash }) if idx == len(hr.VirtualNodes) { idx = 0 } return hr.VirtualNodes[idx].Node } 最后我们来看看，业务如何使用 这个hash_ring\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 type KVSystem struct { hashRing *HashRing kvStores map[string]*kvstorage.KVStore } func NewKVSystem(nodes int) *KVSystem { hashRing := NewHashRing(crc32.ChecksumIEEE) for i := 0; i \u0026lt; nodes; i++ { // init node node := \u0026amp;Node{ ID: fmt.Sprintf(\u0026#34;Node%d\u0026#34;, i), Addr: fmt.Sprintf(\u0026#34;192.168.1.%d\u0026#34;, i+1), } hashRing.AddNode(node) } kvStores := make(map[string]*kvstorage.KVStore) //init storage for id := range hashRing.Nodes { kvStores[id] = kvstorage.NewKVStore() } return \u0026amp;KVSystem{ hashRing: hashRing, kvStores: kvStores, } } func (kv *KVSystem) Get(key string) (string, bool) { //get value node := kv.hashRing.GetNode(key) return kv.kvStores[node.ID].Get(key) } func (kv *KVSystem) Set(key string, value string) { // set value node := kv.hashRing.GetNode(key) kv.kvStores[node.ID].Set(key, value) } func (kv *KVSystem) Delete(key string) { node := kv.hashRing.GetNode(key) kv.kvStores[node.ID].Delete(key) } // DeleteNode 需要将存储在节点上的数据重新分配。 func (kv *KVSystem) DeleteNode(nodeID string) { allData := kv.kvStores[nodeID].GetAll() kv.hashRing.RemoveNode(nodeID) delete(kv.kvStores, nodeID) for key, value := range allData { kv.Set(key, value) } } func (kv *KVSystem) AddNode() { node := \u0026amp;Node{ ID: fmt.Sprintf(\u0026#34;Node%d\u0026#34;, len(kv.hashRing.Nodes)), Addr: fmt.Sprintf(\u0026#34;192.168.1.%d\u0026#34;, len(kv.hashRing.Nodes)+1), } kv.hashRing.AddNode(node) kv.kvStores[node.ID] = kvstorage.NewKVStore() } 这样我们就实现了一个最简单的基于一致性hash的kv 存储，是不是特别简单? 但是它却支撑了我们整个网络世界的运转。\n参考资料 Consistent_hashing\n","date":"2024-06-19T21:22:15+08:00","image":"https://images.hxzhouh.com/blog-images/2024/06/f3b53488c2407a75d85406be58526010.png","permalink":"https://huizhou92.com/zh-cn/p/%E5%88%86%E5%B8%83%E5%BC%8F%E5%9F%BA%E7%9F%B3%E7%AE%97%E6%B3%951-%E4%B8%80%E8%87%B4%E6%80%A7hash/","title":"分布式基石算法1:  一致性hash"},{"content":"在 go语言中，正常的 struct 一定是需要占用一块内存的，但是有一种特殊情况，如果是一个空struct，那么它的大小为0. 这是怎么回事，空struct 又有什么用呢？\nThis article is first published in the medium MPP plan. If you are a medium user, please follow me in medium. Thank you very much.\n1 2 3 4 5 6 7 8 9 10 11 12 13 type Test struct { A int B string } func main() { fmt.Println(unsafe.Sizeof(new(Test))) fmt.Println(unsafe.Sizeof(struct{}{})) } /* 8 0 */ Empty Struct 的 秘密 特殊变量：zerobase 空结构体是没有内存大小的结构体。这句话是没有错的，但是更准确的来说，其实是有一个特殊起点的，那就是 zerobase 变量，这是一个 uintptr 全局变量，占用 8 个字节。当在任何地方定义无数个 struct {} 类型的变量，编译器都只是把这个 zerobase 变量的地址给出去。换句话说，在 golang 里面，涉及到所有内存 size 为 0 的内存分配，那么就是用的同一个地址 \u0026amp;zerobase 。\n例如\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 package main import \u0026#34;fmt\u0026#34; type emptyStruct struct {} func main() { a := struct{}{} b := struct{}{} c := emptyStruct{} fmt.Printf(\u0026#34;%p\\n\u0026#34;, \u0026amp;a) fmt.Printf(\u0026#34;%p\\n\u0026#34;, \u0026amp;b) fmt.Printf(\u0026#34;%p\\n\u0026#34;, \u0026amp;c) } // 0x58e360 // 0x58e360 // 0x58e360 空结构体的变量的内存地址都是一样的。这是因为编译器在编译期间，遇到 struct {} 这种特殊类型的内存分配，会给他分配\u0026amp;zerobase，这个代码逻辑是在 mallocgc 函数里面：\n1 2 3 4 5 6 7 //go:linkname mallocgc func mallocgc(size uintptr, typ *_type, needzero bool) unsafe.Pointer { .... if size == 0 { return unsafe.Pointer(\u0026amp;zerobase) } ..... 这就是Empty struct 的秘密有了这个特殊的 变量，我们利用它可以完成很多功能。\nEmpty struct 与内存对其\n一般情况下，struct 中包含 empty struct ，这个字段是不占用内存空间的，但是有一种情况是特殊的，那就是 empty struct 位于最后一位，它会触发内存对齐 。\n比如\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 type A struct { x int y string z struct{} } type B struct { x int z struct{} y string } func main() { println(unsafe.Alignof(A{})) println(unsafe.Alignof(B{})) println(unsafe.Sizeof(A{})) println(unsafe.Sizeof(B{})) } /** 8 8 32 24 **/ 因为如果有指针指向该字段, 返回的地址将在结构体之外，如果此指针一直存活不释放对应的内存，就会有内存泄露的问题（该内存不因结构体释放而释放）。\n因此，当 struct{} 作为其他 struct 最后一个字段时，需要填充额外的内存保证安全,如果 empty struct 在开始位置，或者中间位置，那么它的地址是下一个变量的地址\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 type A struct { x int y string z struct{} } type B struct { x int z struct{} y string } func main() { a := A{} b := B{} fmt.Printf(\u0026#34;%p\\n\u0026#34;, \u0026amp;a.y) fmt.Printf(\u0026#34;%p\\n\u0026#34;, \u0026amp;a.z) fmt.Printf(\u0026#34;%p\\n\u0026#34;, \u0026amp;b.y) fmt.Printf(\u0026#34;%p\\n\u0026#34;, \u0026amp;b.z) } /** 0x1400012c008 0x1400012c018 0x1400012e008 0x1400012e008 **/ Empty 的使用场景 空结构体 struct{ } 为什么会存在的核心理由就是为了节省内存。当你需要一个结构体，但是却丝毫不关系里面的内容，那么就可以考虑空结构体。golang 核心的几个复合结构 map ，chan ，slice 都能结合 struct{} 使用。\nmap \u0026amp; struct{} 1 2 3 4 5 6 // 创建 map m := make(map[int]struct{}) // 赋值 m[1] = struct{}{} // 判断 key 键存不存在 _, ok := m[1] chan \u0026amp; struct{} channel 和 struct{} 结合是一个最经典的场景，struct{} 通常作为一个信号来传输，并不关注其中内容。chan 的分析在前几篇文章有详细说明。chan 本质的数据结构是一个管理结构加上一个 ringbuffer ，如果 struct{} 作为元素的话，ringbuffer 就是 0 分配的。\nchan 和 struct{} 结合基本只有一种用法，就是信号传递，空结构体本身携带不了值，所以也只有这一种用法啦，一般来说，配合 no buffer 的 channel 使用。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 // 创建一个信号通道 waitc := make(chan struct{}) // ... goroutine 1: // 发送信号: 投递元素 waitc \u0026lt;- struct{} // 发送信号: 关闭 close(waitc) goroutine 2: select { // 收到信号，做出对应的动作 case \u0026lt;-waitc: } 这种场景我们思考下，是否一定是非 struct{} 不可？其实不是，而且也不多这几个字节的内存，所以这种情况真的就只是不关心 chan 的元素值而已，所以才用的 struct{}。\n总结 空结构体也是结构体，只是 size 为 0 的类型而已； 所有的空结构体都有一个共同的地址：zerobase 的地址； 我们可以利用empty struct 不占用内存的特性，来优化代码，比如利用map 实现set 以及 chan 等。 参考链接 The empty struct, Dave Cheney Go 最细节篇— struct{} 空结构体究竟是啥？ ","date":"2024-06-17T23:18:02+08:00","image":"https://images.hxzhouh.com/blog-images/2024/06/c78d096394f1791445b7c10f88dd0378.jpg","permalink":"https://huizhou92.com/zh-cn/p/%E8%A7%A3%E5%AF%86go-empty-struct/","title":"解密go: empty struct"},{"content":"原文链接how-quic-is-displacing-tcp-for-speed\n引言 在过去的三十年中，HTTP（超文本传输协议）一直是互联网的支柱。我们能够浏览网页、下载文件、流式传输电影等，都是因为HTTP。这个协议多年来不断发展，见证了重大的改进。\nHTTP协议是一个应用层协议，工作在TCP（传输控制协议）之上。TCP协议有一些限制，导致网络应用程序响应性较差。\n谷歌开发了一种改变游戏规则的传输协议QUIC，以克服TCP的缺点。QUIC几年前被标准化并加入到IETF（互联网工程任务组）。\n在过去几年中，QUIC的采用呈指数级增长。大多数科技公司，如谷歌、Facebook、Pinterest等，已经开始采用使用QUIC作为传输层的HTTP/3.0。这些公司在使用HTTP/3.0和QUIC后，其网站性能有了显著提升。\n让我们开始我们的旅程，了解QUIC如何取代TCP。我们首先将了解一些基本的TCP和UDP网络概念。之后，我们将看看HTTP的演变，以及每个版本是如何克服前一个版本的限制的。然后，我们将了解QUIC是什么以及它的工作原理。我们将探讨为什么QUIC的性能比TCP高。\nTCP和UDP是如何工作的？ TCP（传输控制协议）和UDP（用户数据报协议）是传输层协议。这些协议管理互联网数据包流向和来自任何电子设备的过程。让我们详细了解这两个协议是如何工作的。\nTCP TCP是一种基于连接的协议。客户端与服务器建立连接，然后发送数据。TCP连接是通过一种称为三次握手的机制建立的。下图展示了三次握手过程：\n这个过程包括三个步骤：\nSYN - 客户端向服务器发送一个SYN数据包。\nACK - 服务器接收到SYN后，通过ACK数据包向客户端发送确认。\nSYN-ACK - 客户端收到服务器的ACK数据包后，最终通过SYN-ACK向服务器发送确认。\nTCP是一个有状态和可靠的协议。它保证从一台设备到另一台设备的所有数据包的传输。此外，它允许客户端和服务器使用相同的连接进行通信。\nUDP UDP是一种无连接协议。与TCP不同，客户端和服务器之间没有三次握手。客户端向服务器发送数据包，不等待服务器的确认。\nUDP不能保证100%的数据包传输。数据包可能会丢失，可能无法到达另一台设备。UDP不像TCP那样可靠。\n由于没有初始握手，UDP比TCP快得多。出于性能原因，UDP主要用于流式数据应用程序，如音乐/视频。\n这是一个流行的互联网梗，对TCP/UDP进行了调侃：\n到目前为止，我们已经了解了TCP和UDP协议是如何工作的。现在让我们探索HTTP协议，这是一个应用层协议。\nHTTP的演变 由Tim Berners-Lee在CERN开发的HTTP的第一个版本是在1989年。从那时起，该协议经历了多次优化和性能改进。大多数现代设备使用HTTP 1.1/ HTTP 2.0和HTTP 3.0。让我们回顾一下HTTP的历史，了解协议经历的重大变化。\nHTTP/1.0 在最初的HTTP/0.9版本之后，HTTP/1.0开始支持头、请求体、文本文件等。客户端每次使用HTTP从服务器获取数据时，都必须创建一个TCP连接。这导致在建立连接时显著浪费资源。\nHTTP/1.1 这个协议增加了对重用客户端和服务器之间现有TCP连接以获取新数据的支持。这是通过HTTP头keep-alive实现的。\n如果客户端想要获取10个JavaScript文件，那么它将与服务器建立一个连接。然后，它将重用相同的连接来获取这10个文件，而不是为每个文件创建一个新连接。\n这导致资源浪费减少和性能提升，因为它避免了创建多余的连接。然而，一个主要的缺点是众所周知的_队头阻塞_问题。\n下图展示了_队头阻塞_问题。\n让我们通过一个例子来理解这个概念。如上图所示，你有3个文件 - 图像、文本和视频。视频文件体积较大，传输时间会更长。由于视频文件传输时间较长，它会阻塞图像和文本文件的发送。\nHTTP/2.0 HTTP 2.0通过多路复用解决了_队头阻塞_问题。通过多路复用，多个文件可以通过同一个TCP连接发送。\n这导致了性能提升，并解决了应用层面的队头阻塞问题。然而，在TCP层面，如果发生数据包丢失，它必须等待数据包重传。\n多路复用解决方案在数据包丢失的情况下并不像预期的那样有效。实际上，如果数据包丢失超过5%，HTTP 1.1的性能比HTTP 2.0更好。_队头阻塞_问题从应用层转移到了传输层。\n下图展示了单个数据包丢失如何导致多个流延迟：\n当一个数据包丢失时，TCP将其后续数据包存储在其缓冲区中，直到收到丢失的数据包。然后TCP使用重传来获取丢失的数据包。HTTP无法看到TCP重传。因此，在这种情况下，不同的流会看到传输延迟。\n什么是QUIC？ 在过去的几个部分中，我们看到了TCP有一些固有的限制，如三次握手和队头阻塞。这些限制可以通过增强TCP或用新协议替换TCP来解决。\n尽管增强TCP很简单，但TCP存在于最低层，与操作系统紧密耦合。简单来说，TCP的代码存在于内核层而不是用户空间。考虑到大量的设备，实施内核空间的更改将需要大量的时间才能到达所有用户。\n因此，谷歌提出了一种新的协议QUIC，作为TCP的替代品。像TCP一样，QUIC也是一个传输层协议。然而，它位于用户空间而不是内核空间。这使得它容易更改和增强，与TCP不同。\nQUIC在UDP之上工作。它通过使用UDP克服了TCP的限制。它只是一个在UDP之上的层或包装器。该包装器添加了TCP的功能，如拥塞控制、数据包重传、多路复用等。它内部使用UDP，并在其上添加了TCP的最佳功能。\n下图显示了QUIC如何适应网络栈：\n现在我们已经了解了QUIC的基础知识，让我们深入了解这个协议的工作原理。\nQUIC是如何工作的？ QUIC握手 QUIC在UDP上工作，它不需要经过三次握手过程。三次握手过程增加了额外的开销，增加了延迟。因此，QUIC通过减少连接延迟来提高性能。\n在TCP的情况下，还有一个额外的用于TLS的握手，这也增加了延迟。QUIC将TLS握手和QUIC握手合并为一个调用。它优化了握手过程并提高了性能。\n可靠性 您可能会想“既然QUIC在UDP上工作，数据包会丢失吗？”。答案是不。QUIC在UDP堆栈上添加了可靠性。它实现了数据包重传，以防它没有收到必要的数据包。例如：如果服务器没有收到来自客户端的第5个数据包，协议将检测到它并要求客户端重新发送相同的数据包。\n多路复用 与TCP类似，QUIC也实现了多路复用。客户端可以使用单个通道同时传输多个文件。QUIC为每个流（传输的文件）创建一个UUID。它使用UUID来识别流。然后，多个流通过单个通道发送。\n下图展示了QUIC中多路复用是如何工作的：\nQUIC还通过其多路复用解决了TCP面临的队头阻塞问题。如果一个流遭受数据包丢失，只有该流会受到影响。QUIC中的流是独立的，不会影响彼此的工作。\n安全性 此外，QUIC 还支持 TLS 1.3（传输层安全性）。这保证了数据的安全性和保密性。TLS 加密了 QUIC 协议的大部分内容，例如数据包编号和连接关闭信号。\n为什么选择QUIC？ 降低延迟 - QUIC通过将TLS握手与连接建立结合起来，最小化了延迟。这也被称为0-RTT（零往返时间）。它实现了更快的连接建立，并提高了网络应用程序的性能。 多路复用 - 通过多路复用，QUIC可以在单个通道上发送多个数据流。这对于下载多个文件（如图像、JavaScript、CSS等）的客户端应用程序非常有用。 连接迁移 - 使用QUIC，您可以在不出现任何问题的情况下从一种网络接口切换到另一种（例如从Wi-Fi切换到移动数据）。这对于移动设备很重要，并提高了用户体验。 提高安全性 - QUIC使用TLS 1.3，提供更好的安全性。此外，它还加密了协议的大部分，与只加密HTTP有效载荷的TCP和TLS不同。与TCP相比，它更能抵御安全攻击。 广泛支持 - 自其诞生以来，它的采用率一直在上升。这进一步加强了它的有效性。 HTTP/3和QUIC HTTP/3是超文本传输协议（HTTP）的最新版本。它内部使用QUIC而不是TCP。它旨在为现代网络提供更有效和安全的基础。它拥有QUIC提供的所有优势。\nHTTP/3由IETF标准化。今天，很大一部分互联网流量依赖于HTTP/3。以下是显示HTTP/3采用率的图表：\n从上述图表中可以看出，采用率已经飙升至30%，并逐渐超越了HTTP/1.1。按照目前的发展速度，HTTP/3.0将在未来几年逐渐超越HTTP/2.0。\n结论 自三十年前HTTP诞生以来，互联网已经走过了漫长的道路。HTTP的演变使在线体验更加高效和响应迅速。随着现代应用程序需求的增长，我们意识到了底层协议如TCP的固有限制。\n谷歌开发了改变游戏规则的协议QUIC。它利用UDP并解决了TCP的所有不足。降低延迟、多路复用、增强安全性和连接迁移是QUIC的一些显著特点。QUIC带来的创新解决了队头阻塞等问题。\n像谷歌和Facebook这样的大型科技公司通过在HTTP/3中采用QUIC，在性能上取得了显著提升。随着采用率的上升和日益增长的支持，HTTP/3将成为互联网通信的标准。在未来几年，互联网将发展并过渡到HTTP/3，以实现效率、可靠性和性能。\n参考文献 TCP VS UDP 梗 为什么HTTP/3.0正在吞噬世界？ Pinterest现在使用HTTP/3.0 与谷歌对等 - QUIC ","date":"2024-06-14T09:38:42+08:00","image":"https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd0e30c17-275b-4a94-8883-74c546ead5e5_5955x3350.jpeg","permalink":"https://huizhou92.com/zh-cn/p/quic-%E5%A6%82%E4%BD%95%E5%9C%A8%E9%80%9F%E5%BA%A6%E5%92%8C%E5%AE%89%E5%85%A8%E6%80%A7%E6%96%B9%E9%9D%A2%E5%8F%96%E4%BB%A3-tcp/","title":"QUIC 如何在速度和安全性方面取代 TCP？"},{"content":"Compare the performance, advantages and disadvantages of fastjson, gjson, and jsonparser.\n对比 fastjson，gjson，jsonparser 的性能以及优缺点。\n这篇文章深入源码分析一下在 Go 中标准库是如何解析 JSON 的，然后再看看有哪些比较流行的 Json 解析库，以及这些库都有什么特点，在什么场景下能更好的帮助我们进行开发。\nThis article is first published in the medium MPP plan. If you are a medium user, please follow me on the medium. Thank you very much.\n其实本来我是没打算去看 JSON 库的性能问题的，但是最近我对我的项目做了一次 pprof，从下面的火焰图中可以发现在业务逻辑处理中，有一半多的性能消耗都是在 JSON 解析过程中，所以就有了这篇文章。\n这篇文章深入源码分析一下在 Go 中标准库是如何解析 JSON 的，然后再看看有哪些比较流行的 Json 解析库，以及这些库都有什么特点，在什么场景下能更好的帮助我们进行开发。\n主要介绍分析以下几个库（2024-06-13）：\n库名 Star 标准库 JSON Unmarshal valyala/fastjson 2.2 k tidwall/gjson 13.8 k buger/jsonparser 5.4 k 标准库 JSON Unmarshal 1 func Unmarshal(data []byte, v interface{}) 官方的 JSON 解析库需要传两个参数，一个是需要被序列化的对象，另一个是表示这个对象的类型。\n在真正执行 JSON 解析之前会调用 reflect.ValueOf来获取参数 v 的反射对象。然后会获取到传入的 data 对象的开头非空字符来界定该用哪种方式来进行解析。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 func (d *decodeState) value(v reflect.Value) error { switch d.opcode { default: panic(phasePanicMsg) // 数组 case scanBeginArray: ... // 结构体或map case scanBeginObject: ... // 字面量，包括 int、string、float 等 case scanBeginLiteral: ... } return nil } 如果被解析的对象是以[开头，那么表示这是个数组对象会进入到 scanBeginArray 分支；如果是以{开头，表明被解析的对象是一个结构体或 map，那么进入到 scanBeginObject 分支 等等。\n小结 通过看 Unmarshal 源码中可以看到其中使用了大量的反射来获取字段值，如果是多层嵌套的 JSON 的话，那么还需要递归进行反射获取值，可想而知性能是非常差的了。\n但是如果对性能不是那么看重的话，直接使用它其实是一个非常好的选择，功能完善的同时并且官方也一直在迭代优化，说不定在以后的版本中性能也会得到质的飞跃。并且他应该是唯一一个可以直接把JSON对象转成 go struct 的。\nfastjson 这个库的特点和它的名字一样就是快，它的介绍页是这么说的：\nFast. As usual, up to 15x faster than the standard encoding/json.\n它的使用也是非常的简单,如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 func main() { var p fastjson.Parser v, _ := p.Parse(`{ \u0026#34;str\u0026#34;: \u0026#34;bar\u0026#34;, \u0026#34;int\u0026#34;: 123, \u0026#34;float\u0026#34;: 1.23, \u0026#34;bool\u0026#34;: true, \u0026#34;arr\u0026#34;: [1, \u0026#34;foo\u0026#34;, {}] }`) fmt.Printf(\u0026#34;foo=%s\\n\u0026#34;, v.GetStringBytes(\u0026#34;str\u0026#34;)) fmt.Printf(\u0026#34;int=%d\\n\u0026#34;, v.GetInt(\u0026#34;int\u0026#34;)) fmt.Printf(\u0026#34;float=%f\\n\u0026#34;, v.GetFloat64(\u0026#34;float\u0026#34;)) fmt.Printf(\u0026#34;bool=%v\\n\u0026#34;, v.GetBool(\u0026#34;bool\u0026#34;)) fmt.Printf(\u0026#34;arr.1=%s\\n\u0026#34;, v.GetStringBytes(\u0026#34;arr\u0026#34;, \u0026#34;1\u0026#34;)) } // Output: // foo=bar // int=123 // float=1.230000 // bool=true // arr.1=foo 使用 fastjson 首先要将被解析的 JSON 串交给 Parser 解析器进行解析，然后通过 Parse 方法返回的对象来获取。如果是嵌套对象可以直接在 Get 方法传参的时候传入相应的父子 key 即可。\n分析 fastjson 在设计上和标准库 Unmarshal 不同的是，它将 JSON 解析划分为两部分：Parse、Get。\nParse 负责将 JSON 串解析成为一个结构体并返回，然后通过返回的结构体来获取数据。在 Parse 解析的过程是无锁的，所以如果想要在并发地调用 Parse 进行解析需要使用 ParserPool\nfastjson 是从上往下依次遍历 JSON ，然后解析好的数据存放在 Value 结构体中：\n1 type Value struct { o Object a []*Value s string t Type } 这个结构体非常简成：\no Object：表示被解析的结构是一个对象； a []*Value：表示表示被解析的结构是个数组； s string：如果被解析的结构不是对象也不是数组，那么其他类型的值会以字符串的形式存放在这个字段中； t Type：表示这个结构的类型，有 TypeObject、TypeArray、TypeString、TypeNumber等。 1 type Object struct { kvs []kv keysUnescaped bool } type kv struct { k string v *Value } 这个结构存放对象的递归结构。如果把上面例子中的 JSON 串解析完毕之后就是这样一个结构：\n代码 在代码实现上，由于没有了反射部分的代码，所以整个解析过程变得非常的清爽。我们直接看看主干部分的解析：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 func parseValue(s string, c *cache, depth int) (*Value, string, error) { if len(s) == 0 { return nil, s, fmt.Errorf(\u0026#34;cannot parse empty string\u0026#34;) } depth++ // 最大深度的json串不能超过MaxDepth if depth \u0026gt; MaxDepth { return nil, s, fmt.Errorf(\u0026#34;too big depth for the nested JSON; it exceeds %d\u0026#34;, MaxDepth) } // 解析对象 if s[0] == \u0026#39;{\u0026#39; { v, tail, err := parseObject(s[1:], c, depth) if err != nil { return nil, tail, fmt.Errorf(\u0026#34;cannot parse object: %s\u0026#34;, err) } return v, tail, nil } // 解析数组 if s[0] == \u0026#39;[\u0026#39; { ... } // 解析字符串 if s[0] == \u0026#39;\u0026#34;\u0026#39; { ... } ... return v, tail, nil } parseValue 会根据字符串的第一个非空字符来判断要解析的类型。这里用一个对象类型来做解析：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 func parseObject(s string, c *cache, depth int) (*Value, string, error) { ... o := c.getValue() o.t = TypeObject o.o.reset() for { var err error // 获取Ojbect结构体中的 kv 对象 kv := o.o.getKV() ... // 解析 key 值 kv.k, s, err = parseRawKey(s[1:]) ... // 递归解析 value 值 kv.v, s, err = parseValue(s, c, depth) ... // 遇到 ，号继续往下解析 if s[0] == \u0026#39;,\u0026#39; { s = s[1:] continue } // 解析完毕 if s[0] == \u0026#39;}\u0026#39; { return o, s[1:], nil } return nil, s, fmt.Errorf(\u0026#34;missing \u0026#39;,\u0026#39; after object value\u0026#34;) } } parseObject 函数也非常简单，在循环体中会获取 key 值，然后调用 parseValue 递归解析 value 值，从上往下依次解析 JSON 对象，直到最后遇到 }退出。\n小结 通过上面的分析可以知道 fastjson 在实现上比标准库简单不少，性能也高上不少。使用 Parse 解析好 JSON 树之后可以多次反复使用，避免了需要反复解析进而提升性能。\n但是它的功能是非常的简陋的，没有常用的如 JSON 转 Struct 或 JSON 转 map 的操作。如果只是想简单的获取 JSON 中的值，那么使用这个库是非常方便的，但是如果想要把 JSON 值转化成一个结构体就需要自己动手一个个设值了。\nGJSON GJSON 在我的测试中，虽然性能是没有 fastjson 这么极致，但是功能是非常完善，性能也是相当 OK 的，下面先简单介绍一下 GJSON 的功能。\nGJSON 的使用是和 fastjson 差不多的，也是非常的简单，只要在参数中传入 json 串以及需要获取的值即可：\n1 2 json := `{\u0026#34;name\u0026#34;:{\u0026#34;first\u0026#34;:\u0026#34;li\u0026#34;,\u0026#34;last\u0026#34;:\u0026#34;dj\u0026#34;},\u0026#34;age\u0026#34;:18}` lastName := gjson.Get(json, \u0026#34;name.last\u0026#34;) 除了这个功能以外还可以进行简单的模糊匹配，支持在键中包含通配符*和?，*匹配任意多个字符，?匹配单个字符，如下：\n1 2 3 4 5 6 7 json := `{ \u0026#34;name\u0026#34;:{\u0026#34;first\u0026#34;:\u0026#34;Tom\u0026#34;, \u0026#34;last\u0026#34;: \u0026#34;Anderson\u0026#34;}, \u0026#34;age\u0026#34;: 37, \u0026#34;children\u0026#34;: [\u0026#34;Sara\u0026#34;, \u0026#34;Alex\u0026#34;, \u0026#34;Jack\u0026#34;] }` fmt.Println(\u0026#34;third child*:\u0026#34;, gjson.Get(json, \u0026#34;child*.2\u0026#34;)) fmt.Println(\u0026#34;first c?ild:\u0026#34;, gjson.Get(json, \u0026#34;c?ildren.0\u0026#34;)) child*.2：首先child*匹配children，.2读取第 3 个元素； c?ildren.0：c?ildren匹配到children，.0读取第一个元素； 除了模糊匹配以外还支持修饰符操作：\n1 2 3 4 5 6 json := `{ \u0026#34;name\u0026#34;:{\u0026#34;first\u0026#34;:\u0026#34;Tom\u0026#34;, \u0026#34;last\u0026#34;: \u0026#34;Anderson\u0026#34;}, \u0026#34;age\u0026#34;: 37, \u0026#34;children\u0026#34;: [\u0026#34;Sara\u0026#34;, \u0026#34;Alex\u0026#34;, \u0026#34;Jack\u0026#34;] }` fmt.Println(\u0026#34;third child*:\u0026#34;, gjson.Get(json, \u0026#34;children|@reverse\u0026#34;)) children|@reverse 先读取数组children，然后使用修饰符@reverse翻转之后返回，输出。\n1 nestedJSON := `{\u0026#34;nested\u0026#34;: [\u0026#34;one\u0026#34;, \u0026#34;two\u0026#34;, [\u0026#34;three\u0026#34;, \u0026#34;four\u0026#34;]]}` fmt.Println(gjson.Get(nestedJSON, \u0026#34;nested|@flatten\u0026#34;)) @flatten将数组nested的内层数组平坦到外层后返回：\n1 [\u0026#34;one\u0026#34;,\u0026#34;two\u0026#34;,\u0026#34;three\u0026#34;, \u0026#34;four\u0026#34;] 等等还有一些其他有意思的功能，大家可以去查阅一下官方文档。\n分析 GJSON 的 Get 方法参数是由两部分组成，一个是 JSON 串，另一个叫做 Path 表示需要获取的 JSON 值的匹配路径。\n在 GJSON 中因为要满足很多的定义的解析场景，所以解析是分为两部分的，需要先解析好 Path 之后才去遍历解析 JSON 串。\n在解析过程中如果遇到可以匹配上的值，那么会直接返回，不需要继续往下遍历，如果是匹配多个值，那么会一直遍历完整个 JSON 串。如果遇到某个 Path 在 JSON 串中匹配不到，那么也是需要遍历完整个 JSON 串。\n在解析的过程中也不会像 fastjson 一样将解析的内容保存在一个结构体中，可以反复的利用。所以当调用 GetMany 想要返回多个值的时候，其实也是需要遍历 JSON 串多次，因此效率会比较低。\n除此之外，在解析 JSON 的时候并不会对它进行校验，即使这个放入的字符串不是个 JSON 也会照样解析，所以需要用户自己去确保放入的是 JSON 。\n代码 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 func Get(json, path string) Result { // 解析 path if len(path) \u0026gt; 1 { ... } var i int var c = \u0026amp;parseContext{json: json} if len(path) \u0026gt;= 2 \u0026amp;\u0026amp; path[0] == \u0026#39;.\u0026#39; \u0026amp;\u0026amp; path[1] == \u0026#39;.\u0026#39; { c.lines = true parseArray(c, 0, path[2:]) } else { // 根据不同的对象进行解析,这里会一直循环，直到找到 \u0026#39;{\u0026#39; 或 \u0026#39;[\u0026#39; for ; i \u0026lt; len(c.json); i++ { if c.json[i] == \u0026#39;{\u0026#39; { i++ parseObject(c, i, path) break } if c.json[i] == \u0026#39;[\u0026#39; { i++ parseArray(c, i, path) break } } } if c.piped { res := c.value.Get(c.pipe) res.Index = 0 return res } fillIndex(json, c) return c.value } Get 方法里面可以看到有很长一串的代码是用来解析各种 Path，然后一个 for 循环一直遍历 JSON 直到找到 ‘{‘ 或 ‘[‘，然后才进行相应的逻辑进行处理。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 func parseObject(c *parseContext, i int, path string) (int, bool) { var pmatch, kesc, vesc, ok, hit bool var key, val string rp := parseObjectPath(path) if !rp.more \u0026amp;\u0026amp; rp.piped { c.pipe = rp.pipe c.piped = true } // 嵌套两个 for 循环 寻找 key 值 for i \u0026lt; len(c.json) { for ; i \u0026lt; len(c.json); i++ { if c.json[i] == \u0026#39;\u0026#34;\u0026#39; { i++ var s = i for ; i \u0026lt; len(c.json); i++ { if c.json[i] \u0026gt; \u0026#39;\\\\\u0026#39; { continue } // 找到 key 值跳转到 parse_key_string_done if c.json[i] == \u0026#39;\u0026#34;\u0026#39; { i, key, kesc, ok = i+1, c.json[s:i], false, true goto parse_key_string_done } ... } key, kesc, ok = c.json[s:], false, false // 直接break parse_key_string_done: break } if c.json[i] == \u0026#39;}\u0026#39; { return i + 1, false } } if !ok { return i, false } // 校验是否是模糊匹配 if rp.wild { if kesc { pmatch = match.Match(unescape(key), rp.part) } else { pmatch = match.Match(key, rp.part) } } else { if kesc { pmatch = rp.part == unescape(key) } else { pmatch = rp.part == key } } // 解析 value hit = pmatch \u0026amp;\u0026amp; !rp.more for ; i \u0026lt; len(c.json); i++ { switch c.json[i] { default: continue case \u0026#39;\u0026#34;\u0026#39;: i++ i, val, vesc, ok = parseString(c.json, i) if !ok { return i, false } if hit { if vesc { c.value.Str = unescape(val[1 : len(val)-1]) } else { c.value.Str = val[1 : len(val)-1] } c.value.Raw = val c.value.Type = String return i, true } case \u0026#39;{\u0026#39;: if pmatch \u0026amp;\u0026amp; !hit { i, hit = parseObject(c, i+1, rp.path) if hit { return i, true } } else { i, val = parseSquash(c.json, i) if hit { c.value.Raw = val c.value.Type = JSON return i, true } } ... break } } return i, false } 在上面看 parseObject 这段代码的时候其实不是想让大家学习如何解析 JSON，以及遍历字符串，而是想要让大家看看一个 bad case 是怎样的。for 循环一层套一层，if 一个接以一个看得我 San 值狂掉，这片代码大家是不是看起来很眼熟？是不是有点像工作中遇到的某个同事写的代码？\n小结 优点：\n性能相对标准库来说还算不错； 可玩性高，可以各种检索、自定义返回值，这点非常方便；\n缺点： 不会校验 JSON 的正确性； 代码的 Code smell 很重。 需要注意的是，如果需要解析返回 JSON 的值的话，GetMany 函数会根据指定的 key 值来一次次遍历 JSON 字符串，解析为 map 可以减少遍历次数。\njsonparser 这也是一个比较热门，并且号称高性能，能比标准库快十倍的解析速度。\n分析 jsonparser 也是传入一个 JSON 的 byte 切片，以及可以通过传入多个 key 值来快速定位到相应的值，并返回。\n和 GJSON 一样，在解析过程中是不会像 fastjson 一样有个数据结构缓存已解析过的 JSON字符串，但是遇到需要解析多个值的情况可以使用 EachKey 函数来解析多个值，只需要遍历一次 JSON字符串即可实现获取多个值的操作。\n如果遇到可以匹配上的值，那么会直接返回，不需要继续往下遍历，如果是匹配多个值，那么会一直遍历完整个 JSON 串。如果遇到某个 Path 在 JSON 串中匹配不到，那么也是需要遍历完整个 JSON 串。\n并且在遍历 JSON 串的时候通过循环的方式来减少递归的使用，减少了调用栈的深度，一定程度上也是可以提升性能。\n在功能性上 ArrayEach、ObjectEach、EachKey 等三个函数都可以传入一个自定义的函数，通过函数来实现个性化的需求，使得实用性大大增强。\n对于 jsonparser 来说，代码没什么可分析的，非常的清晰，感兴趣的可以自己去看看。\n小结 对于 jsonparser 来说相对标准库比较而言性能如此高的原因可以总结为：\n使用 for 循环来减少递归的使用； 相比标准库而言没有使用反射； 在查找相应的 key 值找到了便直接退出，可以不用继续往下递归； 所操作的 JSON 串都是已被传入的，不会去重新再去申请新的空间，减少了内存分配； 除此之外在 api 的设计上也是非常的实用，ArrayEach、ObjectEach、EachKey 等三个函数都可以传入一个自定义的函数在实际的业务开发中解决了不少问题。\n缺点也是非常的明显，不能对 JSON 进行校验，即使这个 传入的不是 JSON。\n性能对比 解析小 JSON 字符串\n解析一个结构简单，大小约 190 bytes 的字符串\n库名 操作 每次迭代耗时 占用内存数 分配内存次数 性能 标准库 解析为map 724 ns/op 976 B/op 51 allocs/op 慢 解析为struct 297 ns/op 256 B/op 5 allocs/op 一般 fastjson get 68.2 ns/op 0 B/op 0 allocs/op 最快 parse 35.1 ns/op 0 B/op 0 allocs/op 最快 GJSON 转map 255 ns/op 1009 B/op 11 allocs/op 一般 get 232 ns/op 448 B/op 1 allocs/op 一般 jsonparser get 106 ns/op 232 B/op 3 allocs/op 快 解析中等大小 JSON 字符串\n解析一个具有一定复杂度，大小约 2.3KB 的字符串\n库名 操作 每次迭代耗时 占用内存数 分配内存次数 性能 标准库 解析为map 4263 ns/op 10212 B/op 208 allocs/op 慢 解析为struct 4789 ns/op 9206 B/op 259 allocs/op 慢 fastjson get 285 ns/op 0 B/op 0 allocs/op 最快 parse 302 ns/op 0 B/op 0 allocs/op 最快 GJSON 转map 2571 ns/op 8539 B/op 83 allocs/op 一般 get 1489 ns/op 448 B/op 1 allocs/op 一般 jsonparser get 878 ns/op 2728 B/op 5 allocs/op 快 解析大 JSON 字符串\n解析复杂度比较高，大小约 2.2MB 的字符串\n库名 操作 每次迭代耗时 占用内存数 分配内存次数 性能 标准库 解析为map 2292959 ns/op 5214009 B/op 95402 allocs/op 慢 解析为struct 1165490 ns/op 2023 B/op 76 allocs/op 一般 fastjson get 368056 ns/op 0 B/op 0 allocs/op 快 parse 371397 ns/op 0 B/op 0 allocs/op 快 GJSON 转map 1901727 ns/op 4788894 B/op 54372 allocs/op 一般 get 1322167 ns/op 448 B/op 1 allocs/op 一般 jsonparser get 233090 ns/op 1788865 B/op 376 allocs/op 最快 总结 在这次的分享过程中，我找了很多 JSON 的解析库分别进行对比分析，可以发现这些高性能的解析库基本上都有一些共同的特点：\n不使用反射； 通过遍历 JSON 字符串的字节来挨个解析； 尽量使用传入的 JSON 字符串来进行解析遍历，减少内存分配； 牺牲了一定的兼容性； 尽管如此，但是功能上，每个都有一定的特色 fastjson 的 api 操作最简单；GJSON 提供了模糊查找的功能，自定义程度最高；jsonparser 在实现高性能的解析过程中，还可以插入回调函数执行，提供了一定程度上的便利。\n综上，回到文章的开头中，对于我自己的业务来说，业务也只是简单的解析 http 请求返回的 JSON 串的部分字段，并且字段都是确定的，无需搜索功能，但是有时候需要做一些自定义的操作，所以对我来说 jsonparser 是最合适的。\n所以如果各位对性能有一定要求，不妨结合自己的业务情况来挑选一款 JSON 解析器。\nReference https://github.com/buger/jsonparser\nhttps://github.com/tidwall/gjson\nhttps://github.com/valyala/fastjson\nhttps://github.com/json-iterator/go\nhttps://github.com/mailru/easyjson\nhttps://github.com/Jeffail/gabs\nhttps://github.com/bitly/go-simplejson\n","date":"2024-06-13T17:10:25+08:00","permalink":"https://huizhou92.com/zh-cn/p/%E6%B7%B1%E5%85%A5-go-%E4%B8%AD%E5%90%84%E4%B8%AA%E9%AB%98%E6%80%A7%E8%83%BD-json-%E8%A7%A3%E6%9E%90%E5%BA%93/","title":"深入 Go 中各个高性能 JSON 解析库"},{"content":"上周，Go 1.23 进入冻结期，这意味着不会添加任何新功能，并且任何已添加的功能不太可能被删除。这是一个预览即将发生的变化的好机会。\n这篇文章，来了解一下 1.23 转正的 iter 包。\nThis article is first published in the medium MPP plan. If you are a medium user, please follow me in medium. Thank you very much.\n在Go 1.22中，引入了range over func实验性功能，但需要通过参数GOEXPERIMENT=rangefunc启用。在Go 1.23中，可以直接使用代码实现这种迭代方式。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 func Backward(s []string) func(yield func(string) bool) { return func(yield func(string) bool) { for i := len(s) - 1; i \u0026gt;= 0; i-- { yield(strings.ToUpper(s[i])) } } } ​ func ToUpperByIter() { sl := []string{\u0026#34;hello\u0026#34;, \u0026#34;world\u0026#34;, \u0026#34;golang\u0026#34;} for v := range Backward(sl) { // do business } } yield是传递给迭代器的可调用函数的常规名称。\n我们考虑一下如何在不使用“iter”包的情况下编写代码来实现相同的功能：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 func Convert[S any, D any](src []S, mapFn func(s S) D) []D { r := make([]D, 0, len(src)) for _, i := range src { r = append(r, mapFn(i)) } return r } func ToUpByString() { sl := []string{\u0026#34;hello\u0026#34;, \u0026#34;world\u0026#34;, \u0026#34;golang\u0026#34;} s0 := Convert(sl, func(v string) string { return strings.ToUpper(v) }) for _, v := range s0 { // do business } } 性能对比 1 2 3 4 5 6 7 8 9 10 11 12 13 ➜ huizhou92 git:(master) ✗ go test -bench . -count=3 goos: darwin goarch: arm64 pkg: huizhou92 cpu: Apple M1 Pro BenchmarkToUpByString-10 8568332 128.7 ns/op BenchmarkToUpByString-10 9310351 128.6 ns/op BenchmarkToUpByString-10 9344986 128.5 ns/op BenchmarkToUpByIter-10 12440120 96.22 ns/op BenchmarkToUpByIter-10 12436645 96.25 ns/op BenchmarkToUpByIter-10 12371175 96.64 ns/op PASS ok huizhou92 8.162s 结果很明显：ToUpperByIter 性能更好，因为它不会重新分配新的slice，使得它比以前的方法更高效。\niter 的目标 iter 包旨在提供统一且高效的迭代方法。它为自定义容器类（尤其是在引入泛型之后）提供了标准的迭代接口，并可以替换一些返回切片的现有 API。通过使用迭代器并利用编译器优化，可以提高性能。此外，它还提供了适合函数式编程风格的标准迭代机制。\n如何使用 iter iter支持两种类型的迭代器：\n1 2 3 4 5 6 7 8 9 // Seq is an iterator over sequences of individual values. // When called as seq(yield), seq calls yield(v) for each value v in the sequence, // stopping early if yield returns false. type Seq[V any] func(yield func(V) bool) // Seq2 is an iterator over sequences of pairs of values, most commonly key-value pairs. // When called as seq(yield), seq calls yield(k, v) for each pair (k, v) in the sequence, // stopping early if yield returns false. type Seq2[K, V any] func(yield func(K, V) bool) map 包已经使用 iter 来添加了诸如 All 和 Keys 等方法。这里是它的实现参考：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 //https://go.googlesource.com/go/blob/c83b1a7013784098c2061ae7be832b2ab7241424/src/maps/iter.go#L12 // All returns an iterator over key-value pairs from m. // The iteration order is not specified and is not guaranteed // to be the same from one call to the next. func All[Map ~map[K]V, K comparable, V any](m Map) iter.Seq2[K, V] { return func(yield func(K, V) bool) { for k, v := range m { if !yield(k, v) { return } } } } // Keys returns an iterator over keys in m. // The iteration order is not specified and is not guaranteed // to be the same from one call to the next. func Keys[Map ~map[K]V, K comparable](m Map) iter.Seq[K] { return func(yield func(K) bool) { for k := range m { if !yield(k) { return } } } } 争论 “在我看来，yield 是一个足够复杂的概念，会导致出现大量糟糕的、难以理解的代码。这个建议只提供了语法糖，用于编写语言中已经超出可能范围的内容。我认为这违背了“一个问题 - 一个解决方案”的规则。拜托，让 Go 保持无聊。” 来源\n这是社区内常见的反对意见。yield 不容易理解，并且我们可以通过多种方式实现迭代器。\n结论 我支持添加iter。\niter包为开发人员提供了许多可能性，旨在简化代码并采用更多的函数式编程实践。然而，由于对性能、复杂性和学习曲线的担忧，它的接受度存在分歧。\n与任何新工具一样，关键是在提供明显好处的地方平衡其使用，并同时注意潜在缺点。毫无疑问，Go社区将继续探索和辩论如何利用iter的力量而不损害该语言的基本原则。\n参考资料 61405 56413 iterators_in_go_123 ","date":"2024-06-11T17:33:16+08:00","permalink":"https://huizhou92.com/zh-cn/p/go-1.23-new-iter-package/","title":"Go 1.23: 新包 Iter"},{"content":"上周，Go 1.23 进入冻结期，这意味着不会添加任何新功能，并且任何已添加的功能不太可能被删除。这是一个预览即将发生的变化的好机会。\n这篇文章，我们来介绍引入的新包unique\nThis article is first published in the medium MPP plan. If you are a medium user, please follow me in medium. Thank you very much.\n根据wikipedia的描述，interning是按需重复使用具有同等值对象的技术，减少创建新对象的动作。这种创建模式经常用于不同编程语言中的数和字符串，可以避免不必要的对象重复分配的开销。\nunique 参考了go4.org/intern ,将它移动到了 官方库，并且做了相应的修改。 issue #62483\n就像官方描述的一样 unique 这个包提供了一种轻量化（unique仅仅八个字节）的比较两个变量是否相等的实现。比如下面这段代码\n性能提升还是很明显的\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 ➜ unique git:(master) ✗ /Users/hxzhouh/workspace/googlesource/go/bin/go test -bench=\u0026#39;BenchmarkMake1\u0026#39; -count=5 goos: darwin goarch: arm64 pkg: unique cpu: Apple M1 Pro BenchmarkMake1-10 122033748 9.692 ns/op BenchmarkMake1-10 123878858 9.688 ns/op BenchmarkMake1-10 123927121 9.706 ns/op BenchmarkMake1-10 123849468 9.759 ns/op BenchmarkMake1-10 123306187 9.673 ns/op PASS ok unique 11.055s ➜ unique git:(master) ✗ /Users/hxzhouh/workspace/googlesource/go/bin/go test -bench=\u0026#39;BenchmarkMake2\u0026#39; -count=5 goos: darwin goarch: arm64 pkg: unique cpu: Apple M1 Pro BenchmarkMake2-10 1000000000 0.3118 ns/op BenchmarkMake2-10 1000000000 0.3114 ns/op BenchmarkMake2-10 1000000000 0.3119 ns/op BenchmarkMake2-10 1000000000 0.3136 ns/op BenchmarkMake2-10 1000000000 0.3115 ns/op PASS ok unique 1.875s 但是 你不应该把他当作一个全局变量来用,存储共享数据，unique 的底层实现其实是一个map,查询的成本也是很高的。\n比如\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 ➜ huizhou92_test git:(master) ✗ /Users/hxzhouh/workspace/googlesource/go/bin/go test --bench=BenchmarkBusinessUnique --count=5 goos: darwin goarch: arm64 pkg: huizhou92_test cpu: Apple M1 Pro BenchmarkBusinessUnique-10 3114 373867 ns/op BenchmarkBusinessUnique-10 3280 390818 ns/op BenchmarkBusinessUnique-10 2941 376503 ns/op BenchmarkBusinessUnique-10 3291 389665 ns/op BenchmarkBusinessUnique-10 2954 398610 ns/op PASS ok huizhou92_test 6.320s ➜ huizhou92_test git:(master) ✗ /Users/hxzhouh/workspace/googlesource/go/bin/go test --bench=BenchmarkBusinessString --count=5 goos: darwin goarch: arm64 pkg: huizhou92_test cpu: Apple M1 Pro BenchmarkBusinessString-10 526721706 2.185 ns/op BenchmarkBusinessString-10 548612287 2.183 ns/op BenchmarkBusinessString-10 549425077 2.188 ns/op BenchmarkBusinessString-10 549012100 2.182 ns/op BenchmarkBusinessString-10 548929644 2.183 ns/op PASS ok huizhou92_test 7.237s 正是因为这样，关于unique的讨论其实还在继续，可能是因为用到的地方不是很多？不管怎么样， 这个新的包进入标准库已经是事实了。 net/netip 已经用unique 重构了它，用来比对IP地址的详细信息。\n","date":"2024-06-04T09:54:42+08:00","image":"https://images.hxzhouh.com/blog-images/2024/06/0a8a9a271b2db6d5922f8e58e589b187.png","permalink":"https://huizhou92.com/zh-cn/p/golang-1.23-%E6%96%B0%E7%9A%84-unique-%E5%8C%85/","title":"Golang 1.23: 新的 unique 包"},{"content":"众所周知，HTTPS可以解决HTTP明文传输过程中的安全性问题，尤其是中间人攻击问题。其最初的全称是HTTP over SSL（或者说 http Security）。其中的SSL是指Secure Sockets Layer，后来SSL被TLS（Transport Layer Security ）所取代。今天我们就来总结一下HTTPS的要点\nThis article is first published in the medium MPP plan. If you are a medium user, please follow me in medium. Thank you very much.\nHTTPS 版本 当前人们一般将SSL,TLS这两个协议统称为SSL/TLS协议，但大家日常说SSL的时，默认还是指TLS协议。\nTLS 协议在版本上有1.1、1.2、1.3，其中1.2曾经是主流，现在推荐使用改进后的 TLS 1.3，它升级了HandShake和Record协议，会使得通信更加安全和高效。\n安全上，TLS 1.3 移除了一些在 TLS 1.2 中被认为是不安全的加密算法，如 RC4、DES、3DES、AES-CBC 和 MD5 等，这样可以减少安全漏洞的风险。\n性能上，TLS 1.3 减少了握手过程中的往返次数（RTT），从而加快了连接的建立速度。在最佳情况下，TLS 1.3 只需要一次往返就可以完成握手，同时支持0-RTT扩展，而 TLS 1.2 需要两次或更多。\n当然，作为设计精良的互联网协议，TLS 1.3也通过hello握手消息的扩展协议考虑了最大化向前兼容，这点不再赘述。\nHTTPS 核心流程 依据不同版本的差异，细节流程会略有不同，不追求严谨细致的情况下，HTTPS工作流程如下。\nbytebytego 的这个图非常具有表现力，展示了关键的交互和核心的加密流程。最关键的几步在于如何建立TCP链接，如何通过非对称加密协商获取对称加密的密钥，以及最后通过对称加密进行通信。\nHTTPS，准确来说是TLS，设计严密，其中最关键的是Record Layer和几种Protocol，前者是数据承载管道，各种子Protocol都跑在它上面 ，其中的Record是TLS数据收发传输的基本单位，类似TCP的segment，IP的Packet，这也是下面这幅图的含义。\n上图中Protocol里最重要的是Handshake协议，针对Client Hello进行抓包后，在Wireshark中体现得会更清晰。\nHTTPS SNI 扩展 互联网早期，单机服务器没那么强大，配套的HTTPS比如SSL v2也有设计缺陷。那时有一个假定，认为拥有一个IP的单台服务器只会托管一个域名服务，所以DNS解析以后，直连IP时就能非常确定要使用具体某个域名的证书。但后面云计算、虚拟主机大爆发，以及IPv4中IP的稀缺性，一台服务器托管多个域名的场景无可避免，这时服务器面临无法知道客户端到底想要访问哪个域名的SSL证书的问题，从而导致了HTTPS SNI的出现。\nSNI（Server Name Indication）是TLS协议的一个扩展，它允许客户端在握手过程中向服务器发送目标主机名信息。这样，服务器就可以在同一个IP地址上托管多个域名的HTTPS服务，并为每个域名提供正确的证书。\n这个问题看似简单，在HTTPS逐渐普及，各互联网服务商走向全站HTTPS化的早期，很多CDN厂商甚至都是不支持SNI的。当然在2024年的今天，无论是Nginx等软件生态，还是各厂商，都已经支持了的。\nSNI信息是通过TLS握手协议传输的，抓包示意大概是下面这样子。\n具体到实操，可以使用openssl s_client子命令中的-servername选项来指定SNI：\n1 openssl s_client -connect example.com:443 -servername example.com 如果使用OpenSSL Library，也可以使用SSL_set_tlsext_host_name和BIO_set_conn_hostname等函数来在代码中设置。\nHTTPS 证书机制 HTTPS通过公钥 体系里的非对称、对称及摘要算法，实现了一系列的加解密、签名、验签等功能，基本实现了安全四大特性：机密性、完整性，身份认证和不可否认。如典型的中间人攻击（Man-in-the-middle attack，MITM），也都有了解决方案。\n这里为了解决公钥的信任问题，又引入了证书和信任链机制。证书（Certificate）是由第三方CA（Certificate Authority，证书认证机构）颁发的，本质上是一个文件，通常是.crt、.cer 或 .pem 等扩展名存储。这个文件按照一定的标准（如X.509）编码，包含了公钥、证书持有者信息、颁发机构信息、有效期和数字签名等信息。\n有一些世界知名的 CA 机构，比如 DigiCert、VeriSign、Entrust、Let’s Encrypt 等，它们签发的证书分 DV、OV、EV 三种，对应不同的可信程度。但CA自己也有信任问题，小CA的信任靠大CA签名认证，但逐层向上到了链条的最后，就是 Root CA，就只能用“自签名证书”（Self-Signed Certificate）或者“根证书”（Root Certificate）了。\n大部分操作系统和浏览器都内置了各大 CA 的根证书，HTTPS通信时会顺着证书链（Certificate Chain）逐层验证到根证书。\nHTTPS 软件生态 HTTPS，或是说TLS，生态虽然丰富，但OpenSSL一家独大。它几乎支持所有公开的加密算法和协议，已经成为了事实上的标准，许多应用软件都会使用它作为底层库来实现 TLS 功能，比如著名的 Apache、Nginx 等。\nOpenSSL源于SSLeay，其后开枝散叶，形成众多分支，如 Google 的 BoringSSL、OpenBSD 的 LibreSSL。OpenSSL的内容也极其庞杂，可以优先使用openssl命令进行学习，具体可以参考ChatGPT。\nHTTPS 加速方案 HTTPS很美好，但美好的事物都有成本。所以关于HTTPS全站铺开后的各种优化，基本上可以写成独立的一篇文章，这里先简单提下。\n首先是优化RTT，这个在IO密集型的互联网场景下尤为重要，主要是通过升级协议，如升级HTTP/3，升级TLS 1.3，都可以通过不同原理来优化RTT。其次是优化单步骤性能，如增加TLS加速卡，设置单独的TLS集群或模块等，还有一些TLS session resumption等名词也可以关注。\n我以前写过一篇文章分享为什么HTTPS为什么这么慢的文章，有兴趣可以阅读一下。\nWhy does HTTPS need 7 handshakes and 9 times delay?\n参考资料 What\u0026rsquo;s the difference between HTTP and HTTPS?\nhow-does-https-work\n","date":"2024-05-27T18:30:32+08:00","image":"https://images.hxzhouh.com/blog-images/2024/05/9113c36ee94b362ffe79a997b75c8efe.png","permalink":"https://huizhou92.com/zh-cn/p/the-key-points-of-https/","title":"了解 HTTPS：关键点和流程详解"},{"content":"上周 go1.23 已经进入冻结期了，应该不会再添加新功能，相应的已经添加了的功能 也不太可能会被移除。\n这正好可以让我们提前尝鲜这些即将到来的新特性。\nhttps://groups.google.com/g/golang-dev/c/vXE304_MnKM\nThis article is first published in the medium MPP plan. If you are a medium user, please follow me in medium. Thank you very much.\n今天要说的就是1.23中对//go:linkname指令的变更。\n相关讨论的issue 在这里：\nhttps://github.com/golang/go/issues/67401\nTL;DR //go:linkname指令官方并不推荐使用，且不保证任何向前或者向后兼容性，因此明智的做法是尽量别用\n牢记这一点之后，我们可以接着往下看了。至于为啥和“我”也就是本文的作者有关，我们先看完新版本带来的新变化再说。\nlinkname指令是做什么的 简单的说，linkname指令用于向编译器和链接器传递信息。具体的含义根据用法可以分为三类。\n第一类叫做“pull”，意思是拉取，使用方式如下：\n1 2 3 4 5 6 import _ \u0026#34;unsafe\u0026#34; // 必须有这行才能用linkname import _ \u0026#34;fmt\u0026#34; // 被拉取的包需要显式导入（除了runtime包） //go:linkname my_func fmt.Println func my_func(...any) (n int, err error) 这种用法的指令格式是//go:linkname \u0026lt;指令下方的只有声明的函数或包级别变量名\u0026gt; \u0026lt;本包或者其他包中的有完整定义的函数或变量\u0026gt;。\n这个指令的作用就是告诉编译器和连接器，my_func的函数体直接使用fmt.Println的，my_func类似fmt.Println的别名，和它共享同一份代码，就像把指令第二个参数指定的函数和变量拉取下来给第一个参数使用一样。\n正因如此，指令下方给出的声明必须和被拉取的函数/变量完全一致，否则很容易因为类型不匹配导致panic（是的没错，除非拉取的对象不存在，否则都不会出现编译错误）。\n这个指令最恐怖的地方在于它能无视函数或者变量是否是export的，包私有的东西也能被拉取出来使用。因为这一点这种用法在早期的社区中很常见，比如很多人喜欢这么干：//go:linkname myRand runtime.fastrand，因为runtime提供了一个性能还不错的随机数实现，但没有公开出来，所以有人会用linkname指令把它导出为己所用，当然随着1.21的发布这种用法不再有任何意义了，请永远都不要去模仿。\n第二种用法叫做“push”，即推送。形式上是下面这样：\n1 2 3 4 5 6 7 8 9 10 11 12 import _ \u0026#34;unsafe\u0026#34; // 必须有这行才能用linkname //go:linkname main.fastHandle func fastHandle(input io.Writer) error { ... } // package main func fastHandle(input io.Writer) error // 后面main包中可以直接使用fastHandle // 这种情况下需要在main包下创建一个空的asm文件（通常以.s作为扩展名），以告诉编译器fastHandle的定义在别处 在这种用法中，我们只需要把函数/变量名当作第一个参数传给指令，注意需要给出想用这个函数/变量的包的名字，这里是main。同时指令声明的变量或函数必须要在同包内有完整的定义，通常推荐直接把完整定义写在linkname指令下方。\n这种用法是告诉编译器和链接器这个函数/变量的名字就是xxx.yyy，如果遇到这个函数就使用linkname指定的函数/变量的代码，这个模式下甚至能在本包定义别的包里的函数。\n当然这种用法的语义作用更明显，它意味着这个函数会在任何地方被使用，修改它需要小心，因为改变了函数的行为可能会让其他调用它的代码出bug；修改了函数的签名则很可能导致运行时panic；删除了这个函数则会导致代码无法编译。\n最后一类叫做“handshake”，即握手。他是把第一类和第二类方法结合使用：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 package mypkg import _ \u0026#34;unsafe\u0026#34; // 必须有这行才能用linkname //go:linkname fastHandle func fastHandle(input io.Writer) error { ... } package main import _ \u0026#34;unsafe\u0026#34; // 必须有这行才能用linkname //go:linkname fastHandle mypkg.fastHandle func fastHandle(input io.Writer) error “pull”的一方没什么区别，但“push”的一方不用再写包名，同时用来告诉编译器函数定义在别的地方的空的asm文件也不需要了。这种就像通讯协议中的“握手”，一方告诉编译器这边允许某个函数/变量被linkname操作，另一边则明确像编译器要求它要使用某个包的某个函数/变量。\n通常“pull”和“push”应该成对出现，也就是你只应该使用“handshake”模式。\n然而不幸的是，当前（1.22）的go语言支持“pull-only”的用法，即可以随便拉取任何包里的任何函数/变量，但不需要被拉取的对象使用“push”标记自己。而被linkname拉取的一方是完全无感知的。\n这就导致了非常大的隐患。\nlinkname带来的隐患 最大的隐患在于这个指令可以在不通知被拉取的packages的情况下随意使用包中私有的函数/变量。\n举个例子：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 // pkg/mymath/mymath.go package mymath func uintPow(n uint) uint { return n*n } // main.go package main import ( \u0026#34;fmt\u0026#34; _ \u0026#34;linkname/pkg/mymath\u0026#34; _ \u0026#34;unsafe\u0026#34; ) //go:linkname pow linkname/pkg/mymath.uintPow func pow(n uint) uint func main() { fmt.Println(pow(6)) // 36 } 正常来说，uintPow是不可能被外部使用的，然而通过linkname指令我们直接无视了接口的公开和私有，有什么就能用什么了。\n这当然是非常危险的，比如我们把uintPow的参数类型改成string：\n1 2 3 4 5 package mymath func uintPow(n string) string { return n + n } 这时候编译还是能正常编译，但运行的时候就会出现各种bug，在我的机器上表现是卡死和段错误。为什么呢？因为我们把uint强行传递了过去，但参数需要是string，类型对不上，自然会出现稀奇古怪的bug。这种在别的语言里是严重的类型相关的内存错误。\n另外如果我们直接删了uintPow或者给他改个名，链接器会在编译期间报错：\n1 2 3 4 $ go build # linkname main.main: relocation target linkname/pkg/mymath.uintPow not defined 而且我们导出的是私有函数，通常没人会认为自己写的私有级别的帮助函数会被导出到包外并被使用，因此在开发时大家都是保证公开接口的稳定性，私有的函数/变量是随时可以被大规模修改甚至删除的。\n而linkname将这种在别的语言里最基本的规矩给粉碎了。\n而且事实上也是如此，从1.18开始几乎每个版本都有因为编译器或者标准库内部的私有函数被修改/删除从而导致某些第三方库在新版本无法使用的问题，因为这些库在内部悄悄用//go:linkname用了一些未公开的功能。最近一次发生在广泛使用的知名json库上类似的问题可以在这里看到。\nlinkname的正面作用 既然这个指令如此危险，为什么还一直存在呢？答案是有不得不用的理由，其中一个就在启动go程序的时候。\n我们来看下go的runtime里是怎么用linkname的：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 // runtime/proc.go //go:linkname main_main main.main func main_main() // runtime.main // 所有go程序的入口 func main() { // 初始化runtime // 调用main.main fn := main_main // make an indirect call, as the linker doesn\u0026#39;t know the address of the main package when laying down the runtime fn() // main退出后做清理工作 } 因为程序的入口在runtime里（要初始化runtime，比如gc等），所以入口函数必须在runtime包里。而我们又需要调用用户定义在main包里的main函数，但main包不能被import，因此只能靠linkname指令让链接器绕过所有编译器附加的限制来调用main函数。\n这是目前在go自身的源代码里看到的唯一一处不得不使用“pull-only”模式的地方。\n另外“handshake”模式也有存在的必要性，因为像runtime和reflect需要共享很多实现上的细节，因此reflect作为pull的一方，runtime作为push的一方，可以极大减少代码维护的复杂度。\n除了上述这些情况，绝大数linkname的使用都可以算作_abuse_。\ngolang1.23对linkname指令的改动 鉴于上述情况，golang核心团队决定限制linkname的使用。\n第一个改动是标准库里新添加的包全部禁止使用linkname导出其中的内容，目前是通过黑名单实现的，1.23中新添加的几个包以及它们的internal依赖都在名单上，这样可以防止已有的linkname问题继续扩大。这对已有的代码也是完全无害的。\n第二个变更时添加了新的ldflags: -checklinkname=1。1代表开启对linkname的限制，0代表维持1.22的行为不变。目前默认是0，但官方决定在1.23发布时默认值为1开启限制。个人建议尽量不要关闭这个限制。这个限制眼下只针对标准库，但按官方的说法效果好的话以后所有的代码不管标准库还是第三方都会启用限制。\n最后也是最大的变动，禁止对标准库的 “pull-only” linkname指令，但允许“handshake”模式。\n虽然go从来不保证linkname的向后兼容性，但这样还是会大量较大的破坏，因此官方已经对常见的go第三方库做了扫描，会把一些经常被人用linkname拉取的接口改成符合“handshake”模式的形式，这种改动只用加一行指令即可。而且该限制目前只针对标准库，其他第三方库暂时不受影响。\n因为这个变更，下面的代码在1.23是无法编译通过的：\n1 2 3 4 5 6 7 8 package main import _ \u0026#34;unsafe\u0026#34; //go:linkname corostart runtime.corostart func corostart() func main() { corostart() } 因为runtime.corostart并不符合handshake模式，所以对它的linkname被禁止了：\n1 2 3 4 5 $ go version go version devel go1.23-13d36a9b46 Wed May 27 21:51:49 2024 +0000 windows/amd64 $ go build -ldflags=-checklinkname=1 # linkname link: main: invalid reference to runtime.corostart linkname指令今后的发展 大趋势肯定是以后只允许handshake模式。不过作为过渡目前还是允许push模式的，并且官方应该会在进入功能冻结后把之前说的扫描到的常用的内部函数添加上linkname指令。\n这里比较重要的是作为开发者的我们应该怎么办：\n1.23发布之后或者现在就开始利用-checklinkname=1排查代码，及时清除不必要的linkname指令。 如果linkname指令非用不可，建议马上提issue或者熟悉go开发流程的立刻提pr补上handshake模式需要的指令，不过我不怎么推荐这种做法，因为内部api尤其是runtime以外的库的本来就不该随便被导出使用，没有一个强力的能说服所有人的理由，这些issue和pr多半不会被接受。 向官方提案，尝试把你要用的私有api变成公开接口，这一步难度也很高，私有api之所以当初不公开一定是有原因的，现在再想公开可能性也不高。 你的追求比较低，只要代码能跑就行，那可以在构建脚本里加上-ldflags=-checklinkname=0关闭限制，这样也许能岁月静好几个版本，直到某一天程序突然没法编译或者运行了一半被莫名其妙的panic打断。 4是万不得已时的保底方案，按优先度我推荐1 \u0026gt; 3 \u0026gt; 2的顺序去适配go1.23。2和3不仅仅适用于go标准库，常用的第三方库也可以。通过这些适配工作说不定也有机会让你成为go或者知名第三方库的贡献者。\n从现在开始完全是来得及的，毕竟离1.23的第一个测试版发布还有一个月左右，离正式版发布还有两个月。而且方案2的修改并不算作新功能，不受功能冻结的影响。\n当然，大部分开发者应该不用担心，比较linkname的使用是少数，一些主动使用linkname的库比如quic-go也知道兼容性问题，很小心地做了不同版本的适配，加上官方承诺的兜底这一对linkname指令的改动的影响应该比想象中小，但是是提高代码安全性的一大步。\n总结 最后总结就一句话：没事别用//go:linkname 可能会留下不可预知的隐患。\n","date":"2024-05-27T09:37:25+08:00","permalink":"https://huizhou92.com/zh-cn/p/%23-golang-1.23-changes-to-/golinkname-and-what-it-means-for-developers/","title":"Golang 1.23：`//go:linkname` 的变更及其对开发人员的意义"},{"content":"背景 gRPC是google开源的高性能跨语言的RPC方案。gRPC的设计目标是在任何环境下运行，支持可插拔的负载均衡，跟踪，运行状况检查和身份验证。它不仅支持数据中心内部和跨数据中心的服务调用，它也适用于分布式计算的最后一公里，将设备，移动应用程序和浏览器连接到后端服务。\n关于 GRPC设计的动机和原则 我们可以从这篇文章里面找到答案，gRPC Motivation and Design Principles\nThis article is first published in the medium MPP plan. If you are a medium user, please follow me in medium. Thank you very much.\n官方的文章令人印象深刻的点：\n内部有Stubby的框架，但是它不是基于任何一个标准的 支持任意环境使用，支持物联网、手机、浏览器 支持stream和流控 实际上：性能不是gRPC 设计的第一目标。那么为什么选择HTTP/2?\nHTTP/2是什么 在正式讨论gRPC为什么选择HTTP/2之前，我们先来简单了解下HTTP/2。\nHTTP/2可以简单用一个图片来介绍：\n来自：https://hpbn.co/\nHTTP/1里的header对应HTTP/2里的 HEADERS frame HTTP/1里的payload对应HTTP/2里的 DATA frame\n在Chrome浏览器里，打开chrome://net-internals/#http2，可以看到http2链接的信息。\n目前很多网站都已经跑在HTTP/2上了。\ngRPC Over HTTP/2 准确来说gRPC设计上是分层的，底层支持不同的协议，目前gRPC支持：\ngRPC over HTTP2 gRPC Web 但是大多数情况下，讨论都是基于gRPC over HTTP2。\n下面从一个真实的gRPC SayHello请求，查看它在HTTP/2上是怎样实现的。用Wireshark抓包：\n可以看到下面这些Header：\n1 2 3 4 5 6 Header: :authority: localhost:50051 Header: :path: /helloworld.Greeter/SayHello Header: :method: POST Header: :scheme: http Header: content-type: application/grpc Header: user-agent: grpc-java-netty/1.11.0 然后请求的参数在DATA frame里：\nGRPC Message: /helloworld.Greeter/SayHello, Request\n简而言之，gGRPC把元数据放到HTTP/2 Headers里，请求参数序列化之后放到 DATA frame里。\n基于HTTP/2 协议的优点 HTTP/2 是一个公开的标准 Google本身把这个事情想清楚了，它并没有把内部的Stubby开源，而是选择重新做。现在技术越来越开放，私有协议的空间越来越小。\nHTTP/2 是一个经过实践检验的标准 HTTP/2是先有实践再有标准，这个很重要。很多不成功的标准都是先有一大堆厂商讨论出标准后有实现，导致混乱而不可用，比如CORBA。HTTP/2的前身是Google的SPDY，没有Google的实践和推动，可能都不会有HTTP/2。\nHTTP/2 天然支持物联网、手机、浏览器 实际上先用上HTTP/2的也是手机和手机浏览器。移动互联网推动了HTTP/2的发展和普及。\n基于HTTP/2 多语言的实现容易 只讨论协议本身的实现，不考虑序列化。\n每个流行的编程语言都会有成熟的HTTP/2 Client HTTP/2 Client是经过充分测试，可靠的 用Client发送HTTP/2请求的难度远低于用socket发送数据包/解析数据包 HTTP/2支持Stream和流控 在业界，有很多支持stream的方案，比如基于websocket的，或者rsocket。但是这些方案都不是通用的。\nHTTP/2里的Stream还可以设置优先级，尽管在rpc里可能用的比较少，但是一些复杂的场景可能会用到。\n基于HTTP/2 在Gateway/Proxy很容易支持 nginx对gRPC的支持 envoy对gRPC的支持 HTTP/2 安全性有保证 HTTP/2 天然支持SSL，当然gRPC可以跑在clear text协议（即不加密）上。 很多私有协议的rpc可能自己包装了一层TLS支持，使用起来也非常复杂。开发者是否有足够的安全知识？使用者是否配置对了？运维者是否能正确理解？ HTTP/2 在公有网络上的传输上有保证。比如这个CRIME攻击，私有协议很难保证没有这样子的漏洞。 HTTP/2 鉴权成熟 从HTTP/1发展起来的鉴权系统已经很成熟了，可以无缝用在HTTP/2上 可以从前端到后端完全打通的鉴权，不需要做任何转换适配\n比如传统的rpc dubbo，需要写一个dubbo filter，还要考虑把鉴权相关的信息通过thread local传递进去。rpc协议本身也需要支持。总之，非常复杂。实际上绝大部分公司里的rpc都是没有鉴权的，可以随便调。 基于HTTP/2 的缺点 rpc的元数据的传输不够高效 尽管HPAC可以压缩HTTP Header，但是对于rpc来说，确定一个函数调用，可以简化为一个int，只要两端去协商过一次，后面直接查表就可以了，不需要像HPAC那样编码解码。\n可以考虑专门对gRPC做一个优化过的HTTP/2解析器，减少一些通用的处理，感觉可以提升性能。\nHTTP/2 里一次gRPC调用需要解码两次 一次是HEADERS frame，一次是DATA frame。\nHTTP/2 标准本身是只有一个TCP连接，但是实际在gRPC里是会有多个TCP连接，使用时需要注意。\ngRPC选择基于HTTP/2，那么它的性能肯定不会是最顶尖的。但是对于rpc来说中庸的qps可以接受，通用和兼容性才是最重要的事情。我们可以参考一下官方的benchmark：https://grpc.io/docs/guides/benchmarking.html\nhttps://github.com/hank-whu/rpc-benchmark\n如果您的场景是搞 Google制定标准的能力 近10年来，Google制定标准的能力越来越强。下面列举一些标准：\nHTTP/2 WebP图片格式 WebRTC 网页即时通信 VP9/AV1 视频编码标准 Service Worker/PWA QUIC/ HTTP/3\n当然google也并不都会成功，很多事情它想推也失败了，比如Chrome的Native Client。 gRPC目前是k8s生态里的事实标准。 gRPC是否会成为更多地方，更大领域的RPC标准？\n为什么会出现gRPC 准确来说为什么会出现基于HTTP/2的RPC？\n个人认为一个重要的原因是，在Cloud Native的潮流下，开放互通的需求必然会产生基于HTTP/2的RPC。即使没有gRPC，也会有其它基于HTTP/2的RPC。\ngRPC在Google的内部也是先用在Google Cloud Platform和公开的API上：https://opensource.google.com/projects/grpc\n总结 尽管gRPC它可能替换不了内部的RPC实现，但是在开放互通的时代，不止在k8s上，gRPC会有越来越多的舞台可以施展。\n参考资料 https://grpc.io/ https://hpbn.co/ https://grpc.io/blog/loadbalancing https://http2.github.io/faq https://github.com/grpc/grpc ","date":"2024-05-23T10:25:02+08:00","image":"https://huizhou92.com/cb553b8f542344f88169374915cb1819.png","permalink":"https://huizhou92.com/zh-cn/p/why-did-google-choose-to-implement-grpc-using-http2/","title":"为什么 Google 选择使用HTTP 2 实现 gRPC"},{"content":"摘要 wireshark 是一个 流行的抓取网络报文的工具,他不仅自己可以抓包，也可以解析tcpdump抓包的文件。\ngRPC 是Google开发的一个高性能RPC框架，基于HTTP/2协议+protobuf序列化协议.\n本文主要介绍如何使用wireshark抓取gRPC的报文，并解析报文内容。\nThis article is first published in the medium MPP plan. If you are a medium user, please follow me in medium. Thank you very much.\nWireshark version: 4.2.2\n配置 因为gRPC 是基于protobuf序列化协议，所以我们需要先添加protobuf的文件地址。\n点击 Wireshark -\u0026gt; Preferences\u0026hellip; -\u0026gt; Protocols -\u0026gt; Protobuf -\u0026gt; Protobuf search paths -\u0026gt; Edit\u0026hellip;\n点击+ 添加您要抓包的protobuf 文件路径，不要忘记勾选右边的 Load all files\n具体操作 首先我们写一个最简单的gRPC服务，\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 syntax = \u0026#34;proto3\u0026#34;; option go_package = \u0026#34;example.com/hxzhouh/go-example/grpc/helloworld/api\u0026#34;; package api; // The greeting service definition. service Greeter { // Sends a greeting rpc SayHello (HelloRequest) returns (HelloReply) {} } // The request message containing the user\u0026#39;s name. message HelloRequest { string name = 1; } // The response message containing the greetings message HelloReply { string message = 1; } 它仅仅就一个函数 Greeter ,补充完服务端代码，把它运行起来。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 type server struct { api.UnimplementedGreeterServer } func (s *server) SayHello(ctx context.Context, in *api.HelloRequest) (*api.HelloReply, error) { log.Printf(\u0026#34;Received: %v\u0026#34;, in.GetName()) return \u0026amp;api.HelloReply{Message: \u0026#34;Hello \u0026#34; + in.GetName()}, nil } func main() { lis, err := net.Listen(\u0026#34;tcp\u0026#34;, \u0026#34;:50051\u0026#34;) if err != nil { log.Fatalf(\u0026#34;failed to listen: %v\u0026#34;, err) } s := grpc.NewServer() api.RegisterGreeterServer(s, \u0026amp;server{}) if err := s.Serve(lis); err != nil { log.Fatalf(\u0026#34;failed to serve: %v\u0026#34;, err) } } 然后我们打开 wireshark ，选择本地网卡，监听 tcp.port == 50051\n如果您以前没接触过 wireshark，我建议您先看看这篇文章：https://www.lifewire.com/wireshark-tutorial-4143298\n一元函数 现在我们有一个gRPC 服务运行再本地的50051 端口， 我们可以使用BloomRPC 或者其他您任何喜欢的工具对服务端发起一个RPC请求,或者直接像我一样使用下面的代码\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 func Test_server_SayHello(t *testing.T) { // Set up a connection to the server. conn, err := grpc.Dial(\u0026#34;localhost:50051\u0026#34;, grpc.WithInsecure(), grpc.WithBlock()) if err != nil { log.Fatalf(\u0026#34;did not connect: %v\u0026#34;, err) } defer conn.Close() c := api.NewGreeterClient(conn) // Contact the server and print out its response. name := \u0026#34;Hello\u0026#34; ctx, cancel := context.WithTimeout(context.Background(), time.Second) defer cancel() r, err := c.SayHello(ctx, \u0026amp;api.HelloRequest{Name: name}) if err != nil { log.Fatalf(\u0026#34;could not greet: %v\u0026#34;, err) } log.Printf(\u0026#34;Greeting: %s\u0026#34;, r.GetMessage()) } 这个时候，wireshark 应该就能抓到流量包了。\n前面我们说过，gRPC = http2+protobuf, 并且我们前面已经加载了protobuf 文件，理论上我们现在已经能解析报文了。\n使用wireshark快捷键 shift+command+U 或者 用鼠标点击 Analyze -\u0026gt; Decode As... 然后设置一下将报文解析成HTTP2 格式。\n这个时候，我们就能很清晰的看到这个请求了\nmetadata 我们知道 gRPC 的metadata 是通过 http2 的header 来传递的。 现在我们通过抓包来验证一下。\n稍微改造一下客户端代码\n1 2 3 4 5 6 7 8 9 10 11 12 func Test_server_SayHello(t *testing.T) { // Set up a connection to the server. ..... // add md md := map[string][]string{\u0026#34;timestamp\u0026#34;: {time.Now().Format(time.Stamp)}} md[\u0026#34;testmd\u0026#34;] = []string{\u0026#34;testmd\u0026#34;} ctx := metadata.NewOutgoingContext(context.Background(), md) // Contact the server and print out its response. name := \u0026#34;Hello\u0026#34; ctx, cancel := context.WithTimeout(ctx, time.Second) .... } 然后重新抓包。 我们就能看到 md 确实放在 header 里面。\n并且我们还在header 看到了grpc-timeout 可见请求超时操作也是房子啊header 里面的。里面涉及的具体细节，我可能会出一篇专门的文章来说明，今天我们只关注抓包。\nTLS 上面使用的例子都是明文 传输的 我们再Dial 的时候使用了 grpc.WithInsecure() ,但是在生产环境中，我们一般使用TLS 对进行加密传输。具体的细节可以参考我以前写的文章。\nhttps://medium.com/gitconnected/secure-communication-with-grpc-from-ssl-tls-certification-to-san-certification-d9464c3d706f\n我们改造一下 服务端代码\nhttps://gist.github.com/hxzhouh/e08546cf0457d28a614d59ec28870b11\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 func main() { certificate, err := tls.LoadX509KeyPair(\u0026#34;./keys/server.crt\u0026#34;, \u0026#34;./keys/server.key\u0026#34;) if err != nil { log.Fatalf(\u0026#34;Failed to load key pair: %v\u0026#34;, err) } certPool := x509.NewCertPool() ca, err := os.ReadFile(\u0026#34;./keys/ca.crt\u0026#34;) if err != nil { log.Fatalf(\u0026#34;Failed to read ca: %v\u0026#34;, err) } if ok := certPool.AppendCertsFromPEM(ca); !ok { log.Fatalf(\u0026#34;Failed to append ca certificate\u0026#34;) } opts := []grpc.ServerOption{ grpc.Creds( // 为所有传入的连接启用TLS credentials.NewTLS(\u0026amp;tls.Config{ ClientAuth: tls.RequireAndVerifyClientCert, Certificates: []tls.Certificate{certificate}, ClientCAs: certPool, }, )), } listen, err := net.Listen(\u0026#34;tcp\u0026#34;, fmt.Sprintf(\u0026#34;0.0.0.0:%d\u0026#34;, 50051)) if err != nil { log.Fatalf(\u0026#34;failed to listen %d port\u0026#34;, 50051) } // 通过传入的TLS服务器凭证创建新的gRPC服务实例 s := grpc.NewServer(opts...) api.RegisterGreeterServer(s, \u0026amp;server{}) log.Printf(\u0026#34;server listening at %v\u0026#34;, listen.Addr()) if err := s.Serve(listen); err != nil { log.Fatalf(\u0026#34;Failed to serve: %v\u0026#34;, err) } } client\nhttps://gist.github.com/hxzhouh/46a7a31e2696b87fe6fb83c8ce7e036c\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 func Test_server_SayHello(t *testing.T) { certificate, err := tls.LoadX509KeyPair(\u0026#34;./keys/client.crt\u0026#34;, \u0026#34;./keys/client.key\u0026#34;) if err != nil { log.Fatalf(\u0026#34;Failed to load client key pair, %v\u0026#34;, err) } certPool := x509.NewCertPool() ca, err := os.ReadFile(\u0026#34;./keys/ca.crt\u0026#34;) if err != nil { log.Fatalf(\u0026#34;Failed to read %s, error: %v\u0026#34;, \u0026#34;./keys/ca.crt\u0026#34;, err) } if ok := certPool.AppendCertsFromPEM(ca); !ok { log.Fatalf(\u0026#34;Failed to append ca certs\u0026#34;) } opts := []grpc.DialOption{ grpc.WithTransportCredentials(credentials.NewTLS( \u0026amp;tls.Config{ ServerName: \u0026#34;localhost\u0026#34;, Certificates: []tls.Certificate{certificate}, RootCAs: certPool, })), } // conn, err := grpc.Dial(*addr, grpc.WithTransportCredentials(insecure.NewCredentials())) conn, err := grpc.Dial(\u0026#34;localhost:50051\u0026#34;, opts...) if err != nil { log.Fatalf(\u0026#34;Connect to %s failed\u0026#34;, \u0026#34;localhost:50051\u0026#34;) } defer conn.Close() client := api.NewGreeterClient(conn) ctx, cancel := context.WithTimeout(context.Background(), time.Second*5) defer cancel() r, err := client.SayHello(ctx, \u0026amp;api.HelloRequest{Name: \u0026#34;Hello\u0026#34;}) if err != nil { log.Printf(\u0026#34;Failed to greet, error: %v\u0026#34;, err) } else { log.Printf(\u0026#34;Greeting: %v\u0026#34;, r.GetMessage()) } } 这个时候我们再抓包，然后使用相同的方式解析。但是，我们会发现，使用HTTP2 已经无法解密了，但是可以解码成 TLS1.3\n总结 这篇文章，首先总结了使用 Wireshark 抓gRPC 包的一个基本流程。\n然后我们通过抓包知道了gRPC的参数传递是通过 HTTP2 的data-frame，CTX 等meta 是通过 header 传递的。这些知识我们以前肯定听过，但是只有动手实验才能加深理解。\n通过TLS 我们可以实现 安全的gRPC 通信，下一篇文章，我们将尝试解密TLS 报文。\n参考资料 Wireshark Tutorial https://grpc.io/blog/wireshark/ https://www.lifewire.com/wireshark-tutorial-4143298 ","date":"2024-05-19T21:36:25Z","image":"https://images.hxzhouh.com/blog-images/2024/05/a8ca43282aece789e1e0b1d2a2db7a5f.png","permalink":"https://huizhou92.com/zh-cn/p/how-to-capture-and-analyze-grpc-packets/","title":"使用 wireshark 抓包GRPC"},{"content":"我最近几年一直再打造自己的第二大脑，下面是我的几个经验教训。\n频繁切换笔记软件/博客系统 我先后使用过 EverNote，WizNote，VNote，CSDN blog，Google blogspot, WordPress，最终只造成博客散落在多个互联网角落。解决办法就是 all in one 。我现在选择的是Obsidian\n频繁切换笔记格式 我先后使用过 txt, orgmode, markdown，富文本等多种格式，最终只造成各种格式转换烦恼，跟第一条一样，每个笔记系统的格式可能不通用，选择Obsidian的原因就是它的markdown语法。如果我需要，我可以轻易的将它迁移到任何笔记系统，\n闪念笔记和真正有用的笔记混杂 闪念笔记用于快速捕捉一瞬间的灵感，但只有你在一两天内回顾它并把它变成有用的合适的笔记才有意义。如果不及时回顾，好的想法将淹没在大量的突发奇想中。我们每天大多数的想法没有太大意义应该被丢弃，而那些可以成为重大有意义的想法我们必须将他们识别出来。\n项目笔记和知识笔记混杂 只记录特定项目相关的笔记，将导致项目期间有趣的观点或者想法信息丢失。正确的做法是在项目中提取通用的知识。我推荐使用P.A.R.A 方法来整理笔记，有关P.A.R.A 您可以参考 这个网页\n频繁整理笔记的「洁癖」 大量堆积的笔记将造成知识整理冲动，多来几次就会影响坚持记录的信心。解决方法是，确定自己关注的领域和负责的责任范围，并不完全采用自下而上的知识管理方法。在达到心理挤压点时，使用 MOCS（Maps of Content）的方法整理笔记（双链绝对是你值得尝试的。）。知识管理系统最重要的是在同一个地方，用同样的格式和一致的标准记录你的洞见。\n","date":"2024-05-06T10:19:00+08:00","image":"https://images.hxzhouh.com/blog-images/2024/05/5ab6b54893dc2241704444526269572a.jpg","permalink":"https://huizhou92.com/zh-cn/p/crafting-your-second-brain-lessons-learned-from-my-note-taking-journey/","title":"知识管理的几个误区"},{"content":"进程是操作系统的伟大发明之一，对应用程序屏蔽了CPU调度、内存管理等硬件细节，而抽象出一个进程的概念，让应用程序专心于实现自己的业务逻辑既可，而且在有限的CPU上可以“同时”进行许多个任务。但是它为用户带来方便的同时，也引入了一些额外的开销。如下图，在进程运行中间的时间里，虽然CPU也在忙于干活，但是却没有完成任何的用户工作，这就是进程机制带来的额外开销。\n在进程A切换到进程B的过程中，先保存A进程的上下文，以便于等A恢复运行的时候，能够知道A进程的下一条指令是啥。然后将要运行的B进程的上下文恢复到寄存器中。这个过程被称为上下文切换。上下文切换开销在进程不多、切换不频繁的应用场景下问题不大。但是现在Linux操作系统被用到了高并发的网络程序后端服务器。在单机支持成千上万个用户请求的时候，这个开销就得拿出来说道说道了。因为用户进程在请求Redis、Mysql数据等网络IO阻塞掉的时候，或者在进程时间片到了，都会引发上下文切换。\n一个简单的进程上下文切换开销测试实验 废话不多说，我们先用个实验测试一下，到底一次上下文切换需要多长的CPU时间！实验方法是创建两个进程并在它们之间传送一个令牌。其中一个进程在读取令牌时就会引起阻塞。另一个进程发送令牌后等待其返回时也处于阻塞状态。如此往返传送一定的次数，然后统计他们的平均单次切换时间开销。\ntest04\n1 2 3 4 # gcc main.c -o main # ./main./main Before Context Switch Time1565352257 s, 774767 us After Context SWitch Time1565352257 s, 842852 us 每次执行的时间会有差异，多次运行后平均每次上下文切换耗时3.5us左右。当然了这个数字因机器而异，而且建议在实机上测试。\n前面我们测试系统调用的时候，最低值是200ns。可见，上下文切换开销要比系统调用的开销要大。系统调用只是在进程内将用户态切换到内核态，然后再切回来，而上下文切换可是直接从进程A切换到了进程B。显然这个上下文切换需要完成的工作量更大。\n进程上下文切换开销都有哪些 那么上下文切换的时候，CPU的开销都具体有哪些呢？开销分成两种，一种是直接开销、一种是间接开销。\n直接开销就是在切换时，cpu必须做的事情，包括：\n1、==切换页表全局目录== 2、==切换内核态堆栈== 3、==切换硬件上下文==（进程恢复前，必须装入寄存器的数据统称为硬件上下文） ip(instruction pointer)：指向当前执行指令的下一条指令 bp(base pointer): 用于存放执行中的函数对应的栈帧的栈底地址 sp(stack poinger): 用于存放执行中的函数对应的栈帧的栈顶地址 cr3:页目录基址寄存器，保存页目录表的物理地址 \u0026hellip;\u0026hellip; 4、刷新TLB 5、系统调度器的代码执行 间接开销主要指的是虽然切换到一个新进程后，==由于各种缓存并不热，速度运行会慢一些==。如果进程始终都在一个CPU上调度还好一些，如果跨CPU的话，之前热起来的TLB、L1、L2、L3因为运行的进程已经变了，所以以局部性原理cache起来的代码、数据也都没有用了，导致新进程穿透到内存的IO会变多。 其实我们上面的实验并没有很好地测量到这种情况，所以实际的上下文切换开销可能比3.5us要大。\n想了解更详细操作过程的同学请参考《深入理解Linux内核》中的第三章和第九章。\n一个更为专业的测试工具-lmbench lmbench用于评价系统综合性能的多平台开源benchmark，能够测试包括文档读写、内存操作、进程创建销毁开销、网络等性能。使用方法简单，但就是跑有点慢，感兴趣的同学可以自己试一试。\n这个工具的优势是是进行了多组实验，每组2个进程、8个、16个。每个进程使用的数据大小也在变，充分模拟cache miss造成的影响。我用他测了一下结果如下：\n1 2 3 4 5 ------------------------------------------------------------------------- Host OS 2p/0K 2p/16K 2p/64K 8p/16K 8p/64K 16p/16K 16p/64K ctxsw ctxsw ctxsw ctxsw ctxsw ctxsw ctxsw --------- ------------- ------ ------ ------ ------ ------ ------- ------- bjzw_46_7 Linux 2.6.32- 2.7800 2.7800 2.7000 4.3800 4.0400 4.75000 5.48000 lmbench显示的进程上下文切换耗时从2.7us到5.48之间。\n线程上下文切换耗时 前面我们测试了进程上下文切换的开销，我们再继续在Linux测试一下线程。看看究竟比进程能不能快一些，快的话能快多少。\n在Linux下其实本并没有线程，只是为了迎合开发者口味，搞了个轻量级进程出来就叫做了线程。轻量级进程和进程一样，都有自己独立的task_struct进程描述符，也都有自己独立的pid。从操作系统视角看，调度上和进程没有什么区别，都是在等待队列的双向链表里选择一个task_struct切到运行态而已。只不过轻量级进程和普通进程的区别是可以共享同一内存地址空间、代码段、全局变量、同一打开文件集合而已。\n同一进程下的线程之所有getpid()看到的pid是一样的，其实task_struct里还有一个tgid字段。 对于多线程程序来说，getpid()系统调用获取的实际上是这个tgid，因此隶属同一进程的多线程看起来PID相同。\n我们用一个实验来测试一下test06。其原理和进程测试差不多，创建了20个线程，在线程之间通过管道来传递信号。接到信号就唤醒，然后再传递信号给下一个线程，自己睡眠。 这个实验里单独考虑了给管道传递信号的额外开销，并在第一步就统计了出来。\n1 2 3 # gcc -lpthread main.c -o main 0.508250 4.363495 每次实验结果会有一些差异，上面的结果是取了多次的结果之后然后平均的，大约每次线程切换开销大约是3.8us左右。从上下文切换的耗时上来看，Linux线程（轻量级进程）其实和进程差别不太大。\nLinux相关命令 既然我们知道了上下文切换比较的消耗CPU时间，那么我们通过什么工具可以查看一下Linux里究竟在发生多少切换呢？如果上下文切换已经影响到了系统整体性能，我们有没有办法把有问题的进程揪出来，并把它优化掉呢？\n1 2 3 4 5 6 7 8 # vmstat 1 procs -----------memory---------- ---swap-- -----io---- --system-- -----cpu----- r b swpd free buff cache si so bi bo in cs us sy id wa st 2 0 0 595504 5724 190884 0 0 295 297 0 0 14 6 75 0 4 5 0 0 593016 5732 193288 0 0 0 92 19889 29104 20 6 67 0 7 3 0 0 591292 5732 195476 0 0 0 0 20151 28487 20 6 66 0 8 4 0 0 589296 5732 196800 0 0 116 384 19326 27693 20 7 67 0 7 4 0 0 586956 5740 199496 0 0 216 24 18321 24018 22 8 62 0 8 或者是\n1 2 3 4 5 6 7 8 9 10 11 12 13 # sar -w 1 proc/s Total number of tasks created per second. cswch/s Total number of context switches per second. 11:19:20 AM proc/s cswch/s 11:19:21 AM 110.28 23468.22 11:19:22 AM 128.85 33910.58 11:19:23 AM 47.52 40733.66 11:19:24 AM 35.85 30972.64 11:19:25 AM 47.62 24951.43 11:19:26 AM 47.52 42950.50 ...... 上图的环境是一台生产环境机器，配置是8核8G的KVM虚机，环境是在nginx+fpm的，fpm数量为1000，平均每秒处理的用户接口请求大约100左右。其中cs列表示的就是在1s内系统发生的上下文切换次数，大约1s切换次数都达到4W次了。粗略估算一下，每核大约每秒需要切换5K次，则1s内需要花将近20ms在上下文切换上。要知道这是虚机，本身在虚拟化上还会有一些额外开销，而且还要真正消耗CPU在用户接口逻辑处理、系统调用内核逻辑处理、以及网络连接的处理以及软中断，所以20ms的开销实际上不低了。\n那么进一步，我们看下到底是哪些进程导致了频繁的上下文切换？\n1 2 3 4 5 6 # pidstat -w 1 11:07:56 AM PID cswch/s nvcswch/s Command 11:07:56 AM 32316 4.00 0.00 php-fpm 11:07:56 AM 32508 160.00 34.00 php-fpm 11:07:56 AM 32726 131.00 8.00 php-fpm ...... 由于fpm是同步阻塞的模式，每当请求Redis、Memcache、Mysql的时候就会阻塞导致cswch/s自愿上下文切换，而只有时间片到了之后才会触发nvcswch/s非自愿切换。可见fpm进程大部分的切换都是自愿的、非自愿的比较少。\n如果想查看具体某个进程的上下文切换总情况，可以在/proc接口下直接看，不过这个是总值。\n1 2 3 grep ctxt /proc/32583/status voluntary_ctxt_switches: 573066 nonvoluntary_ctxt_switches: 89260 结论 上下文切换具体做哪些事情我们没有必要记，只需要记住一个结论既可，在我的工作机上下文切换的开销大约是2.7-5.48us左右，你自己的机器可以用我提供的代码或工具进行一番测试。 可以使用 vmstat sar 等工具查看进程的上下文切换，进而定位性能问题。 lmbench相对更准确一些，因为考虑了切换后Cache miss导致的额外开销。 ","date":"2024-03-19T18:45:00Z","permalink":"https://huizhou92.com/zh-cn/p/the-time-in-the-computers-context-switching/","title":"计算机中的时间 线程上下文切换会用掉你多少CPU？"}]